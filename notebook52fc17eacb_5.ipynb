{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. (most) package imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "\n",
    "import gc\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "from contextlib import contextmanager\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\", 20, \"display.max_columns\", 30)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini = False\n",
    "offline = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Global functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(title):\n",
    "    t0 = time.perf_counter()\n",
    "    yield\n",
    "    print(\"{} - done in {:.0f}s\".format(title, time.perf_counter() - t0))\n",
    "\n",
    "def one_hot_encoder(df, nan_as_category=True):\n",
    "    original_columns = list(df.columns)\n",
    "    categorical_columns = [col for col in df.columns if df[col].dtype == \"object\"]\n",
    "    df = pd.get_dummies(df, columns=categorical_columns, dummy_na=nan_as_category)\n",
    "    new_columns = [c for c in df.columns if c not in original_columns]\n",
    "    return df, new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C_B', 'C_G', 'C_R', 'L_A', 'L_B', 'L_C', 'L_D']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C_B</th>\n",
       "      <th>C_G</th>\n",
       "      <th>C_R</th>\n",
       "      <th>C_nan</th>\n",
       "      <th>L_A</th>\n",
       "      <th>L_B</th>\n",
       "      <th>L_C</th>\n",
       "      <th>L_D</th>\n",
       "      <th>L_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   C_B  C_G  C_R  C_nan  L_A  L_B  L_C  L_D  L_nan\n",
       "0    0    0    1      0    1    0    0    0      0\n",
       "1    0    1    0      0    0    1    0    0      0\n",
       "2    1    0    0      0    0    0    1    0      0\n",
       "3    1    0    0      0    0    0    0    1      0\n",
       "4    0    0    1      0    1    0    0    0      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_ohe_test = pd.DataFrame({\n",
    "    \"C\": [\"R\", \"G\", \"B\", \"B\", \"R\"],\n",
    "    \"L\": [\"A\", \"B\", \"C\", \"D\", \"A\"]\n",
    "})\n",
    "\n",
    "display(one_hot_encoder(df_ohe_test, False)[1])\n",
    "display(one_hot_encoder(df_ohe_test, True)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Dataset overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "offline j'ai:\n",
    "\n",
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">filenames = [\n",
    "    \"home-credit-default-risk/application_test.csv\",\n",
    "    \"home-credit-default-risk/application_train.csv\",\n",
    "    \"home-credit-default-risk/bureau.csv\",\n",
    "    \"home-credit-default-risk/bureau_balance.csv\",\n",
    "    \"home-credit-default-risk/credit_card_balance.csv\",\n",
    "    \"home-credit-default-risk/installments_payments.csv\",\n",
    "    \"home-credit-default-risk/POS_CASH_balance.csv\",\n",
    "    \"home-credit-default-risk/previous_application.csv\",\n",
    "    \"home-credit-default-risk/sample_submission.csv\"\n",
    "    ]\n",
    "</code>\n",
    "</p>\n",
    "\n",
    "not offline (on Kaggle) j'ai:\n",
    "\n",
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">filenames = [\n",
    "    \"/kaggle/input/home-credit-default-risk/sample_submission.csv\",\n",
    "    \"/kaggle/input/home-credit-default-risk/bureau_balance.csv\",\n",
    "    \"/kaggle/input/home-credit-default-risk/POS_CASH_balance.csv\",\n",
    "    \"/kaggle/input/home-credit-default-risk/application_train.csv\",\n",
    "    \"/kaggle/input/home-credit-default-risk/application_test.csv\",\n",
    "    \"/kaggle/input/home-credit-default-risk/previous_application.csv\",\n",
    "    \"/kaggle/input/home-credit-default-risk/credit_card_balance.csv\",\n",
    "    \"/kaggle/input/home-credit-default-risk/installments_payments.csv\",\n",
    "    \"/kaggle/input/home-credit-default-risk/bureau.csv\"]\n",
    "    ]\n",
    "</code>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "home-credit-default-risk/application_test.csv\n",
      "home-credit-default-risk/application_train.csv\n",
      "home-credit-default-risk/bureau.csv\n",
      "home-credit-default-risk/bureau_balance.csv\n",
      "home-credit-default-risk/credit_card_balance.csv\n",
      "home-credit-default-risk/installments_payments.csv\n",
      "home-credit-default-risk/POS_CASH_balance.csv\n",
      "home-credit-default-risk/previous_application.csv\n",
      "home-credit-default-risk/sample_submission.csv\n"
     ]
    }
   ],
   "source": [
    "filenames = []\n",
    "\n",
    "if offline:\n",
    "    le_path = \"home-credit-default-risk/\"\n",
    "else:\n",
    "    le_path = \"/kaggle/input\"\n",
    "\n",
    "for dirname, _, filenamess in os.walk(le_path):\n",
    "    for filenamee in filenamess:\n",
    "#                        HomeCredit_columns_description.csv est illisible.\n",
    "        if filenamee != \"HomeCredit_columns_description.csv\":\n",
    "            filename = os.path.join(dirname, filenamee)\n",
    "            print(filename)\n",
    "            filenames.append(filename)\n",
    " #           df = pd.read_csv(filename)\n",
    " #           display(df[-1:])\n",
    " #           if filenamee != \"bureau_balance.csv\":\n",
    " #               print(set(df.SK_ID_CURR.value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not offline:\n",
    "    flnms = []\n",
    "    flnms.append(filenames[4])\n",
    "    flnms.append(filenames[3])\n",
    "    flnms.append(filenames[8])\n",
    "    flnms.append(filenames[1])\n",
    "    flnms.append(filenames[6])\n",
    "    flnms.append(filenames[7])\n",
    "    flnms.append(filenames[2])\n",
    "    flnms.append(filenames[5])\n",
    "    flnms.append(filenames[0])\n",
    "    filenames = flnms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipped\n",
    "for filename in (filenames[:4] + filenames[5:]):\n",
    "    df = pd.read_csv(filename)\n",
    "    print(filename)\n",
    "    display(df.head(2))\n",
    "    #display(df.info())\n",
    "    print(\"shape: \", df.shape)\n",
    "    display(df.nunique())\n",
    "    #display(df.isna().mean().sort_values())\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.read_csv(filenames[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1234567890123456789012345678901234567890123456789012345678901234567890123456789"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1234567890123456789012345678901234567890123456789012345678901234567890123456789"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. application_train_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1. tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipped\n",
    "num_rows = None\n",
    "nan_as_category = False\n",
    "df = pd.read_csv(\"../input/home-credit-default-risk/application_train.csv\", nrows=num_rows)\n",
    "test_df = pd.read_csv(\"../input/home-credit-default-risk/application_test.csv\", nrows=num_rows)\n",
    "print(\"Train samples: {}, test samples: {}\".format(len(df), len(test_df)))\n",
    "df = df.append(test_df).reset_index()\n",
    "display(df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipped\n",
    "pd.factorize(df[\"CODE_GENDER\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2. preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def application_train_test(num_rows=None, nan_as_category=False):\n",
    "    # Read data and merge\n",
    "    if mini:\n",
    "        df = pd.read_csv(filenames[1], nrows=num_rows)[-10:]\n",
    "        test_df = pd.read_csv(filenames[0], nrows=num_rows)[-2:]\n",
    "    else:\n",
    "        df = pd.read_csv(filenames[1], nrows=num_rows)\n",
    "        test_df = pd.read_csv(filenames[0], nrows=num_rows)\n",
    "    print(\"Train samples: {}, test samples: {}\".format(len(df), len(test_df)))\n",
    "    df = df.append(test_df).reset_index()\n",
    "    # Optional: Remove 4 applications with XNA CODE_GENDER (train set)\n",
    "    df = df[df[\"CODE_GENDER\"] != \"XNA\"]\n",
    "\n",
    "    # Categorical features with Binary encode (0 or 1; two categories)\n",
    "    for bin_feature in [\"CODE_GENDER\", \"FLAG_OWN_CAR\", \"FLAG_OWN_REALTY\"]:\n",
    "        df[bin_feature], uniques = pd.factorize(df[bin_feature])\n",
    "    # Categorical features with One-Hot encode\n",
    "    df, cat_cols = one_hot_encoder(df, nan_as_category)\n",
    "\n",
    "    # NaN values for DAYS_EMPLOYED: 365.243 -> nan\n",
    "    df[\"DAYS_EMPLOYED\"].replace(365243, np.nan, inplace=True)\n",
    "    # Some simple new features (percentages)\n",
    "    df[\"DAYS_EMPLOYED_PERC\"] = df[\"DAYS_EMPLOYED\"] / df[\"DAYS_BIRTH\"]\n",
    "    df[\"INCOME_CREDIT_PERC\"] = df[\"AMT_INCOME_TOTAL\"] / df[\"AMT_CREDIT\"]\n",
    "    df[\"INCOME_PER_PERSON\"] = df[\"AMT_INCOME_TOTAL\"] / df[\"CNT_FAM_MEMBERS\"]\n",
    "    df[\"ANNUITY_INCOME_PERC\"] = df[\"AMT_ANNUITY\"] / df[\"AMT_INCOME_TOTAL\"]\n",
    "    df[\"PAYMENT_RATE\"] = df[\"AMT_ANNUITY\"] / df[\"AMT_CREDIT\"]\n",
    "    del test_df\n",
    "    gc.collect()\n",
    "    #print(df.dtypes.value_counts())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. bureau_and_balance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1. tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipped\n",
    "bureau = pd.read_csv(\"../input/home-credit-default-risk/bureau.csv\", nrows=num_rows)\n",
    "bb = pd.read_csv(\"../input/home-credit-default-risk/bureau_balance.csv\", nrows=num_rows)\n",
    "bb, bb_cat = one_hot_encoder(bb, nan_as_category)\n",
    "bureau, bureau_cat = one_hot_encoder(bureau, nan_as_category)\n",
    "bb_aggregations = {\"MONTHS_BALANCE\": [\"min\", \"max\", \"size\"]}\n",
    "for col in bb_cat:\n",
    "    bb_aggregations[col] = [\"mean\"]\n",
    "print(bb_aggregations, \"\\n\", bb.columns, \"\\n\", bureau_cat, \"\\n\", bureau.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipped\n",
    "bb_agg = bb.groupby(\"SK_ID_BUREAU\").agg(bb_aggregations)\n",
    "bb_agg.columns = pd.Index([e[0] + \"_\" + e[1].upper() for e in bb_agg.columns.tolist()])\n",
    "bureau = bureau.join(bb_agg, how=\"left\", on=\"SK_ID_BUREAU\")\n",
    "bureau.drop([\"SK_ID_BUREAU\"], axis=1, inplace=True)\n",
    "bureau.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipped\n",
    "num_aggregations = {\n",
    "    \"DAYS_CREDIT\": [\"min\", \"max\", \"mean\", \"var\"],\n",
    "    \"DAYS_CREDIT_ENDDATE\": [\"min\", \"max\", \"mean\"],\n",
    "    \"DAYS_CREDIT_UPDATE\": [\"mean\"],\n",
    "    \"CREDIT_DAY_OVERDUE\": [\"max\", \"mean\"],\n",
    "    \"AMT_CREDIT_MAX_OVERDUE\": [\"mean\"],\n",
    "    \"AMT_CREDIT_SUM\": [\"max\", \"mean\", \"sum\"],\n",
    "    \"AMT_CREDIT_SUM_DEBT\": [\"max\", \"mean\", \"sum\"],\n",
    "    \"AMT_CREDIT_SUM_OVERDUE\": [\"mean\"],\n",
    "    \"AMT_CREDIT_SUM_LIMIT\": [\"mean\", \"sum\"],\n",
    "    \"AMT_ANNUITY\": [\"max\", \"mean\"],\n",
    "    \"CNT_CREDIT_PROLONG\": [\"sum\"],\n",
    "    \"MONTHS_BALANCE_MIN\": [\"min\"],\n",
    "    \"MONTHS_BALANCE_MAX\": [\"max\"],\n",
    "    \"MONTHS_BALANCE_SIZE\": [\"mean\", \"sum\"]\n",
    "}\n",
    "# Bureau and bureau_balance categorical features\n",
    "cat_aggregations = {}\n",
    "for cat in bureau_cat: cat_aggregations[cat] = [\"mean\"]\n",
    "for cat in bb_cat: cat_aggregations[cat + \"_MEAN\"] = [\"mean\"]\n",
    "\n",
    "bureau_agg = bureau.groupby(\"SK_ID_CURR\").agg({**num_aggregations, **cat_aggregations})\n",
    "bureau_agg.columns = pd.Index([\"BURO_\" + e[0] + \"_\" + e[1].upper() for e in bureau_agg.columns.tolist()])\n",
    "# Bureau: Active credits - using only numerical aggregations\n",
    "active = bureau[bureau[\"CREDIT_ACTIVE_Active\"] == 1]\n",
    "active.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2. preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bureau_and_balance(num_rows=None, nan_as_category=True):\n",
    "    if mini:\n",
    "        bureau = pd.read_csv(filenames[2], nrows=num_rows)[-5:-3]\n",
    "        bb = pd.read_csv(filenames[3], nrows=num_rows)[-5:-3]\n",
    "    else:\n",
    "        bureau = pd.read_csv(filenames[2], nrows=num_rows)\n",
    "        bb = pd.read_csv(filenames[3], nrows=num_rows)\n",
    "    bb, bb_cat = one_hot_encoder(bb, nan_as_category)\n",
    "    bureau, bureau_cat = one_hot_encoder(bureau, nan_as_category)\n",
    "\n",
    "    # Bureau balance: Perform aggregations and merge with bureau.csv\n",
    "    bb_aggregations = {\"MONTHS_BALANCE\": [\"min\", \"max\", \"size\"]}\n",
    "    for col in bb_cat:\n",
    "        bb_aggregations[col] = [\"mean\"]\n",
    "    bb_agg = bb.groupby(\"SK_ID_BUREAU\").agg(bb_aggregations)\n",
    "    bb_agg.columns = pd.Index([e[0] + \"_\" + e[1].upper() for e in bb_agg.columns.tolist()])\n",
    "    bureau = bureau.join(bb_agg, how=\"left\", on=\"SK_ID_BUREAU\")\n",
    "    bureau.drop([\"SK_ID_BUREAU\"], axis=1, inplace=True)\n",
    "    del bb, bb_agg\n",
    "    gc.collect()\n",
    "\n",
    "    # Bureau and bureau_balance numeric features\n",
    "    num_aggregations = {\n",
    "        \"DAYS_CREDIT\": [\"min\", \"max\", \"mean\", \"var\"],\n",
    "        \"DAYS_CREDIT_ENDDATE\": [\"min\", \"max\", \"mean\"],\n",
    "        \"DAYS_CREDIT_UPDATE\": [\"mean\"],\n",
    "        \"CREDIT_DAY_OVERDUE\": [\"max\", \"mean\"],\n",
    "        \"AMT_CREDIT_MAX_OVERDUE\": [\"mean\"],\n",
    "        \"AMT_CREDIT_SUM\": [\"max\", \"mean\", \"sum\"],\n",
    "        \"AMT_CREDIT_SUM_DEBT\": [\"max\", \"mean\", \"sum\"],\n",
    "        \"AMT_CREDIT_SUM_OVERDUE\": [\"mean\"],\n",
    "        \"AMT_CREDIT_SUM_LIMIT\": [\"mean\", \"sum\"],\n",
    "        \"AMT_ANNUITY\": [\"max\", \"mean\"],\n",
    "        \"CNT_CREDIT_PROLONG\": [\"sum\"],\n",
    "        \"MONTHS_BALANCE_MIN\": [\"min\"],\n",
    "        \"MONTHS_BALANCE_MAX\": [\"max\"],\n",
    "        \"MONTHS_BALANCE_SIZE\": [\"mean\", \"sum\"]\n",
    "    }\n",
    "    # Bureau and bureau_balance categorical features\n",
    "    cat_aggregations = {}\n",
    "    for cat in bureau_cat: cat_aggregations[cat] = [\"mean\"]\n",
    "    for cat in bb_cat: cat_aggregations[cat + \"_MEAN\"] = [\"mean\"]\n",
    "\n",
    "    bureau_agg = bureau.groupby(\"SK_ID_CURR\").agg({**num_aggregations, **cat_aggregations})\n",
    "    bureau_agg.columns = pd.Index([\"BURO_\" + e[0] + \"_\" + e[1].upper() for e in bureau_agg.columns.tolist()])\n",
    "    # Bureau: Active credits - using only numerical aggregations\n",
    "    active = bureau[bureau[\"CREDIT_ACTIVE_Active\"] == 1]\n",
    "    active_agg = active.groupby(\"SK_ID_CURR\").agg(num_aggregations)\n",
    "    active_agg.columns = pd.Index([\"ACTIVE_\" + e[0] + \"_\" + e[1].upper() for e in active_agg.columns.tolist()])\n",
    "    bureau_agg = bureau_agg.join(active_agg, how=\"left\", on=\"SK_ID_CURR\")\n",
    "    del active, active_agg\n",
    "    gc.collect()\n",
    "    # Bureau: Closed credits - using only numerical aggregations\n",
    "    closed = bureau[bureau[\"CREDIT_ACTIVE_Closed\"] == 1]\n",
    "    closed_agg = closed.groupby(\"SK_ID_CURR\").agg(num_aggregations)\n",
    "    closed_agg.columns = pd.Index([\"CLOSED_\" + e[0] + \"_\" + e[1].upper() for e in closed_agg.columns.tolist()])\n",
    "    bureau_agg = bureau_agg.join(closed_agg, how=\"left\", on=\"SK_ID_CURR\")\n",
    "    del closed, closed_agg, bureau\n",
    "    gc.collect()\n",
    "    #print(bureau_agg.dtypes.value_counts())\n",
    "    return bureau_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3. more tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipped\n",
    "df = pd.read_csv(filenames[2])[-5:]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipped\n",
    "prev.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. previous_applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1. preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def previous_applications(num_rows=None, nan_as_category=True):\n",
    "    if mini:\n",
    "        prev = pd.read_csv(filenames[7], nrows=num_rows)[-7:-5]\n",
    "    else:\n",
    "        prev = pd.read_csv(filenames[7], nrows=num_rows)\n",
    "    prev, cat_cols = one_hot_encoder(prev, nan_as_category=True)\n",
    "    # Days 365.243 values -> nan\n",
    "    prev[\"DAYS_FIRST_DRAWING\"].replace(365243, np.nan, inplace=True)\n",
    "    prev[\"DAYS_FIRST_DUE\"].replace(365243, np.nan, inplace=True)\n",
    "    prev[\"DAYS_LAST_DUE_1ST_VERSION\"].replace(365243, np.nan, inplace=True)\n",
    "    prev[\"DAYS_LAST_DUE\"].replace(365243, np.nan, inplace=True)\n",
    "    prev[\"DAYS_TERMINATION\"].replace(365243, np.nan, inplace=True)\n",
    "    # Add feature: value ask / value received percentage\n",
    "    prev[\"APP_CREDIT_PERC\"] = prev[\"AMT_APPLICATION\"] / prev[\"AMT_CREDIT\"]\n",
    "    # Previous applications numeric features\n",
    "    num_aggregations = {\n",
    "        \"AMT_ANNUITY\": [\"min\", \"max\", \"mean\"],\n",
    "        \"AMT_APPLICATION\": [\"min\", \"max\", \"mean\"],\n",
    "        \"AMT_CREDIT\": [\"min\", \"max\", \"mean\"],\n",
    "        \"APP_CREDIT_PERC\": [\"min\", \"max\", \"mean\", \"var\"],\n",
    "        \"AMT_DOWN_PAYMENT\": [\"min\", \"max\", \"mean\"],\n",
    "        \"AMT_GOODS_PRICE\": [\"min\", \"max\", \"mean\"],\n",
    "        \"HOUR_APPR_PROCESS_START\": [\"min\", \"max\", \"mean\"],\n",
    "        \"RATE_DOWN_PAYMENT\": [\"min\", \"max\", \"mean\"],\n",
    "        \"DAYS_DECISION\": [\"min\", \"max\", \"mean\"],\n",
    "        \"CNT_PAYMENT\": [\"mean\", \"sum\"],\n",
    "    }\n",
    "    # Previous applications categorical features\n",
    "    cat_aggregations = {}\n",
    "    for cat in cat_cols:\n",
    "        cat_aggregations[cat] = [\"mean\"]\n",
    "\n",
    "    prev_agg = prev.groupby(\"SK_ID_CURR\").agg({**num_aggregations, **cat_aggregations})\n",
    "    prev_agg.columns = pd.Index([\"PREV_\" + e[0] + \"_\" + e[1].upper() for e in prev_agg.columns.tolist()])\n",
    "    # Previous Applications: Approved Applications - only numerical features\n",
    "    approved = prev[prev[\"NAME_CONTRACT_STATUS_Approved\"] == 1]\n",
    "    approved_agg = approved.groupby(\"SK_ID_CURR\").agg(num_aggregations)\n",
    "    approved_agg.columns = pd.Index([\"APPROVED_\" + e[0] + \"_\" + e[1].upper() for e in approved_agg.columns.tolist()])\n",
    "    prev_agg = prev_agg.join(approved_agg, how=\"left\", on=\"SK_ID_CURR\")\n",
    "    # Previous Applications: Refused Applications - only numerical features\n",
    "    refused = prev[prev[\"NAME_CONTRACT_STATUS_Refused\"] == 1]\n",
    "    refused_agg = refused.groupby(\"SK_ID_CURR\").agg(num_aggregations)\n",
    "    refused_agg.columns = pd.Index([\"REFUSED_\" + e[0] + \"_\" + e[1].upper() for e in refused_agg.columns.tolist()])\n",
    "    prev_agg = prev_agg.join(refused_agg, how=\"left\", on=\"SK_ID_CURR\")\n",
    "    del refused, refused_agg, approved, approved_agg, prev\n",
    "    gc.collect()\n",
    "    #print(prev_agg.dtypes.value_counts())\n",
    "    return prev_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2. tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipped\n",
    "df = pd.read_csv(filenames[7])[-7:]\n",
    "df.NAME_CONTRACT_STATUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipped\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. pos_cash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.1. preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_cash(num_rows=None, nan_as_category=True):\n",
    "    if mini:\n",
    "        pos = pd.read_csv(filenames[6], nrows=num_rows)[-2:]\n",
    "    else:\n",
    "        pos = pd.read_csv(filenames[6], nrows=num_rows)\n",
    "    pos, cat_cols = one_hot_encoder(pos, nan_as_category=True)\n",
    "    # Features\n",
    "    aggregations = {\n",
    "        \"MONTHS_BALANCE\": [\"max\", \"mean\", \"size\"],\n",
    "        \"SK_DPD\": [\"max\", \"mean\"],\n",
    "        \"SK_DPD_DEF\": [\"max\", \"mean\"]\n",
    "    }\n",
    "    for cat in cat_cols:\n",
    "        aggregations[cat] = [\"mean\"]\n",
    "\n",
    "    pos_agg = pos.groupby(\"SK_ID_CURR\").agg(aggregations)\n",
    "    pos_agg.columns = pd.Index([\"POS_\" + e[0] + \"_\" + e[1].upper() for e in pos_agg.columns.tolist()])\n",
    "    # Count pos cash accounts\n",
    "    pos_agg[\"POS_COUNT\"] = pos.groupby(\"SK_ID_CURR\").size()\n",
    "    del pos\n",
    "    gc.collect()\n",
    "    #print(pos_agg.dtypes.value_counts())\n",
    "    return pos_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. installment_payments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.1. preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def installments_payments(num_rows=None, nan_as_category=True):\n",
    "    if mini:\n",
    "        ins = pd.read_csv(filenames[5], nrows=num_rows)[-2:]\n",
    "    else:\n",
    "        ins = pd.read_csv(filenames[5], nrows=num_rows)\n",
    "    ins, cat_cols = one_hot_encoder(ins, nan_as_category=True)\n",
    "    # Percentage and difference paid in each installment (amount paid and installment value)\n",
    "    ins[\"PAYMENT_PERC\"] = ins[\"AMT_PAYMENT\"] / ins[\"AMT_INSTALMENT\"]\n",
    "    ins[\"PAYMENT_DIFF\"] = ins[\"AMT_INSTALMENT\"] - ins[\"AMT_PAYMENT\"]\n",
    "    # Days past due and days before due (no negative values)\n",
    "    ins[\"DPD\"] = ins[\"DAYS_ENTRY_PAYMENT\"] - ins[\"DAYS_INSTALMENT\"]\n",
    "    ins[\"DBD\"] = ins[\"DAYS_INSTALMENT\"] - ins[\"DAYS_ENTRY_PAYMENT\"]\n",
    "    ins[\"DPD\"] = ins[\"DPD\"].apply(lambda x: x if x > 0 else 0)\n",
    "    ins[\"DBD\"] = ins[\"DBD\"].apply(lambda x: x if x > 0 else 0)\n",
    "    # Features: Perform aggregations\n",
    "    aggregations = {\n",
    "        \"NUM_INSTALMENT_VERSION\": [\"nunique\"],\n",
    "        \"DPD\": [\"max\", \"mean\", \"sum\"],\n",
    "        \"DBD\": [\"max\", \"mean\", \"sum\"],\n",
    "        \"PAYMENT_PERC\": [\"max\", \"mean\", \"sum\", \"var\"],\n",
    "        \"PAYMENT_DIFF\": [\"max\", \"mean\", \"sum\", \"var\"],\n",
    "        \"AMT_INSTALMENT\": [\"max\", \"mean\", \"sum\"],\n",
    "        \"AMT_PAYMENT\": [\"min\", \"max\", \"mean\", \"sum\"],\n",
    "        \"DAYS_ENTRY_PAYMENT\": [\"max\", \"mean\", \"sum\"]\n",
    "    }\n",
    "    for cat in cat_cols:\n",
    "        aggregations[cat] = [\"mean\"]\n",
    "    ins_agg = ins.groupby(\"SK_ID_CURR\").agg(aggregations)\n",
    "    ins_agg.columns = pd.Index([\"INSTAL_\" + e[0] + \"_\" + e[1].upper() for e in ins_agg.columns.tolist()])\n",
    "    # Count installments accounts\n",
    "    ins_agg[\"INSTAL_COUNT\"] = ins.groupby(\"SK_ID_CURR\").size()\n",
    "    del ins\n",
    "    gc.collect()\n",
    "    #print(ins_agg.dtypes.value_counts())\n",
    "    return ins_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6. credit_card_balance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6.1. preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def credit_card_balance(num_rows=None, nan_as_category=True):\n",
    "    if mini:\n",
    "        cc = pd.read_csv(filenames[4], nrows=num_rows)[-2:]\n",
    "    else:\n",
    "        cc = pd.read_csv(filenames[4], nrows=num_rows)\n",
    "    cc, cat_cols = one_hot_encoder(cc, nan_as_category=True)\n",
    "    # General aggregations\n",
    "    cc.drop([\"SK_ID_PREV\"], axis=1, inplace =True)\n",
    "    cc_agg = cc.groupby(\"SK_ID_CURR\").agg([\"min\", \"max\", \"mean\", \"sum\", \"var\"])\n",
    "    cc_agg.columns = pd.Index([\"CC_\" + e[0] + \"_\" + e[1].upper() for e in cc_agg.columns.tolist()])\n",
    "    # Count credit card lines\n",
    "    cc_agg[\"CC_COUNT\"] = cc.groupby(\"SK_ID_CURR\").size()\n",
    "    del cc\n",
    "    gc.collect()\n",
    "    #print(cc_agg.dtypes.value_counts())\n",
    "    return cc_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. functions from the original notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM GBDT with KFold or Stratified KFold\n",
    "# Parameters from Tilii kernel: https://www.kaggle.com/tilii7/olivier-lightgbm-parameters-by-bayesian-opt/code\n",
    "def kfold_lightgbm(df, num_folds, stratified=False, debug=False):\n",
    "    # Divide in training/validation and test data\n",
    "    train_df = df[df[\"TARGET\"].notnull()]\n",
    "    test_df = df[df[\"TARGET\"].isnull()]\n",
    "    print(\"Starting LightGBM. Train shape: {}, test shape: {}\".format(train_df.shape, test_df.shape))\n",
    "    del df\n",
    "    gc.collect()\n",
    "    # Cross validation model\n",
    "    if stratified:\n",
    "        folds = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=1001)\n",
    "    else:\n",
    "        folds = KFold(n_splits=num_folds, shuffle=True, random_state=1001)\n",
    "    # Create arrays and dataframes to store results\n",
    "    oof_preds = np.zeros(train_df.shape[0])\n",
    "    sub_preds = np.zeros(test_df.shape[0])\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    feats = [f for f in train_df.columns if f not in [\"TARGET\",\"SK_ID_CURR\",\"SK_ID_BUREAU\",\"SK_ID_PREV\",\"index\"]]\n",
    "\n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], train_df[\"TARGET\"])):\n",
    "        train_x, train_y = train_df[feats].iloc[train_idx], train_df[\"TARGET\"].iloc[train_idx]\n",
    "        valid_x, valid_y = train_df[feats].iloc[valid_idx], train_df[\"TARGET\"].iloc[valid_idx]\n",
    "\n",
    "        # LightGBM parameters found by Bayesian optimization\n",
    "        clf = LGBMClassifier(\n",
    "            nthread=4,\n",
    "            n_estimators=10000,\n",
    "            learning_rate=0.02,\n",
    "            num_leaves=34,\n",
    "            colsample_bytree=0.9497036,\n",
    "            subsample=0.8715623,\n",
    "            max_depth=8,\n",
    "            reg_alpha=0.041545473,\n",
    "            reg_lambda=0.0735294,\n",
    "            min_split_gain=0.0222415,\n",
    "            min_child_weight=39.3259775,\n",
    "            silent=-1,\n",
    "            verbose=-1,\n",
    "        )\n",
    "\n",
    "        clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], \n",
    "            eval_metric=\"auc\", verbose=200, early_stopping_rounds=200)\n",
    "\n",
    "        oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration=clf.best_iteration_)[:, 1]\n",
    "        sub_preds += clf.predict_proba(test_df[feats], num_iteration=clf.best_iteration_)[:, 1] / folds.n_splits\n",
    "\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = feats\n",
    "        fold_importance_df[\"importance\"] = clf.feature_importances_\n",
    "        fold_importance_df[\"fold\"] = n_fold + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "        print(\"Fold %2d AUC : %.6f\" % (n_fold + 1, roc_auc_score(valid_y, oof_preds[valid_idx])))\n",
    "        del clf, train_x, train_y, valid_x, valid_y\n",
    "        gc.collect()\n",
    "\n",
    "    print(\"Full AUC score %.6f\" % roc_auc_score(train_df[\"TARGET\"], oof_preds))\n",
    "    # Write submission file and plot feature importance\n",
    "    if not debug:\n",
    "        test_df[\"TARGET\"] = sub_preds\n",
    "        test_df[[\"SK_ID_CURR\", \"TARGET\"]].to_csv(submission_file_name, index=False)\n",
    "    display_importances(feature_importance_df)\n",
    "    return feature_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display/plot feature importance\n",
    "def display_importances(feature_importance_df_):\n",
    "    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\")\\\n",
    "           .mean().sort_values(by=\"importance\", ascending=False)[:40].index\n",
    "    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n",
    "    plt.figure(figsize=(8, 10))\n",
    "    sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "    plt.title(\"LightGBM Features (avg over folds)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"lgbm_importances01.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(debug=False):\n",
    "    num_rows = 1000 if debug else None\n",
    "#    mini = 0 if debug else non sinon il est jamais full le df\n",
    "#    if debug: mini = 0 En fait même celui-ci ne fontionne pas car lors de la\n",
    "#    def des fcts mini valait 1 et lors le l'appel des fcts soit le \"if mini\"\n",
    "#    ne sera pas lu car il a déjà été évalué lors du def ou alors le \"if mini\"\n",
    "#    est lu mais ne regarde pas la valeur actuelle de mini seulement celle qui\n",
    "#    était active lors du def. Je ne sais pas exactement mais le résultat est\n",
    "#    que c'est trop tard ici pour dire \"mini = 0\".\n",
    "    df = application_train_test(num_rows)\n",
    "    print(\"Application train test df shape:\", df.shape)\n",
    "#    print(df.dtypes.value_counts())\n",
    "    with timer(\"Process bureau and bureau_balance\"):\n",
    "        bureau = bureau_and_balance(num_rows)\n",
    "        print(\"Bureau df shape:\", bureau.shape)\n",
    "        df = df.join(bureau, how=\"left\", on=\"SK_ID_CURR\")\n",
    "#        print(df.dtypes.value_counts())\n",
    "        del bureau\n",
    "        gc.collect()\n",
    "    with timer(\"Process previous_applications\"):\n",
    "        prev = previous_applications(num_rows)\n",
    "        print(\"Previous applications df shape:\", prev.shape)\n",
    "        df = df.join(prev, how=\"left\", on=\"SK_ID_CURR\")\n",
    "#        print(df.dtypes.value_counts())\n",
    "        del prev\n",
    "        gc.collect()\n",
    "    with timer(\"Process POS-CASH balance\"):\n",
    "        pos = pos_cash(num_rows)\n",
    "        print(\"Pos-cash balance df shape:\", pos.shape)\n",
    "        df = df.join(pos, how=\"left\", on=\"SK_ID_CURR\")\n",
    "#        print(df.dtypes.value_counts())\n",
    "        del pos\n",
    "        gc.collect()\n",
    "    with timer(\"Process installments payments\"):\n",
    "        ins = installments_payments(num_rows)\n",
    "        print(\"Installments payments df shape:\", ins.shape)\n",
    "        df = df.join(ins, how=\"left\", on=\"SK_ID_CURR\")\n",
    "#        print(df.dtypes.value_counts())\n",
    "        del ins\n",
    "        gc.collect()\n",
    "    with timer(\"Process credit card balance\"):\n",
    "        cc = credit_card_balance(num_rows)\n",
    "        print(\"Credit card balance df shape:\", cc.shape)\n",
    "        df = df.join(cc, how=\"left\", on=\"SK_ID_CURR\")\n",
    "#        print(df.dtypes.value_counts())\n",
    "        del cc\n",
    "        gc.collect()\n",
    "#    with timer(\"Run LightGBM with kfold\"):\n",
    "#        feat_importance = kfold_lightgbm(df, num_folds=10, stratified=False, debug=debug)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1234567890123456789012345678901234567890123456789012345678901234567890123456789"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1234567890123456789012345678901234567890123456789012345678901234567890123456789"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Run the preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. A first full run just to measure the target imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo\n",
    "# I ran this cell only once, just to get the exact values of zo and oz.\n",
    "if __name__ == \"__main__\":\n",
    "    submission_file_name = \"submission_kernel02.csv\"\n",
    "    with timer(\"Full model run\"):\n",
    "#        main()\n",
    "        df = main(debug=False)\n",
    "\n",
    "zeros_full = df.TARGET.value_counts(\n",
    "    sort=True,\n",
    "    ascending=False,\n",
    "    dropna=True,\n",
    ")[0]\n",
    "ones_full = df.TARGET.value_counts(\n",
    "    sort=True,\n",
    "    ascending=False,\n",
    "    dropna=True,\n",
    ")[1]\n",
    "nans_full = df.TARGET.isna().sum()\n",
    "print(\"TARGET has\",\n",
    "      f\"{zeros_full:10.0f} zeros,\",\n",
    "      f\"{ones_full:10.0f} ones and\",\n",
    "      f\"{nans_full:10.0f} NaNs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros_full, ones_full, nans_full = 282682, 24825, 48744"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is zo = 11.39 more zeros than ones in TARGET. (and oz = 0.09)\n"
     ]
    }
   ],
   "source": [
    "zo = zeros_full/ones_full\n",
    "oz = ones_full/zeros_full\n",
    "print(\"There is zo =\",\n",
    "      f\"{zo:.2f} more zeros than ones in TARGET. (and oz =\",\n",
    "      f\"{oz:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Subsampled run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1. kinda the original run code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo\n",
    "if __name__ == \"__main__\":\n",
    "    submission_file_name = \"submission_kernel02.csv\"\n",
    "    with timer(\"Full model run\"):\n",
    "#        main()\n",
    "        df = main(debug=True)\n",
    "\n",
    "zeros = df.TARGET.value_counts(\n",
    "    sort=True,\n",
    "    ascending=False,\n",
    "    dropna=True,\n",
    ")[0]\n",
    "ones = df.TARGET.value_counts(\n",
    "    sort=True,\n",
    "    ascending=False,\n",
    "    dropna=True,\n",
    ")[1]\n",
    "nans = df.TARGET.isna().sum()\n",
    "print(\"TARGET has\",\n",
    "      f\"{zeros:10.0f} zeros,\",\n",
    "      f\"{ones:10.0f} ones and\",\n",
    "      f\"{nans:10.0f} NaNs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2. An easier to debug version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 1000, test samples: 1000\n",
      "Application train test df shape: (2000, 235)\n",
      "Bureau df shape: (205, 99)\n",
      "Process bureau and bureau_balance - done in 0s\n",
      "Previous applications df shape: (985, 221)\n",
      "Process previous_applications - done in 0s\n",
      "Pos-cash balance df shape: (989, 12)\n",
      "Process POS-CASH balance - done in 0s\n",
      "Installments payments df shape: (965, 26)\n",
      "Process installments payments - done in 0s\n",
      "Credit card balance df shape: (1000, 116)\n",
      "Process credit card balance - done in 0s\n",
      "Full model run - done in 1s\n",
      "TARGET has        930 zeros,         70 ones and       1000 NaNs\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    submission_file_name = \"submission_kernel02.csv\"\n",
    "    with timer(\"Full model run\"):\n",
    "        debug = True\n",
    "        num_rows = 1000 if debug else None\n",
    "#        if debug: mini = 0\n",
    "        mini = 0 if debug else mini\n",
    "        df = application_train_test(num_rows)\n",
    "        print(\"Application train test df shape:\", df.shape)\n",
    "#        print(df.dtypes.value_counts())\n",
    "        with timer(\"Process bureau and bureau_balance\"):\n",
    "            bureau = bureau_and_balance(num_rows)\n",
    "            print(\"Bureau df shape:\", bureau.shape)\n",
    "            df = df.join(bureau, how=\"left\", on=\"SK_ID_CURR\")\n",
    "#            print(df.dtypes.value_counts())\n",
    "            del bureau\n",
    "            gc.collect()\n",
    "        with timer(\"Process previous_applications\"):\n",
    "            prev = previous_applications(num_rows)\n",
    "            print(\"Previous applications df shape:\", prev.shape)\n",
    "            df = df.join(prev, how=\"left\", on=\"SK_ID_CURR\")\n",
    "#            print(df.dtypes.value_counts())\n",
    "            del prev\n",
    "            gc.collect()\n",
    "        with timer(\"Process POS-CASH balance\"):\n",
    "            pos = pos_cash(num_rows)\n",
    "            print(\"Pos-cash balance df shape:\", pos.shape)\n",
    "            df = df.join(pos, how=\"left\", on=\"SK_ID_CURR\")\n",
    "#            print(df.dtypes.value_counts())\n",
    "            del pos\n",
    "            gc.collect()\n",
    "        with timer(\"Process installments payments\"):\n",
    "            ins = installments_payments(num_rows)\n",
    "            print(\"Installments payments df shape:\", ins.shape)\n",
    "            df = df.join(ins, how=\"left\", on=\"SK_ID_CURR\")\n",
    "#            print(df.dtypes.value_counts())\n",
    "            del ins\n",
    "            gc.collect()\n",
    "        with timer(\"Process credit card balance\"):\n",
    "            cc = credit_card_balance(num_rows)\n",
    "            print(\"Credit card balance df shape:\", cc.shape)\n",
    "            df = df.join(cc, how=\"left\", on=\"SK_ID_CURR\")\n",
    "#            print(df.dtypes.value_counts())\n",
    "            del cc\n",
    "            gc.collect()\n",
    "\n",
    "zeros = df.TARGET.value_counts(\n",
    "    sort=True,\n",
    "    ascending=False,\n",
    "    dropna=True,\n",
    ")[0]\n",
    "ones = df.TARGET.value_counts(\n",
    "    sort=True,\n",
    "    ascending=False,\n",
    "    dropna=True,\n",
    ")[1]\n",
    "nans = df.TARGET.isna().sum()\n",
    "print(\"TARGET has\",\n",
    "      f\"{zeros:10.0f} zeros,\",\n",
    "      f\"{ones:10.0f} ones and\",\n",
    "      f\"{nans:10.0f} NaNs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3. Measure of the target imbalance after the subsampling is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is zo_sub = 13.29 more zeros than ones in TARGET. (and oz_sub = 0.08)\n"
     ]
    }
   ],
   "source": [
    "zo_sub = zeros/ones\n",
    "oz_sub = ones/zeros\n",
    "print(\"There is zo_sub =\",\n",
    "      f\"{zo_sub:.2f} more zeros than ones in TARGET. (and oz_sub =\",\n",
    "      f\"{oz_sub:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'imbalance de 11.39 des targets du dataset est de 13.29 après subsampling.\n"
     ]
    }
   ],
   "source": [
    "if (zo/zo_sub >= 3/2 or zo/zo_sub <= 2/3):\n",
    "    for _ in range(8):\n",
    "        print(\"!\")\n",
    "    print(\n",
    "        \"L'imbalance des targets a été fortement modifiée par le subsampling.\",\n",
    "        f\"Elle est passée de {zo:.2f} à {zo_sub:.2f}.\",\n",
    "    )\n",
    "    for _ in range(8):\n",
    "        print(\"!\")\n",
    "else:\n",
    "    print(\n",
    "        f\"L'imbalance de {zo:.2f} des targets du dataset est de {zo_sub:.2f}\",\n",
    "        \"après subsampling.\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1234567890123456789012345678901234567890123456789012345678901234567890123456789"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1234567890123456789012345678901234567890123456789012345678901234567890123456789"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Tentatives infructueuses de sauvegarde du dataset nettoyé dans Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"df_agg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"../input/df_agg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"../df_agg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"../working/df_agg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.read_csv('../df_agg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipped\n",
    "df = pd.read_csv(\"df_agg.csv\")\n",
    "print(df.shape)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipped\n",
    "for dirname, _, filenames in os.walk(\"..\"):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipped\n",
    "for dirname, _, filenames in os.walk(\"/kaggle\"):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Suppression du caractère illisible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_of_df = list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipped\n",
    "# Ce code prend un temps infini à run. Prende la cell en-dessous.\n",
    "for j in cols_of_df:\n",
    "    df = df.rename(columns={j: re.sub(r\"[ ]\", r\"_a_\", j)})\n",
    "    df = df.rename(columns={j: re.sub(r\"[-]\", r\"_b_\", j)})\n",
    "    df = df.rename(columns={j: re.sub(r\"[:]\", r\"_c_\", j)})\n",
    "    df = df.rename(columns={j: re.sub(r\"[/]\", r\"_d_\", j)})\n",
    "    df = df.rename(columns={j: re.sub(r\"[,]\", r\"_e_\", j)})\n",
    "    df = df.rename(columns={j: re.sub(r\"[:]\", r\"_f_\", j)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipped\n",
    "df = df.rename(columns=lambda x: x.replace(\" \", \"_a_\")\\\n",
    "                                  .replace(\"-\", \"_b_\")\\\n",
    "                                  .replace(\":\", \"_c_\")\\\n",
    "                                  .replace(\"/\", \"_d_\")\\\n",
    "                                  .replace(\",\", \"_e_\")\\\n",
    "                                  .replace(\":\", \"_f_\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns=lambda x: x.replace(\":\", \"_f_\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Classification run from the original notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipped\n",
    "with timer(\"Run LightGBM with kfold\"):\n",
    "    feat_importance = kfold_lightgbm(df, num_folds=10, stratified=False, debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.0. Suppression des données sans TARGET\n",
    "En effet mon but ici c'est juste de créer un modèle qui fonctionne, faire les\n",
    " prédictions de solvabilité des futurs clients ça sera pour plus tard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"TARGET\"].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1. train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"TARGET\", axis=\"columns\")\n",
    "y = df[\"TARGET\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    742\n",
       "1.0     58\n",
       "Name: TARGET, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2. SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_old = X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "X_train_i = imputer.fit_transform(X_train)\n",
    "X_test = imputer.fit_transform(X_test_old)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3. Balancing the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipped\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "undersampler = RandomUnderSampler(sampling_strategy=\"majority\")\n",
    "X_train_u, y_train_u = undersampler.fit_resample(X_train_i, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "#oversampler = RandomOverSampler(sampling_strategy='minority')\n",
    "oversampler = SMOTE()\n",
    "X_train_o, y_train_o = oversampler.fit_resample(X_train_i, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.4. Declaring the classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo Cette approche ne permet pas le SearchCV multi-estimateurs\n",
    "classifiers = {\n",
    "    \"dummy\": DummyClassifier(),\n",
    "    \"naive_bayes\": GaussianNB(),\n",
    "    \"sgd\": SGDClassifier(),\n",
    "    \"knn\": KNeighborsClassifier(),\n",
    "    \"svc\": SVC(),\n",
    "    \"random_forest\": RandomForestClassifier(),\n",
    "    \"xgb\": XGBClassifier(),\n",
    "    \"catboost\": CatBoostClassifier(),\n",
    "    \"adaboost\": AdaBoostClassifier(),\n",
    "    \"lightgbm\": LGBMClassifier(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo\n",
    "# Ça me plaît davantage comme ça mais ça pourrait bloquer le fonctionnement du\n",
    "# SearchCV si je ne range pas chaque classifier dans un objet (?)\n",
    "classifiers = []\n",
    "classifiers.append(DummyClassifier())\n",
    "classifiers.append(LogisticRegression(random_state=42))\n",
    "classifiers.append(SGDClassifier())\n",
    "classifiers.append(GaussianNB())\n",
    "classifiers.append(MultinomialNB())\n",
    "classifiers.append(KNeighborsClassifier())\n",
    "classifiers.append(SVC(probability=True, random_state=42))\n",
    "classifiers.append(DecisionTreeClassifier(random_state=42))\n",
    "classifiers.append(RandomForestClassifier(random_state=42))\n",
    "classifiers.append(GradientBoostingClassifier(random_state=42))\n",
    "classifiers.append(AdaBoostClassifier(random_state=42))\n",
    "classifiers.append(XGBClassifier(random_state=42))\n",
    "classifiers.append(CatBoostClassifier(random_state=42))\n",
    "classifiers.append(LGBMClassifier(random_state=42))\n",
    "#classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pas très joli mais ça fonctionne.\n",
    "clf0 = DummyClassifier()\n",
    "clf1 = LogisticRegression(random_state=42)\n",
    "clf2 = SGDClassifier()\n",
    "clf3 = GaussianNB()\n",
    "clf4 = MultinomialNB()\n",
    "clf5 = KNeighborsClassifier()\n",
    "clf6 = SVC(probability=True, random_state=42)\n",
    "clf7 = DecisionTreeClassifier(random_state=42)\n",
    "clf8 = RandomForestClassifier(random_state=42)\n",
    "clf9 = GradientBoostingClassifier(random_state=42)\n",
    "clf10 = AdaBoostClassifier(random_state=42)\n",
    "clf11 = XGBClassifier(random_state=42)\n",
    "clf12 = CatBoostClassifier(random_state=42)\n",
    "clf13 = LGBMClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.5. Declaring the classifiers' parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 8.5.0. DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "param0 = {}\n",
    "param0[\"classifier__strategy\"] = [\"most_frequent\",\n",
    "                                  \"prior\"]\n",
    "param0[\"classifier\"] = [clf0]\n",
    "#param0[\"classifier\"] = [classifiers[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 8.5.1. LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "param1 = {}\n",
    "param1[\"classifier__C\"] = [10**-2,\n",
    "                           10**-1,\n",
    "                           10**0,\n",
    "                           10**1,\n",
    "                           10**2]\n",
    "param1[\"classifier__penalty\"] = [\"l1\",\n",
    "                                 \"l2\",\n",
    "                                 \"elasticnet\"]\n",
    "#param1[\"classifier__class_weight\"] = [{0: 1, 1: 1},\n",
    "#                                         {0: oz, 1: zo}]\n",
    "#param1[\"classifier__class_weight\"] = [None]\n",
    "param1[\"classifier__class_weight\"] = [None,\n",
    "                                      {0: oz, 1: zo}]\n",
    "# J'ai déjà fait un oversampling donc normalement je n'ai plus besoin de mettre\n",
    "# les poids. Je teste juste ici.\n",
    "param1[\"classifier\"] = [clf1]\n",
    "#param1[\"classifier\"] = [classifiers[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 8.5.2. SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "param2 = {}\n",
    "param2[\"classifier__loss\"] = [\"hinge\",\n",
    "                              \"log\",\n",
    "                              \"squared_hinge\",\n",
    "                              \"modified_huber\"]\n",
    "param2[\"classifier__penalty\"] = [\"l2\",\n",
    "                                 \"l1\",\n",
    "                                 \"elasticnet\"]\n",
    "param2[\"classifier\"] = [clf2]\n",
    "#param2[\"classifier\"] = [classifiers[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 8.5.3. GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "param3 = {}\n",
    "param3[\"classifier\"] = [clf3]\n",
    "#param3[\"classifier\"] = [classifiers[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 8.5.4. MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "param4 = {}\n",
    "param4[\"classifier__alpha\"] = [10**0,\n",
    "                               10**1,\n",
    "                               10**2]\n",
    "param4[\"classifier\"] = [clf4]\n",
    "#param4[\"classifier\"] = [classifiers[4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 8.5.5. KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "param5 = {}\n",
    "param5[\"classifier__n_neighbors\"] = [10**.5,\n",
    "                                     10**1,\n",
    "                                     10**1.5,\n",
    "                                     10**2]\n",
    "param5[\"classifier__weights\"] = [\"uniform\",\n",
    "                                 \"distance\"]\n",
    "param5[\"classifier\"] = [clf5]\n",
    "#param5[\"classifier\"] = [classifiers[5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 8.5.6. SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "param6 = {}\n",
    "param6[\"classifier__kernel\"] = [\"linear\",\n",
    "                                \"rbf\",\n",
    "                                \"poly\",\n",
    "                                \"sigmoid\"]\n",
    "param6[\"classifier__C\"] = [10**-2,\n",
    "                           10**-1,\n",
    "                           10**0,\n",
    "                           10**1,\n",
    "                           10**2,\n",
    "                           10**3]\n",
    "param6[\"classifier__gamma\"] = [\"auto\",\n",
    "                               \"scale\"]\n",
    "#param6[\"classifier__class_weight\"] = [None,\n",
    "#                                         {0: oz, 1: zo}]\n",
    "# J'ai déjà fait un oversampling donc plus besoin de mettre les poids.\n",
    "param6[\"classifier__class_weight\"] = [None]\n",
    "param6[\"classifier\"] = [clf6]\n",
    "#param6[\"classifier\"] = [classifiers[6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 8.5.7. DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "param7 = {}\n",
    "param7[\"classifier__max_depth\"] = [3,\n",
    "                                   10**1,\n",
    "                                   30,\n",
    "                                   None]\n",
    "param7[\"classifier__min_samples_split\"] = [10**.5,\n",
    "                                           10**1]\n",
    "#param7[\"classifier__class_weight\"] = [{0: oz, 1: zo}]\n",
    "# J'ai déjà fait un oversampling donc plus besoin de mettre les poids.\n",
    "param7[\"classifier__class_weight\"] = [None]\n",
    "param7[\"classifier\"] = [clf7]\n",
    "#param7[\"classifier\"] = [classifiers[7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 8.5.8. RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "param8 = {}\n",
    "param8[\"classifier__n_estimators\"] = [10**1,\n",
    "                                      10**2,\n",
    "                                      10**3]\n",
    "param8[\"classifier__max_depth\"] = [3,\n",
    "                                   10**1,\n",
    "                                   30]\n",
    "param8[\"classifier__criterion\"] = [\"gini\",\n",
    "                                   \"entropy\"]\n",
    "#param8[\"classifier__class_weight\"] = [None,\n",
    "#                                         {0: oz, 1: zo}]\n",
    "# J'ai déjà fait un oversampling donc plus besoin de mettre les poids.\n",
    "param8[\"classifier__class_weight\"] = [None]\n",
    "param8[\"classifier\"] = [clf8]\n",
    "#param8[\"classifier\"] = [classifiers[8]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 8.5.9. GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "param9 = {}\n",
    "param9[\"classifier__n_estimators\"] = [10**1,\n",
    "                                      10**2,\n",
    "                                      10**3]\n",
    "param9[\"classifier__max_depth\"] = [3,\n",
    "                                   10**1,\n",
    "                                   30]\n",
    "param9[\"classifier\"] = [clf9]\n",
    "#param9[\"classifier\"] = [classifiers[9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 8.5.10. AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "param10 = {}\n",
    "param10[\"classifier__n_estimators\"] = [10**1,\n",
    "                                       10**2,\n",
    "                                       10**3]\n",
    "param10[\"classifier__learning_rate\"] = [10**-3,\n",
    "                                        10**-2,\n",
    "                                        10**-1]\n",
    "param10[\"classifier\"] = [clf10]\n",
    "#param10[\"classifier\"] = [classifiers[10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 8.5.11. XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "param11 = {}\n",
    "param11[\"classifier__booster\"] = [\"gbtree\",\n",
    "                                  \"gblinear\",\n",
    "                                  \"dart\"]\n",
    "param11[\"classifier__learning_rate\"] = [10**-3,\n",
    "                                        10**-2,\n",
    "                                        10**-1]\n",
    "param11[\"classifier__max_depth\"] = [10**0,\n",
    "                                    3,\n",
    "                                    10**1]\n",
    "param11[\"classifier\"] = [clf11]\n",
    "#param11[\"classifier\"] = [classifiers[11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 8.5.12. CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "param12 = {}\n",
    "param12[\"classifier__iterations\"] = [10**1,\n",
    "                                     10**2,\n",
    "                                     10**3]\n",
    "param12[\"classifier__learning_rate\"] = [10**-3,\n",
    "                                        10**-2,\n",
    "                                        10**-1]\n",
    "param12[\"classifier__depth\"] = [10**0,\n",
    "                                3,\n",
    "                                10**1]\n",
    "param12[\"classifier\"] = [clf12]\n",
    "#param12[\"classifier\"] = [classifiers[12]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5.13. LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "param13 = {}\n",
    "param13[\"classifier__boosting_type\"] = [\"gbdt\",\n",
    "                                        \"dart\",\n",
    "                                        \"goss\"]\n",
    "param13[\"classifier__learning_rate\"] = [10**-3,\n",
    "                                        10**-2,\n",
    "                                        10**-1]\n",
    "param13[\"classifier__num_leaves\"] = [10**1,\n",
    "                                     10**1.5,\n",
    "                                     10**2]\n",
    "param13[\"classifier\"] = [clf13]\n",
    "#param13[\"classifier\"] = [classifiers[13]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [\n",
    "#    DummyClassifier\n",
    "    param0,\n",
    "#    LogisticRegression\n",
    "#    param1,\n",
    "#    SGDClassifier\n",
    "#    param2,\n",
    "#    GaussianNB\n",
    "#    param3,\n",
    "#    MultinomialNB\n",
    "#    param4,\n",
    "#    KNeighborsClassifier\n",
    "    param5,\n",
    "#    SVC\n",
    "#    param6,\n",
    "#    DecisionTreeClassifier\n",
    "#    param7,\n",
    "#    RandomForestClassifier\n",
    "    param8,\n",
    "#    GradientBoostingClassifier\n",
    "#    param9,\n",
    "#    AdaBoostClassifier\n",
    "#    param10,\n",
    "#    XGBClassifier\n",
    "    param11,\n",
    "#    CatBoostClassifier\n",
    "#    param12,\n",
    "#    LGBMClassifier\n",
    "#    param13,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 8.5.14. Déclaration des paramètres sous la forme d'un dictionnaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo\n",
    "# J\"aurais préféré input comme ceci mais il faut toujours exactement le keyword\n",
    "# \"classifier\" pour que le SearchCV multi-estimateur fonctionne et donc je ne\n",
    "# peux pas utiliser un dictionnaire pour ça.\n",
    "param_distributions = {\n",
    "    \"dummy\": {\"class_weight\": [{0: 1, 1: 1}, {0: oz, 1: zo}]},\n",
    "    \"sgd\": {\"loss\": [\"hinge\", \"log\", \"squared_hinge\", \"modified_huber\"],\n",
    "            \"penalty\": [\"l2\", \"l1\", \"elasticnet\"],\n",
    "            \"class_weight\": [{0: oz, 1: zo}]},\n",
    "    \"naive_bayes\": {\"class_weight\": [{0: oz, 1: zo}]},\n",
    "    \"knn\": {\"n_neighbors\": range(1, 11),\n",
    "            \"weights\": [\"uniform\", \"distance\"],\n",
    "            \"class_weight\": [{0: oz, 1: zo}]},\n",
    "    \"svc\": {\"kernel\": [\"linear\", \"rbf\", \"poly\", \"sigmoid\"],\n",
    "            \"C\": [0.1, 1, 10, 100, 1000],\n",
    "            \"gamma\": [\"auto\", \"scale\"],\n",
    "            \"class_weight\": [{0: oz, 1: zo}]},\n",
    "    \"random_forest\": {\"n_estimators\": [10, 100, 1000],\n",
    "                      \"criterion\": [\"gini\", \"entropy\"],\n",
    "                      \"class_weight\": [{0: oz, 1: zo}]},\n",
    "    \"adaboost\": {\"n_estimators\": [10, 100, 1000],\n",
    "                 \"learning_rate\": [0.1, 0.01, 0.001],\n",
    "                 \"class_weight\": [{0: oz, 1: zo}]},\n",
    "    \"xgb\": {\"booster\": [\"gbtree\", \"gblinear\", \"dart\"],\n",
    "            \"learning_rate\": [0.1, 0.01, 0.001],\n",
    "            \"max_depth\": range(1, 11),\n",
    "            \"class_weight\": [{0: oz, 1: zo}]},\n",
    "    \"catboost\": {\"iterations\": [10, 100, 1000],\n",
    "                 \"learning_rate\": [0.1, 0.01, 0.001],\n",
    "                 \"depth\": range(1, 11),\n",
    "                 \"class_weight\": [{0: oz, 1: zo}]},\n",
    "    \"lightgbm\": {\"boosting_type\": [\"gbdt\", \"dart\", \"goss\"],\n",
    "                 \"learning_rate\": [0.1, 0.01, 0.001],\n",
    "                 \"num_leaves\": range(10, 110, 10),\n",
    "                 \"class_weight\": [{0: oz, 1: zo}]},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo\n",
    "param_distributions = {\n",
    "    \"dummy\": {},\n",
    "    \"naive_bayes\": {},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.6. Tentative infructueuse d'itérer sur les classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo\n",
    "# Non. Pipeline ne fonctionne pas du tout comme ça.\n",
    "pipe = Pipeline(steps=[(name, estimator) for name, estimator in classifiers.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo\n",
    "# Non. Pipeline ne fonctionne pas comme ça non plus. Elle ne prend qu'un seul\n",
    "# estimateur à la fois.\n",
    "# Peut-être cependant qu'en mettant en bout de pipe un columntransformer qui\n",
    "# définit tous les estimateurs en parallèle ça pourrait fonctionner mais j'y\n",
    "# crois peu.\n",
    "rs_cv = RandomizedSearchCV(estimator=Pipeline(classifiers),\n",
    "                           param_distributions=param_distributions,\n",
    "                           n_iter=10,\n",
    "                           cv=5,\n",
    "                           scoring=[\"roc_auc\", \"accuracy\"],\n",
    "                           refit=\"roc_auc\",\n",
    "                           random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo\n",
    "#rs_cv.fit(X_train, y_train)\n",
    "#rs_cv.fit(X_train_u, y_train_u)\n",
    "rs_cv.fit(X_train_o, y_train_o)\n",
    "\n",
    "for algorithm in classifiers.keys():\n",
    "    print(f\"Best parameters for {algorithm}: {rs_cv.best_params_[algorithm]}\")\n",
    "    print(f\"Best AUC score for {algorithm}: {rs_cv.best_score_[algorithm]['roc_auc']:.3f}\")\n",
    "    print(f\"Best accuracy score for {algorithm}: {rs_cv.best_score_[algorithm]['accuracy']:.3f}\")\n",
    "\n",
    "#best_algorithm = rs_cv.best_estimator_.keys()[0]\n",
    "best_algorithm = rs_cv.best_estimator_.named_steps.keys()\n",
    "print(f\"Overall best algorithm: {best_algorithm}\")\n",
    "print(f\"Best AUC score: {rs_cv.best_score_[best_algorithm]['roc_auc']:.3f}\")\n",
    "print(f\"Best accuracy score: {rs_cv.best_score_[best_algorithm]['accuracy']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.7. Itération sur les classifiers avec une méthode étrange\n",
    "En fait ici on ne donne au SearchCV qu'une seule pipe de travail ne contenant\n",
    "qu'un seul estimateur, mais il va quand même itérer sur tous les classifiers\n",
    "car ils sont tous renseignés dans ```params```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([(\"classifier\", clf0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3.47 s\n",
      "Wall time: 11.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rs = RandomizedSearchCV(\n",
    "    pipeline,\n",
    "    params,\n",
    "    n_iter=5,\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    scoring=\"roc_auc\"\n",
    "#).fit(X_train, y_train)\n",
    "#).fit(X_train_u, y_train_u)\n",
    ").fit(X_train_o, y_train_o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.8. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__max_depth': 3,\n",
       " 'classifier__learning_rate': 0.1,\n",
       " 'classifier__booster': 'gbtree',\n",
       " 'classifier': XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
       "               colsample_bylevel=None, colsample_bynode=None,\n",
       "               colsample_bytree=None, early_stopping_rounds=None,\n",
       "               enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "               gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "               interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "               max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "               max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "               min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "               n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "               predictor=None, random_state=42, ...)}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9880773363774814"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    188\n",
       "1.0     12\n",
       "Name: TARGET, dtype: int64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Feature shape mismatch, expected: 644, got 270",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [106]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrecision:\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m----> 2\u001b[0m       precision_score(\u001b[43mrs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m, y_test))\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecall:\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      4\u001b[0m       recall_score(rs\u001b[38;5;241m.\u001b[39mpredict(X_test), y_test))\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mROC AUC Score:\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      6\u001b[0m       roc_auc_score(rs\u001b[38;5;241m.\u001b[39mpredict(X_test), y_test))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py:113\u001b[0m, in \u001b[0;36m_AvailableIfDescriptor.__get__.<locals>.<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m attr_err\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;66;03m# lambda, but not partial, allows help() to work with update_wrapper\u001b[39;00m\n\u001b[1;32m--> 113\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn(obj, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:521\u001b[0m, in \u001b[0;36mBaseSearchCV.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    503\u001b[0m \u001b[38;5;124;03m\"\"\"Call predict on the estimator with the best found parameters.\u001b[39;00m\n\u001b[0;32m    504\u001b[0m \n\u001b[0;32m    505\u001b[0m \u001b[38;5;124;03mOnly available if ``refit=True`` and the underlying estimator supports\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    518\u001b[0m \u001b[38;5;124;03m    the best found parameters.\u001b[39;00m\n\u001b[0;32m    519\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    520\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 521\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_estimator_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py:113\u001b[0m, in \u001b[0;36m_AvailableIfDescriptor.__get__.<locals>.<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m attr_err\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;66;03m# lambda, but not partial, allows help() to work with update_wrapper\u001b[39;00m\n\u001b[1;32m--> 113\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn(obj, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:470\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[1;34m(self, X, **predict_params)\u001b[0m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(with_final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    469\u001b[0m     Xt \u001b[38;5;241m=\u001b[39m transform\u001b[38;5;241m.\u001b[39mtransform(Xt)\n\u001b[1;32m--> 470\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpredict(Xt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpredict_params)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1551\u001b[0m, in \u001b[0;36mXGBClassifier.predict\u001b[1;34m(self, X, output_margin, ntree_limit, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[0;32m   1541\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\n\u001b[0;32m   1542\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1543\u001b[0m     X: ArrayLike,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1548\u001b[0m     iteration_range: Optional[Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1549\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m   1550\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbosity):\n\u001b[1;32m-> 1551\u001b[0m         class_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1552\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1553\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1554\u001b[0m \u001b[43m            \u001b[49m\u001b[43mntree_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mntree_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1555\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1556\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1557\u001b[0m \u001b[43m            \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1558\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1559\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m output_margin:\n\u001b[0;32m   1560\u001b[0m             \u001b[38;5;66;03m# If output_margin is active, simply return the scores\u001b[39;00m\n\u001b[0;32m   1561\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m class_probs\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1140\u001b[0m, in \u001b[0;36mXGBModel.predict\u001b[1;34m(self, X, output_margin, ntree_limit, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[0;32m   1138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_can_use_inplace_predict():\n\u001b[0;32m   1139\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1140\u001b[0m         predts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_booster\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace_predict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1142\u001b[0m \u001b[43m            \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpredict_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmargin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1144\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1145\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1146\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1147\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1148\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m _is_cupy_array(predts):\n\u001b[0;32m   1149\u001b[0m             \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcupy\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=import-error\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py:2268\u001b[0m, in \u001b[0;36mBooster.inplace_predict\u001b[1;34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001b[0m\n\u001b[0;32m   2264\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   2265\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`shape` attribute is required when `validate_features` is True.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2266\u001b[0m         )\n\u001b[0;32m   2267\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_features() \u001b[38;5;241m!=\u001b[39m data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m-> 2268\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2269\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature shape mismatch, expected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_features()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2270\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2271\u001b[0m         )\n\u001b[0;32m   2273\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m   2274\u001b[0m     _array_interface,\n\u001b[0;32m   2275\u001b[0m     _is_cudf_df,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2278\u001b[0m     _transform_pandas_df,\n\u001b[0;32m   2279\u001b[0m )\n\u001b[0;32m   2281\u001b[0m enable_categorical \u001b[38;5;241m=\u001b[39m _has_categorical(\u001b[38;5;28mself\u001b[39m, data)\n",
      "\u001b[1;31mValueError\u001b[0m: Feature shape mismatch, expected: 644, got 270"
     ]
    }
   ],
   "source": [
    "print(\"Precision:\",\n",
    "      precision_score(rs.predict(X_test), y_test))\n",
    "print(\"Recall:\",\n",
    "      recall_score(rs.predict(X_test), y_test))\n",
    "print(\"ROC AUC Score:\",\n",
    "      roc_auc_score(rs.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Fine tuning with the best classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1. GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.2. Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Applying the fine-tuned best classifier for the final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#y_pred = rs_cv.best_estimator_[best_algorithm].predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Features' importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.1. SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.2. LIME"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
