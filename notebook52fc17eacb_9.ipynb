{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kaggle/python Docker image: https://github.com/kaggle/docker-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. (most) package imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "from contextlib import contextmanager\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\", 20, \"display.max_columns\", 30)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "import imblearn.pipeline\n",
    "#from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import precision_score, recall_score, fbeta_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, confusion_matrix\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "#from sklearn.utils.testing import ignore_warnings # For LogisticRegression\n",
    "#from sklearn.exceptions import ConvergenceWarning # For LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "offline = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Global functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(title):\n",
    "    t0 = time.perf_counter()\n",
    "    yield\n",
    "    print(\"{} - done in {:.0f}s\".format(title, time.perf_counter() - t0))\n",
    "\n",
    "def one_hot_encoder(df, nan_as_category=True):\n",
    "    original_columns = list(df.columns)\n",
    "    categorical_columns = [col for col in df.columns if df[col].dtype == \"object\"]\n",
    "    df = pd.get_dummies(df, columns=categorical_columns, dummy_na=nan_as_category)\n",
    "    new_columns = [c for c in df.columns if c not in original_columns]\n",
    "    return df, new_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Dataset overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "offline j'ai:\n",
    "\n",
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">filenames = [\n",
    "    \"home-credit-default-risk/application_test.csv\",\n",
    "    \"home-credit-default-risk/application_train.csv\",\n",
    "    \"home-credit-default-risk/bureau.csv\",\n",
    "    \"home-credit-default-risk/bureau_balance.csv\",\n",
    "    \"home-credit-default-risk/credit_card_balance.csv\",\n",
    "    \"home-credit-default-risk/installments_payments.csv\",\n",
    "    \"home-credit-default-risk/POS_CASH_balance.csv\",\n",
    "    \"home-credit-default-risk/previous_application.csv\",\n",
    "    \"home-credit-default-risk/sample_submission.csv\"\n",
    "    ]\n",
    "</code>\n",
    "</p>\n",
    "\n",
    "not offline (on Kaggle) j'ai:\n",
    "\n",
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">filenames = [\n",
    "    \"/kaggle/input/home-credit-default-risk/sample_submission.csv\",\n",
    "    \"/kaggle/input/home-credit-default-risk/bureau_balance.csv\",\n",
    "    \"/kaggle/input/home-credit-default-risk/POS_CASH_balance.csv\",\n",
    "    \"/kaggle/input/home-credit-default-risk/application_train.csv\",\n",
    "    \"/kaggle/input/home-credit-default-risk/application_test.csv\",\n",
    "    \"/kaggle/input/home-credit-default-risk/previous_application.csv\",\n",
    "    \"/kaggle/input/home-credit-default-risk/credit_card_balance.csv\",\n",
    "    \"/kaggle/input/home-credit-default-risk/installments_payments.csv\",\n",
    "    \"/kaggle/input/home-credit-default-risk/bureau.csv\"]\n",
    "    ]\n",
    "</code>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if offline:\n",
    "    le_path = \"home-credit-default-risk/\"\n",
    "else:\n",
    "    le_path = \"/kaggle/input\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = []\n",
    "for dirname, _, filenamess in os.walk(le_path):\n",
    "    for filenamee in filenamess:\n",
    "#                        HomeCredit_columns_description.csv est illisible.\n",
    "        if filenamee != \"HomeCredit_columns_description.csv\":\n",
    "            filename = os.path.join(dirname, filenamee)\n",
    "#            print(filename)\n",
    "            filenames.append(filename)\n",
    "#            df = pd.read_csv(filename)\n",
    "#            display(df[-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not offline:\n",
    "    flnms = []\n",
    "    flnms.append(filenames[4])\n",
    "    flnms.append(filenames[3])\n",
    "    flnms.append(filenames[8])\n",
    "    flnms.append(filenames[1])\n",
    "    flnms.append(filenames[6])\n",
    "    flnms.append(filenames[7])\n",
    "    flnms.append(filenames[2])\n",
    "    flnms.append(filenames[5])\n",
    "    flnms.append(filenames[0])\n",
    "    filenames = flnms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. application_train and application_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def application_train_test(num_rows=None, nan_as_category=False):\n",
    "    df = pd.read_csv(filenames[1], nrows=num_rows)\n",
    "    test_df = pd.read_csv(filenames[0], nrows=num_rows)\n",
    "    print(\"Train samples: {}, test samples: {}\".format(len(df), len(test_df)))\n",
    "    df = df.append(test_df).reset_index()\n",
    "\n",
    "    # Optional: Remove 4 applications with XNA CODE_GENDER (train set)\n",
    "    df = df[df[\"CODE_GENDER\"] != \"XNA\"]\n",
    "\n",
    "    # Categorical features with Binary encode (0 or 1; two categories)\n",
    "    for bin_feature in [\"CODE_GENDER\", \"FLAG_OWN_CAR\", \"FLAG_OWN_REALTY\"]:\n",
    "        df[bin_feature], uniques = pd.factorize(df[bin_feature])\n",
    "    # Categorical features with One-Hot encode\n",
    "    df, cat_cols = one_hot_encoder(df, nan_as_category)\n",
    "\n",
    "    # Aberrant values\n",
    "    df[\"DAYS_EMPLOYED\"].replace(365243, np.nan, inplace=True)\n",
    "\n",
    "    # Some simple new features (percentages)\n",
    "    df[\"DAYS_EMPLOYED_PERC\"] = df[\"DAYS_EMPLOYED\"] / df[\"DAYS_BIRTH\"]\n",
    "    df[\"INCOME_CREDIT_PERC\"] = df[\"AMT_INCOME_TOTAL\"] / df[\"AMT_CREDIT\"]\n",
    "    df[\"INCOME_PER_PERSON\"] = df[\"AMT_INCOME_TOTAL\"] / df[\"CNT_FAM_MEMBERS\"]\n",
    "    df[\"ANNUITY_INCOME_PERC\"] = df[\"AMT_ANNUITY\"] / df[\"AMT_INCOME_TOTAL\"]\n",
    "    df[\"PAYMENT_RATE\"] = df[\"AMT_ANNUITY\"] / df[\"AMT_CREDIT\"]\n",
    "\n",
    "    del test_df\n",
    "    gc.collect()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. bureau and bureau_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bureau_and_balance(num_rows=None, nan_as_category=True):\n",
    "    bureau = pd.read_csv(filenames[2], nrows=num_rows)\n",
    "    bb = pd.read_csv(filenames[3], nrows=num_rows)\n",
    "\n",
    "    bb, bb_cat = one_hot_encoder(bb, nan_as_category)\n",
    "    bureau, bureau_cat = one_hot_encoder(bureau, nan_as_category)\n",
    "\n",
    "    # Bureau balance: Perform aggregations and merge with bureau.csv\n",
    "    bb_aggregations = {\"MONTHS_BALANCE\": [\"min\", \"max\", \"size\"]}\n",
    "    for col in bb_cat:\n",
    "        bb_aggregations[col] = [\"mean\"]\n",
    "    bb_agg = bb.groupby(\"SK_ID_BUREAU\").agg(bb_aggregations)\n",
    "    bb_agg.columns = pd.Index(\n",
    "        [e[0] + \"_\" + e[1].upper() for e in bb_agg.columns.tolist()]\n",
    "    )\n",
    "    bureau = bureau.join(bb_agg, how=\"left\", on=\"SK_ID_BUREAU\")\n",
    "    bureau.drop([\"SK_ID_BUREAU\"], axis=1, inplace=True)\n",
    "    del bb, bb_agg\n",
    "    gc.collect()\n",
    "\n",
    "    # Bureau and bureau_balance numeric features\n",
    "    num_aggregations = {\n",
    "        \"DAYS_CREDIT\": [\"min\", \"max\", \"mean\", \"var\"],\n",
    "        \"DAYS_CREDIT_ENDDATE\": [\"min\", \"max\", \"mean\"],\n",
    "        \"DAYS_CREDIT_UPDATE\": [\"mean\"],\n",
    "        \"CREDIT_DAY_OVERDUE\": [\"max\", \"mean\"],\n",
    "        \"AMT_CREDIT_MAX_OVERDUE\": [\"mean\"],\n",
    "        \"AMT_CREDIT_SUM\": [\"max\", \"mean\", \"sum\"],\n",
    "        \"AMT_CREDIT_SUM_DEBT\": [\"max\", \"mean\", \"sum\"],\n",
    "        \"AMT_CREDIT_SUM_OVERDUE\": [\"mean\"],\n",
    "        \"AMT_CREDIT_SUM_LIMIT\": [\"mean\", \"sum\"],\n",
    "        \"AMT_ANNUITY\": [\"max\", \"mean\"],\n",
    "        \"CNT_CREDIT_PROLONG\": [\"sum\"],\n",
    "        \"MONTHS_BALANCE_MIN\": [\"min\"],\n",
    "        \"MONTHS_BALANCE_MAX\": [\"max\"],\n",
    "        \"MONTHS_BALANCE_SIZE\": [\"mean\", \"sum\"]\n",
    "    }\n",
    "\n",
    "    # Bureau and bureau_balance categorical features\n",
    "    cat_aggregations = {}\n",
    "    for cat in bureau_cat: cat_aggregations[cat] = [\"mean\"]\n",
    "    for cat in bb_cat: cat_aggregations[cat + \"_MEAN\"] = [\"mean\"]\n",
    "\n",
    "    bureau_agg = bureau.groupby(\"SK_ID_CURR\").agg(\n",
    "        {**num_aggregations, **cat_aggregations}\n",
    "    )\n",
    "    bureau_agg.columns = pd.Index([\n",
    "        \"BURO_\" + e[0] + \"_\" + e[1].upper() for e in bureau_agg.columns.tolist()\n",
    "    ])\n",
    "\n",
    "    # Bureau: Active credits - using only numerical aggregations\n",
    "    active = bureau[bureau[\"CREDIT_ACTIVE_Active\"] == 1]\n",
    "    active_agg = active.groupby(\"SK_ID_CURR\").agg(num_aggregations)\n",
    "    active_agg.columns = pd.Index([\n",
    "        \"ACTIVE_\" + e[0] + \"_\" + e[1].upper() for e in active_agg.columns.tolist()\n",
    "    ])\n",
    "    bureau_agg = bureau_agg.join(active_agg, how=\"left\", on=\"SK_ID_CURR\")\n",
    "    del active, active_agg\n",
    "    gc.collect()\n",
    "\n",
    "    # Bureau: Closed credits - using only numerical aggregations\n",
    "    closed = bureau[bureau[\"CREDIT_ACTIVE_Closed\"] == 1]\n",
    "    closed_agg = closed.groupby(\"SK_ID_CURR\").agg(num_aggregations)\n",
    "    closed_agg.columns = pd.Index([\n",
    "        \"CLOSED_\" + e[0] + \"_\" + e[1].upper() for e in closed_agg.columns.tolist()\n",
    "    ])\n",
    "    bureau_agg = bureau_agg.join(closed_agg, how=\"left\", on=\"SK_ID_CURR\")\n",
    "    del closed, closed_agg, bureau\n",
    "    gc.collect()\n",
    "\n",
    "    return bureau_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. previous_applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def previous_applications(num_rows=None, nan_as_category=True):\n",
    "    prev = pd.read_csv(filenames[7], nrows=num_rows)\n",
    "\n",
    "    prev, cat_cols = one_hot_encoder(prev, nan_as_category=True)\n",
    "\n",
    "    # Aberrant values\n",
    "    prev[\"DAYS_FIRST_DRAWING\"].replace(365243, np.nan, inplace=True)\n",
    "    prev[\"DAYS_FIRST_DUE\"].replace(365243, np.nan, inplace=True)\n",
    "    prev[\"DAYS_LAST_DUE_1ST_VERSION\"].replace(365243, np.nan, inplace=True)\n",
    "    prev[\"DAYS_LAST_DUE\"].replace(365243, np.nan, inplace=True)\n",
    "    prev[\"DAYS_TERMINATION\"].replace(365243, np.nan, inplace=True)\n",
    "\n",
    "    # Add feature: value ask / value received percentage\n",
    "    prev[\"APP_CREDIT_PERC\"] = prev[\"AMT_APPLICATION\"] / prev[\"AMT_CREDIT\"]\n",
    "\n",
    "    # Previous applications numeric features\n",
    "    num_aggregations = {\n",
    "        \"AMT_ANNUITY\": [\"min\", \"max\", \"mean\"],\n",
    "        \"AMT_APPLICATION\": [\"min\", \"max\", \"mean\"],\n",
    "        \"AMT_CREDIT\": [\"min\", \"max\", \"mean\"],\n",
    "        \"APP_CREDIT_PERC\": [\"min\", \"max\", \"mean\", \"var\"],\n",
    "        \"AMT_DOWN_PAYMENT\": [\"min\", \"max\", \"mean\"],\n",
    "        \"AMT_GOODS_PRICE\": [\"min\", \"max\", \"mean\"],\n",
    "        \"HOUR_APPR_PROCESS_START\": [\"min\", \"max\", \"mean\"],\n",
    "        \"RATE_DOWN_PAYMENT\": [\"min\", \"max\", \"mean\"],\n",
    "        \"DAYS_DECISION\": [\"min\", \"max\", \"mean\"],\n",
    "        \"CNT_PAYMENT\": [\"mean\", \"sum\"],\n",
    "    }\n",
    "\n",
    "    # Previous applications categorical features\n",
    "    cat_aggregations = {}\n",
    "    for cat in cat_cols:\n",
    "        cat_aggregations[cat] = [\"mean\"]\n",
    "\n",
    "    prev_agg = prev.groupby(\"SK_ID_CURR\").agg({**num_aggregations,\n",
    "                                               **cat_aggregations})\n",
    "    prev_agg.columns = pd.Index([\n",
    "        \"PREV_\" + e[0] + \"_\" + e[1].upper() for e in prev_agg.columns.tolist()\n",
    "    ])\n",
    "\n",
    "    # Previous Applications: Approved Applications - only numerical features\n",
    "    approved = prev[prev[\"NAME_CONTRACT_STATUS_Approved\"] == 1]\n",
    "    approved_agg = approved.groupby(\"SK_ID_CURR\").agg(num_aggregations)\n",
    "    approved_agg.columns = pd.Index([\n",
    "        \"APPROVED_\" + e[0] + \"_\" + e[1].upper() for e in approved_agg.columns.tolist()\n",
    "    ])\n",
    "    prev_agg = prev_agg.join(approved_agg, how=\"left\", on=\"SK_ID_CURR\")\n",
    "\n",
    "    # Previous Applications: Refused Applications - only numerical features\n",
    "    refused = prev[prev[\"NAME_CONTRACT_STATUS_Refused\"] == 1]\n",
    "    refused_agg = refused.groupby(\"SK_ID_CURR\").agg(num_aggregations)\n",
    "    refused_agg.columns = pd.Index([\n",
    "        \"REFUSED_\" + e[0] + \"_\" + e[1].upper() for e in refused_agg.columns.tolist()\n",
    "    ])\n",
    "    prev_agg = prev_agg.join(refused_agg, how=\"left\", on=\"SK_ID_CURR\")\n",
    "\n",
    "    del refused, refused_agg, approved, approved_agg, prev\n",
    "    gc.collect()\n",
    "    return prev_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. pos_cash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_cash(num_rows=None, nan_as_category=True):\n",
    "    pos = pd.read_csv(filenames[6], nrows=num_rows)\n",
    "\n",
    "    pos, cat_cols = one_hot_encoder(pos, nan_as_category=True)\n",
    "\n",
    "    # Features\n",
    "    aggregations = {\n",
    "        \"MONTHS_BALANCE\": [\"max\", \"mean\", \"size\"],\n",
    "        \"SK_DPD\": [\"max\", \"mean\"],\n",
    "        \"SK_DPD_DEF\": [\"max\", \"mean\"]\n",
    "    }\n",
    "    for cat in cat_cols:\n",
    "        aggregations[cat] = [\"mean\"]\n",
    "\n",
    "    pos_agg = pos.groupby(\"SK_ID_CURR\").agg(aggregations)\n",
    "    pos_agg.columns = pd.Index([\n",
    "        \"POS_\" + e[0] + \"_\" + e[1].upper() for e in pos_agg.columns.tolist()\n",
    "    ])\n",
    "\n",
    "    # Count pos cash accounts\n",
    "    pos_agg[\"POS_COUNT\"] = pos.groupby(\"SK_ID_CURR\").size()\n",
    "\n",
    "    del pos\n",
    "    gc.collect()\n",
    "    return pos_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. installment_payments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def installments_payments(num_rows=None, nan_as_category=True):\n",
    "    ins = pd.read_csv(filenames[5], nrows=num_rows)\n",
    "\n",
    "    ins, cat_cols = one_hot_encoder(ins, nan_as_category=True)\n",
    "\n",
    "    # Features\n",
    "    # Percentage and difference paid in each installment (amount paid and\n",
    "    # installment value)\n",
    "    ins[\"PAYMENT_PERC\"] = ins[\"AMT_PAYMENT\"] / ins[\"AMT_INSTALMENT\"]\n",
    "    ins[\"PAYMENT_DIFF\"] = ins[\"AMT_INSTALMENT\"] - ins[\"AMT_PAYMENT\"]\n",
    "    # Days past due and days before due (no negative values)\n",
    "    ins[\"DPD\"] = ins[\"DAYS_ENTRY_PAYMENT\"] - ins[\"DAYS_INSTALMENT\"]\n",
    "    ins[\"DBD\"] = ins[\"DAYS_INSTALMENT\"] - ins[\"DAYS_ENTRY_PAYMENT\"]\n",
    "    ins[\"DPD\"] = ins[\"DPD\"].apply(lambda x: x if x > 0 else 0)\n",
    "    ins[\"DBD\"] = ins[\"DBD\"].apply(lambda x: x if x > 0 else 0)\n",
    "\n",
    "    # Features: Perform aggregations\n",
    "    aggregations = {\n",
    "        \"NUM_INSTALMENT_VERSION\": [\"nunique\"],\n",
    "        \"DPD\": [\"max\", \"mean\", \"sum\"],\n",
    "        \"DBD\": [\"max\", \"mean\", \"sum\"],\n",
    "        \"PAYMENT_PERC\": [\"max\", \"mean\", \"sum\", \"var\"],\n",
    "        \"PAYMENT_DIFF\": [\"max\", \"mean\", \"sum\", \"var\"],\n",
    "        \"AMT_INSTALMENT\": [\"max\", \"mean\", \"sum\"],\n",
    "        \"AMT_PAYMENT\": [\"min\", \"max\", \"mean\", \"sum\"],\n",
    "        \"DAYS_ENTRY_PAYMENT\": [\"max\", \"mean\", \"sum\"]\n",
    "    }\n",
    "    for cat in cat_cols:\n",
    "        aggregations[cat] = [\"mean\"]\n",
    "\n",
    "    ins_agg = ins.groupby(\"SK_ID_CURR\").agg(aggregations)\n",
    "    ins_agg.columns = pd.Index([\n",
    "        \"INSTAL_\" + e[0] + \"_\" + e[1].upper() for e in ins_agg.columns.tolist()\n",
    "    ])\n",
    "\n",
    "    # Count installments accounts\n",
    "    ins_agg[\"INSTAL_COUNT\"] = ins.groupby(\"SK_ID_CURR\").size()\n",
    "\n",
    "    del ins\n",
    "    gc.collect()\n",
    "    return ins_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6. credit_card_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def credit_card_balance(num_rows=None, nan_as_category=True):\n",
    "    cc = pd.read_csv(filenames[4], nrows=num_rows)\n",
    "\n",
    "    cc, cat_cols = one_hot_encoder(cc, nan_as_category=True)\n",
    "\n",
    "    # General aggregations\n",
    "    cc.drop([\"SK_ID_PREV\"], axis=1, inplace =True)\n",
    "\n",
    "    cc_agg = cc.groupby(\"SK_ID_CURR\").agg([\"min\", \"max\", \"mean\", \"sum\", \"var\"])\n",
    "    cc_agg.columns = pd.Index([\n",
    "        \"CC_\" + e[0] + \"_\" + e[1].upper() for e in cc_agg.columns.tolist()\n",
    "    ])\n",
    "\n",
    "    # Count credit card lines\n",
    "    cc_agg[\"CC_COUNT\"] = cc.groupby(\"SK_ID_CURR\").size()\n",
    "\n",
    "    del cc\n",
    "    gc.collect()\n",
    "    return cc_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. functions from the original notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM GBDT with KFold or Stratified KFold\n",
    "# Parameters from Tilii kernel: https://www.kaggle.com/tilii7/olivier-lightgbm-parameters-by-bayesian-opt/code\n",
    "def kfold_lightgbm(df, num_folds, stratified=False, debug=False):\n",
    "    # Divide in training/validation and test data\n",
    "    train_df = df[df[\"TARGET\"].notnull()]\n",
    "    test_df = df[df[\"TARGET\"].isnull()]\n",
    "    print(\"Starting LightGBM. Train shape: {}, test shape: {}\".format(\n",
    "        train_df.shape, test_df.shape\n",
    "    ))\n",
    "    del df\n",
    "    gc.collect()\n",
    "\n",
    "    # Cross validation model\n",
    "    if stratified:\n",
    "        folds = StratifiedKFold(n_splits=num_folds,\n",
    "                                shuffle=True,\n",
    "                                random_state=1001)\n",
    "    else:\n",
    "        folds = KFold(n_splits=num_folds,\n",
    "                      shuffle=True,\n",
    "                      random_state=1001)\n",
    "\n",
    "    # Create arrays and dataframes to store results\n",
    "    oof_preds = np.zeros(train_df.shape[0])\n",
    "    sub_preds = np.zeros(test_df.shape[0])\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    feats = [f for f in train_df.columns if f not in [\"TARGET\",\n",
    "                                                      \"SK_ID_CURR\",\n",
    "                                                      \"SK_ID_BUREAU\",\n",
    "                                                      \"SK_ID_PREV\",\n",
    "                                                      \"index\"]]\n",
    "\n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(\n",
    "            folds.split(train_df[feats], train_df[\"TARGET\"])\n",
    "    ):\n",
    "        train_x, train_y = train_df[feats].iloc[train_idx],\\\n",
    "                           train_df[\"TARGET\"].iloc[train_idx]\n",
    "        valid_x, valid_y = train_df[feats].iloc[valid_idx],\\\n",
    "                           train_df[\"TARGET\"].iloc[valid_idx]\n",
    "\n",
    "        # LightGBM parameters found by Bayesian optimization\n",
    "        clf = LGBMClassifier(\n",
    "            nthread=4,\n",
    "            n_estimators=10000,\n",
    "            learning_rate=0.02,\n",
    "            num_leaves=34,\n",
    "            colsample_bytree=0.9497036,\n",
    "            subsample=0.8715623,\n",
    "            max_depth=8,\n",
    "            reg_alpha=0.041545473,\n",
    "            reg_lambda=0.0735294,\n",
    "            min_split_gain=0.0222415,\n",
    "            min_child_weight=39.3259775,\n",
    "            silent=-1,\n",
    "            verbose=-1,\n",
    "        )\n",
    "\n",
    "        clf.fit(train_x,\n",
    "                train_y,\n",
    "                eval_set=[(train_x, train_y), (valid_x, valid_y)],\n",
    "                eval_metric=\"auc\",\n",
    "                verbose=200,\n",
    "                early_stopping_rounds=200)\n",
    "\n",
    "        oof_preds[valid_idx] = clf.predict_proba(\n",
    "            valid_x,\n",
    "            num_iteration=clf.best_iteration_\n",
    "        )[:, 1]\n",
    "        sub_preds += clf.predict_proba(\n",
    "            test_df[feats],\n",
    "            num_iteration=clf.best_iteration_\n",
    "        )[:, 1] / folds.n_splits\n",
    "\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = feats\n",
    "        fold_importance_df[\"importance\"] = clf.feature_importances_\n",
    "        fold_importance_df[\"fold\"] = n_fold + 1\n",
    "        feature_importance_df = pd.concat(\n",
    "            [feature_importance_df, fold_importance_df],\n",
    "            axis=0\n",
    "        )\n",
    "        print(\"Fold %2d AUC : %.6f\" % (\n",
    "            n_fold + 1,\n",
    "            roc_auc_score(valid_y, oof_preds[valid_idx])\n",
    "        ))\n",
    "\n",
    "        del clf, train_x, train_y, valid_x, valid_y\n",
    "        gc.collect()\n",
    "\n",
    "    # Write submission file and plot feature importance\n",
    "    print(\"Full AUC score %.6f\" % roc_auc_score(train_df[\"TARGET\"], oof_preds))\n",
    "    if not debug:\n",
    "        test_df[\"TARGET\"] = sub_preds\n",
    "        test_df[[\"SK_ID_CURR\", \"TARGET\"]].to_csv(submission_file_name,\n",
    "                                                 index=False)\n",
    "    display_importances(feature_importance_df)\n",
    "    return feature_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display/plot feature importance\n",
    "def display_importances(feature_importance_df_):\n",
    "    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\n",
    "        \"feature\"\n",
    "    ).mean().sort_values(by=\"importance\", ascending=False)[:40].index\n",
    "    best_features = feature_importance_df_.loc[\n",
    "        feature_importance_df_.feature.isin(cols)\n",
    "    ]\n",
    "\n",
    "    plt.figure(figsize=(8, 10))\n",
    "    sns.barplot(x=\"importance\",\n",
    "                y=\"feature\",\n",
    "                data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "    plt.title(\"LightGBM Features (avg over folds)\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(\"lgbm_importances01.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Run the preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc(debug=True):\n",
    "    num_rows = debug if debug else None\n",
    "    with timer(\"Process application train test\"):\n",
    "        df = application_train_test(num_rows)\n",
    "        print(\"Application train test df shape:\", df.shape)\n",
    "        # print(df.dtypes.value_counts())\n",
    "    with timer(\"Process bureau and bureau_balance\"):\n",
    "        bureau = bureau_and_balance(num_rows)\n",
    "        print(\"Bureau df shape:\", bureau.shape)\n",
    "        df = df.join(bureau, how=\"left\", on=\"SK_ID_CURR\")\n",
    "        # print(df.dtypes.value_counts())\n",
    "        del bureau\n",
    "        gc.collect()\n",
    "    with timer(\"Process previous_applications\"):\n",
    "        prev = previous_applications(num_rows)\n",
    "        print(\"Previous applications df shape:\", prev.shape)\n",
    "        df = df.join(prev, how=\"left\", on=\"SK_ID_CURR\")\n",
    "        # print(df.dtypes.value_counts())\n",
    "        del prev\n",
    "        gc.collect()\n",
    "    with timer(\"Process POS-CASH balance\"):\n",
    "        pos = pos_cash(num_rows)\n",
    "        print(\"Pos-cash balance df shape:\", pos.shape)\n",
    "        df = df.join(pos, how=\"left\", on=\"SK_ID_CURR\")\n",
    "        # print(df.dtypes.value_counts())\n",
    "        del pos\n",
    "        gc.collect()\n",
    "    with timer(\"Process installments payments\"):\n",
    "        ins = installments_payments(num_rows)\n",
    "        print(\"Installments payments df shape:\", ins.shape)\n",
    "        df = df.join(ins, how=\"left\", on=\"SK_ID_CURR\")\n",
    "        # print(df.dtypes.value_counts())\n",
    "        del ins\n",
    "        gc.collect()\n",
    "    with timer(\"Process credit card balance\"):\n",
    "        cc = credit_card_balance(num_rows)\n",
    "        print(\"Credit card balance df shape:\", cc.shape)\n",
    "        df = df.join(cc, how=\"left\", on=\"SK_ID_CURR\")\n",
    "        # print(df.dtypes.value_counts())\n",
    "        del cc\n",
    "        gc.collect()\n",
    "\n",
    "    zeros = df.TARGET.value_counts(\n",
    "        sort=True,\n",
    "        ascending=False,\n",
    "        dropna=True,\n",
    "    )[0]\n",
    "    ones = df.TARGET.value_counts(\n",
    "        sort=True,\n",
    "        ascending=False,\n",
    "        dropna=True,\n",
    "    )[1]\n",
    "    nans = df.TARGET.isna().sum()\n",
    "    print(\"-----------------------------------------------------------------------\")\n",
    "    if debug:\n",
    "        print(\"subsampled df's TARGET has\",\n",
    "              f\"{zeros:10.0f} zeros,\",\n",
    "              f\"{ones:10.0f} ones and\",\n",
    "              f\"{nans:10.0f} NaNs\")\n",
    "    else:\n",
    "        print(\"TARGET has\",\n",
    "              f\"{zeros:10.0f} zeros,\",\n",
    "              f\"{ones:10.0f} ones and\",\n",
    "              f\"{nans:10.0f} NaNs\")\n",
    "\n",
    "    return zeros, ones, nans, df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. A first full run just to measure the target imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo\n",
    "# I ran this cell only once, just to get the exact values of zo and oz.\n",
    "if __name__ == \"__main__\":\n",
    "    with timer(\"preproc_full\"):\n",
    "        zeros_full, ones_full, nans_full, df_full = preproc(debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros_full, ones_full, nans_full = 282682, 24825, 48744"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is zo = 11.39 more zeros than ones in TARGET. (and oz = 0.09)\n"
     ]
    }
   ],
   "source": [
    "zo = zeros_full/ones_full\n",
    "oz = ones_full/zeros_full\n",
    "print(\"There is zo =\",\n",
    "      f\"{zo:.2f} more zeros than ones in TARGET. (and oz =\",\n",
    "      f\"{oz:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Subsampled run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1. Run the preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 100000, test samples: 48744\n",
      "Application train test df shape: (148741, 248)\n",
      "Process application train test - done in 2s\n",
      "Bureau df shape: (23121, 113)\n",
      "Process bureau and bureau_balance - done in 1s\n",
      "Previous applications df shape: (79977, 247)\n",
      "Process previous_applications - done in 1s\n",
      "Pos-cash balance df shape: (77469, 15)\n",
      "Process POS-CASH balance - done in 0s\n",
      "Installments payments df shape: (48591, 26)\n",
      "Process installments payments - done in 0s\n",
      "Credit card balance df shape: (53383, 131)\n",
      "Process credit card balance - done in 1s\n",
      "-----------------------------------------------------------------------\n",
      "subsampled df's TARGET has      91904 zeros,       8093 ones and      48744 NaNs\n",
      "preproc_subsampled - done in 5s\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    with timer(\"preproc_subsampled\"):\n",
    "        # I tried 1_000 here but the ROC AUC scores obtained were > 90% which\n",
    "        # proves overfitting.\n",
    "        zeros, ones, nans, df = preproc(debug=100_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3. Measure of the target imbalance after the subsampling is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is zo_sub = 11.36 more zeros than ones in TARGET. (and oz_sub = 0.09)\n"
     ]
    }
   ],
   "source": [
    "zo_sub = zeros/ones\n",
    "oz_sub = ones/zeros\n",
    "print(\"There is zo_sub =\",\n",
    "      f\"{zo_sub:.2f} more zeros than ones in TARGET. (and oz_sub =\",\n",
    "      f\"{oz_sub:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'imbalance de 11.39 des targets du dataset est de 11.36 après subsampling.\n"
     ]
    }
   ],
   "source": [
    "if (zo/zo_sub >= 3/2 or zo/zo_sub <= 2/3):\n",
    "    for _ in range(8):\n",
    "        print(\"!\")\n",
    "    print(\n",
    "        \"L'imbalance des targets a été fortement modifiée par le subsampling.\",\n",
    "        f\"Elle est passée de {zo:.2f} à {zo_sub:.2f}.\",\n",
    "    )\n",
    "    for _ in range(8):\n",
    "        print(\"!\")\n",
    "else:\n",
    "    print(\n",
    "        f\"L'imbalance de {zo:.2f} des targets du dataset est de {zo_sub:.2f}\",\n",
    "        \"après subsampling.\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Suppression du caractère illisible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_of_df = list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipped\n",
    "# Ce code prend un temps infini à run. Prende la cell en-dessous.\n",
    "for j in cols_of_df:\n",
    "    df = df.rename(columns={j: re.sub(r\"[ ]\", r\"_a_\", j)})\n",
    "    df = df.rename(columns={j: re.sub(r\"[-]\", r\"_b_\", j)})\n",
    "    df = df.rename(columns={j: re.sub(r\"[:]\", r\"_c_\", j)})\n",
    "    df = df.rename(columns={j: re.sub(r\"[/]\", r\"_d_\", j)})\n",
    "    df = df.rename(columns={j: re.sub(r\"[,]\", r\"_e_\", j)})\n",
    "    df = df.rename(columns={j: re.sub(r\"[:]\", r\"_f_\", j)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%script echo skipped\n",
    "df = df.rename(columns=lambda x: x.replace(\" \", \"_a_\")\\\n",
    "                                  .replace(\"-\", \"_b_\")\\\n",
    "                                  .replace(\":\", \"_c_\")\\\n",
    "                                  .replace(\"/\", \"_d_\")\\\n",
    "                                  .replace(\",\", \"_e_\")\\\n",
    "                                  .replace(\":\", \"_f_\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.rename(columns=lambda x: x.replace(\":\", \"deuxpoints\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Classification run from the original notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipped\n",
    "with timer(\"Run LightGBM with kfold\"):\n",
    "    feat_importance = kfold_lightgbm(df, num_folds=10, stratified=False, debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.0. Suppression des données sans TARGET et colonnes sans données\n",
    "En effet mon but ici c'est juste de créer un modèle qui fonctionne, faire les\n",
    " prédictions de solvabilité des futurs clients ça sera pour plus tard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"TARGET\"].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_notnull = list(df.loc[:, df.notnull().sum() > 0].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isinf(df).sum()[np.isinf(df).sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:, cols_notnull]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1. train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"TARGET\", axis=\"columns\")\n",
    "y = df[\"TARGET\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    73518\n",
       "1.0     6479\n",
       "Name: TARGET, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2. SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.0'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_old = X_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_names_old = list(X_train.columns)\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "#X_train_i = imputer.fit_transform(X_train)\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "feature_names = imputer.get_feature_names_out()\n",
    "X_train = pd.DataFrame(X_train, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test_old = X_test.copy()\n",
    "# X_test = imputer.fit_transform(X_test_old)\n",
    "X_test = imputer.transform(X_test_old) # pas de fit, recommandé par mentor\n",
    "X_test = pd.DataFrame(X_test, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 779)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3. Balancing the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "undersampler = RandomUnderSampler(sampling_strategy=\"majority\")\n",
    "#X_train_u, y_train_u = undersampler.fit_resample(X_train_i, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampler_1 = RandomOverSampler(sampling_strategy=\"not majority\")\n",
    "# La doc de imblearn dit exactement l'inverse mais ici j'ai cette erreur:\n",
    "#\n",
    "# ValueError: The 'sampling_strategy' parameter of RandomOverSampler must be a\n",
    "# float in the range (0, 1], a str among {'majority', 'not majority', 'all',\n",
    "# 'auto', 'not minority'}, an instance of 'collections.abc.Mapping' or a\n",
    "# callable. Got 'minority' instead.\n",
    "oversampler_2 = SMOTE()\n",
    "#X_train_o, y_train_o = oversampler.fit_resample(X_train_i, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.4. Declaring the classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf0 = DummyClassifier()\n",
    "clf1 = LogisticRegression(random_state=42, n_jobs=1, solver=\"sag\")\n",
    "clf2 = SGDClassifier()\n",
    "clf3 = GaussianNB()\n",
    "clf4 = MultinomialNB()\n",
    "clf5 = KNeighborsClassifier()\n",
    "clf6 = SVC(probability=True, random_state=42)\n",
    "clf7 = DecisionTreeClassifier(random_state=42)\n",
    "clf8 = RandomForestClassifier(random_state=42)\n",
    "clf9 = GradientBoostingClassifier(random_state=42)\n",
    "clf10 = AdaBoostClassifier(random_state=42)\n",
    "clf11 = XGBClassifier(random_state=42)\n",
    "# Even with logging_level=\"info\" catboost prints millions of lines and crashes\n",
    "# my computer so i need logging_level=\"Silent\" here.\n",
    "clf12 = CatBoostClassifier(random_state=42, logging_level=\"Silent\")\n",
    "clf13 = LGBMClassifier(random_state=42, verbose=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.5. Declaring the classifiers' parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5.0. DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "param0 = {}\n",
    "param0[\"classifier__strategy\"] = [\"most_frequent\",\n",
    "                                  \"prior\"]\n",
    "param0[\"classifier\"] = [clf0]\n",
    "#param0[\"classifier\"] = [classifiers[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5.1. LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "param1 = {}\n",
    "param1[\"classifier__C\"] = [\n",
    "    10**-2,\n",
    "    10**-1,\n",
    "    10**0,\n",
    "    10**1,\n",
    "    # 10**2,\n",
    "]\n",
    "param1[\"classifier__penalty\"] = [\n",
    "    # The default solver lbfgs supports only l2 penalty and None.\n",
    "    # \"l1\",\n",
    "    \"l2\",\n",
    "    # \"elasticnet\",\n",
    "]\n",
    "# param1[\"classifier__class_weight\"] = [{0: 1, 1: 1},\n",
    "#                                       {0: oz, 1: zo}]\n",
    "# param1[\"classifier__class_weight\"] = [None]\n",
    "# param1[\"classifier__class_weight\"] = [None,\n",
    "#                                       {0: oz, 1: zo}]\n",
    "# Je rajoute les class_weights et leurs variantes plus tard dans un if.\n",
    "param1[\"classifier\"] = [clf1]\n",
    "#param1[\"classifier\"] = [classifiers[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5.2. SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "param2 = {}\n",
    "param2[\"classifier__loss\"] = [\n",
    "    \"hinge\",\n",
    "    \"log\",\n",
    "    \"squared_hinge\",\n",
    "    \"modified_huber\",\n",
    "]\n",
    "param2[\"classifier__penalty\"] = [\n",
    "    # \"l1\",\n",
    "    # \"l2\",\n",
    "    \"elasticnet\",\n",
    "]\n",
    "param2[\"classifier\"] = [clf2]\n",
    "#param2[\"classifier\"] = [classifiers[2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5.3. GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "param3 = {}\n",
    "param3[\"classifier\"] = [clf3]\n",
    "#param3[\"classifier\"] = [classifiers[3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5.4. MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "param4 = {}\n",
    "param4[\"classifier__alpha\"] = [\n",
    "    10**0,\n",
    "    10**1,\n",
    "    # 10**2,\n",
    "]\n",
    "param4[\"classifier\"] = [clf4]\n",
    "#param4[\"classifier\"] = [classifiers[4]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5.5. KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "param5 = {}\n",
    "param5[\"classifier__n_neighbors\"] = [\n",
    "    int(10**.5),\n",
    "    10**1,\n",
    "    10**2,\n",
    "    10**3,\n",
    "]\n",
    "param5[\"classifier__weights\"] = [\n",
    "    \"uniform\",\n",
    "    \"distance\",\n",
    "]\n",
    "param5[\"classifier\"] = [clf5]\n",
    "#param5[\"classifier\"] = [classifiers[5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5.6. SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "param6 = {}\n",
    "param6[\"classifier__kernel\"] = [\"linear\",\n",
    "                                \"rbf\",\n",
    "                                \"poly\",\n",
    "                                \"sigmoid\"]\n",
    "param6[\"classifier__C\"] = [10**-2,\n",
    "                           10**-1,\n",
    "                           10**0,\n",
    "                           10**1,\n",
    "                           10**2,\n",
    "                           10**3]\n",
    "param6[\"classifier__gamma\"] = [\"auto\",\n",
    "                               \"scale\"]\n",
    "param6[\"classifier\"] = [clf6]\n",
    "#param6[\"classifier\"] = [classifiers[6]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5.7. DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "param7 = {}\n",
    "param7[\"classifier__max_depth\"] = [\n",
    "    int(10**.5),\n",
    "    10**1,\n",
    "    # int(10**1.5),\n",
    "    None,\n",
    "]\n",
    "param7[\"classifier__min_samples_split\"] = [\n",
    "    int(10**.5),\n",
    "    10**1,\n",
    "]\n",
    "param7[\"classifier__criterion\"] = [\n",
    "    \"gini\",\n",
    "    \"entropy\",\n",
    "]\n",
    "param7[\"classifier\"] = [clf7]\n",
    "#param7[\"classifier\"] = [classifiers[7]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 8.5.8. RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "param8 = {}\n",
    "param8[\"classifier__n_estimators\"] = [\n",
    "    int(10**1.5),\n",
    "    10**2,\n",
    "]\n",
    "param8[\"classifier__max_depth\"] = [\n",
    "    int(10**.5),\n",
    "    10**1,\n",
    "    # int(10**1.5),\n",
    "    None,\n",
    "]\n",
    "param8[\"classifier__criterion\"] = [\n",
    "    \"gini\",\n",
    "    \"entropy\",\n",
    "]\n",
    "param8[\"classifier\"] = [clf8]\n",
    "#param8[\"classifier\"] = [classifiers[8]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5.9. GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "param9 = {}\n",
    "param9[\"classifier__n_estimators\"] = [10**1,\n",
    "                                      10**2,\n",
    "                                      10**3]\n",
    "param9[\"classifier__max_depth\"] = [3,\n",
    "                                   10**1,\n",
    "                                   30]\n",
    "param9[\"classifier\"] = [clf9]\n",
    "#param9[\"classifier\"] = [classifiers[9]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5.10. AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "param10 = {}\n",
    "param10[\"classifier__n_estimators\"] = [10**1,\n",
    "                                       10**2,\n",
    "                                       10**3]\n",
    "param10[\"classifier__learning_rate\"] = [10**-3,\n",
    "                                        10**-2,\n",
    "                                        10**-1]\n",
    "param10[\"classifier\"] = [clf10]\n",
    "#param10[\"classifier\"] = [classifiers[10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5.11. XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "param11 = {}\n",
    "param11[\"classifier__booster\"] = [\n",
    "    # \"gbtree\",\n",
    "    # gblinear doesn't support max_depth\n",
    "    # \"gblinear\",\n",
    "    \"dart\",\n",
    "]\n",
    "param11[\"classifier__learning_rate\"] = [\n",
    "    # 10**-3,\n",
    "    # 10**-2,\n",
    "    10**-.5,\n",
    "    10**-1,\n",
    "]\n",
    "param11[\"classifier__max_depth\"] = [\n",
    "    6,\n",
    "    10**1,\n",
    "]\n",
    "param11[\"classifier\"] = [clf11]\n",
    "#param11[\"classifier\"] = [classifiers[11]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5.12. CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "param12 = {}\n",
    "param12[\"classifier__iterations\"] = [\n",
    "    # 10**1,\n",
    "    # 10**2,\n",
    "    10**3,\n",
    "]\n",
    "param12[\"classifier__learning_rate\"] = [\n",
    "    # 10**-3,\n",
    "    10**-2,\n",
    "    10**-1,\n",
    "]\n",
    "param12[\"classifier__depth\"] = [\n",
    "    # 10**0,\n",
    "    # 3,\n",
    "    6,\n",
    "    10**1,\n",
    "]\n",
    "param12[\"classifier\"] = [clf12]\n",
    "#param12[\"classifier\"] = [classifiers[12]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5.13. LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "param13 = {}\n",
    "param13[\"classifier__boosting_type\"] = [\n",
    "    # \"gbdt\",\n",
    "    \"dart\",\n",
    "    # \"goss\",\n",
    "]\n",
    "param13[\"classifier__learning_rate\"] = [\n",
    "    # 10**-3,\n",
    "    10**-2,\n",
    "    10**-1.5,\n",
    "    10**-1,\n",
    "]\n",
    "param13[\"classifier__num_leaves\"] = [\n",
    "    10**1,\n",
    "    int(10**1.5),\n",
    "    10**2,\n",
    "]\n",
    "param13[\"classifier\"] = [clf13]\n",
    "#param13[\"classifier\"] = [classifiers[13]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 8.5bis. Listing des paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "nz = [\n",
    "    0,\n",
    "    1,\n",
    "    2,\n",
    "    3,\n",
    "    4,\n",
    "    5,\n",
    "    6,\n",
    "    7,\n",
    "    8,\n",
    "    9,\n",
    "    10,\n",
    "    11,\n",
    "    12,\n",
    "    13,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = [\n",
    "    \"Dummy\",\n",
    "    \"Logistic\",\n",
    "    \"SGDC\",\n",
    "    \"GaussNB\",\n",
    "    \"MultinNB\",\n",
    "    \"KNeighbor\",\n",
    "    \"SVC\",\n",
    "    \"DecisionT\",\n",
    "    \"RandomF\",\n",
    "    \"GB\",\n",
    "    \"AdaB\",\n",
    "    \"XGB\",\n",
    "    \"CatB\",\n",
    "    \"LGBM\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = [\n",
    "    clf0,\n",
    "    # LogisticReg has trouble converging and is quite slow.\n",
    "    clf1,\n",
    "    clf2,\n",
    "    clf3,\n",
    "    clf4,\n",
    "    clf5,\n",
    "    # No SVC because it never finishes computing.\n",
    "    clf6,\n",
    "    clf7,\n",
    "    clf8,\n",
    "    clf9,\n",
    "    # AdaBoost et GBoost sont de loin les plus lents et ne sont pas les\n",
    "    # meilleurs (ils sont proches des scores des meilleurs néanmoins).\n",
    "    # Je les abandonne car je ne peux pas attendre de nouveau 10h à chaque fois\n",
    "    # que je veux faire un nouveau RandomSearchCV.\n",
    "    clf10,\n",
    "    clf11,\n",
    "    clf12,\n",
    "    clf13,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_full = [\n",
    "    param0,\n",
    "    param1,\n",
    "    param2,\n",
    "    param3,\n",
    "    param4,\n",
    "    param5,\n",
    "    param6,\n",
    "    param7,\n",
    "    param8,\n",
    "    param9,\n",
    "    param10,\n",
    "    param11,\n",
    "    param12,\n",
    "    param13,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "dA = pd.DataFrame(columns=[\"nz\", \"clf\", \"clfs\", \"params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dA.nz = nz\n",
    "dA.clf = clf\n",
    "dA.clfs = clfs\n",
    "dA.params = params_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour les raisons citées précédemment:\n",
    "dA.drop(index=[6, 9, 10], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nz</th>\n",
       "      <th>clf</th>\n",
       "      <th>clfs</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Dummy</td>\n",
       "      <td>DummyClassifier()</td>\n",
       "      <td>{'classifier__strategy': ['most_frequent', 'pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Logistic</td>\n",
       "      <td>LogisticRegression(n_jobs=1, random_state=42, ...</td>\n",
       "      <td>{'classifier__C': [0.01, 0.1, 1, 10], 'classif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>SGDC</td>\n",
       "      <td>SGDClassifier()</td>\n",
       "      <td>{'classifier__loss': ['hinge', 'log', 'squared...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>GaussNB</td>\n",
       "      <td>GaussianNB()</td>\n",
       "      <td>{'classifier': [GaussianNB()]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>MultinNB</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>{'classifier__alpha': [1, 10], 'classifier': [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>KNeighbor</td>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>{'classifier__n_neighbors': [3, 10, 100, 1000]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>DecisionT</td>\n",
       "      <td>DecisionTreeClassifier(random_state=42)</td>\n",
       "      <td>{'classifier__max_depth': [3, 10, None], 'clas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>RandomF</td>\n",
       "      <td>RandomForestClassifier(random_state=42)</td>\n",
       "      <td>{'classifier__n_estimators': [31, 100], 'class...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>XGB</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'classifier__booster': ['dart'], 'classifier_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>CatB</td>\n",
       "      <td>&lt;catboost.core.CatBoostClassifier object at 0x...</td>\n",
       "      <td>{'classifier__iterations': [1000], 'classifier...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>LGBMClassifier(random_state=42, verbose=-1)</td>\n",
       "      <td>{'classifier__boosting_type': ['dart'], 'class...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    nz        clf                                               clfs  \\\n",
       "0    0      Dummy                                  DummyClassifier()   \n",
       "1    1   Logistic  LogisticRegression(n_jobs=1, random_state=42, ...   \n",
       "2    2       SGDC                                    SGDClassifier()   \n",
       "3    3    GaussNB                                       GaussianNB()   \n",
       "4    4   MultinNB                                    MultinomialNB()   \n",
       "5    5  KNeighbor                             KNeighborsClassifier()   \n",
       "7    7  DecisionT            DecisionTreeClassifier(random_state=42)   \n",
       "8    8    RandomF            RandomForestClassifier(random_state=42)   \n",
       "11  11        XGB  XGBClassifier(base_score=None, booster=None, c...   \n",
       "12  12       CatB  <catboost.core.CatBoostClassifier object at 0x...   \n",
       "13  13       LGBM        LGBMClassifier(random_state=42, verbose=-1)   \n",
       "\n",
       "                                               params  \n",
       "0   {'classifier__strategy': ['most_frequent', 'pr...  \n",
       "1   {'classifier__C': [0.01, 0.1, 1, 10], 'classif...  \n",
       "2   {'classifier__loss': ['hinge', 'log', 'squared...  \n",
       "3                      {'classifier': [GaussianNB()]}  \n",
       "4   {'classifier__alpha': [1, 10], 'classifier': [...  \n",
       "5   {'classifier__n_neighbors': [3, 10, 100, 1000]...  \n",
       "7   {'classifier__max_depth': [3, 10, None], 'clas...  \n",
       "8   {'classifier__n_estimators': [31, 100], 'class...  \n",
       "11  {'classifier__booster': ['dart'], 'classifier_...  \n",
       "12  {'classifier__iterations': [1000], 'classifier...  \n",
       "13  {'classifier__boosting_type': ['dart'], 'class...  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    DummyClassifier                  2         \n",
      "1    LogisticRegression               4         \n",
      "2    SGDClassifier                    4         \n",
      "3    GaussianNB                       1         \n",
      "4    MultinomialNB                    2         \n",
      "5    KNeighborsClassifier             8         \n",
      "6    DecisionTreeClassifier           12        \n",
      "7    RandomForestClassifier           12        \n",
      "8    XGBClassifier                    4         \n",
      "9    <catboost.core.CatBoostClassifier object at 0x000001FA9DC81F40>] 4         \n",
      "10   LGBMClassifier                   9         \n"
     ]
    }
   ],
   "source": [
    "nl = []\n",
    "for j, k in enumerate(dA.params):\n",
    "    nl.append(math.prod([len(i) for i in k.values()]))\n",
    "    print(\"{:<4}\".format(j),\n",
    "          \"{:<32}\".format(str(k[\"classifier\"]).split('(')[0][1:]),\n",
    "          \"{:<10.0f}\".format(nl[j]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 8.5ter. Déclaration des samplers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_sampler = {}\n",
    "param_sampler[\"sampler\"] = [\n",
    "    None,\n",
    "    # undersampler,\n",
    "    # oversampler_1,\n",
    "    oversampler_2\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.6. Itération sur les classifiers avec une boucle.\n",
    "Je vais gridsearch les paramètres de chacun des estimateurs et enregistrer le\n",
    "best_estimator_ obtenu à chaque fois pour pouvoir comparer les estimateurs.\n",
    "\n",
    "Le problème c'est qu'ici apparemment on veut l'inverse. On veut plutôt random\n",
    "entre tous les estimateurs pour trouver lequel est le meilleur et ne sortir que\n",
    "ses stats à lui. Puis recommencer avec une autre technique de sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo\n",
    "# C'était juste pour constater qu'il y a pas mal de valeurs négatives\n",
    "# donc on ne peut pas utiliser MultinomialNB dans l'état\n",
    "# donc je vais rajouter un MinMaxScaler qui met tout entre 0 et 1.\n",
    "for co in df.columns:\n",
    "    neg = (df[co] < 0).sum()\n",
    "    if neg:\n",
    "        print(\"{:<40}\".format(co), \"{:>5.0f}\".format(neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo\n",
    "for sampler in param_sampler[\"sampler\"][0:]:\n",
    "    for (n, clf, param) in list(zip(nz, clfs, params_full))[0:]:\n",
    "            n_loops = math.prod([len(i) for i in param.values()])\n",
    "            print(clf, n_loops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">DummyClassifier() 2\n",
    "LogisticRegression(n_jobs=1, random_state=42, solver='sag') 5\n",
    "SGDClassifier() 12\n",
    "GaussianNB() 1\n",
    "MultinomialNB() 3\n",
    "KNeighborsClassifier() 8\n",
    "DecisionTreeClassifier(random_state=42) 8\n",
    "RandomForestClassifier(random_state=42) 18\n",
    "GradientBoostingClassifier(random_state=42) 9\n",
    "AdaBoostClassifier(random_state=42) 9\n",
    "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
    "              colsample_bylevel=None, colsample_bynode=None,\n",
    "              colsample_bytree=None, early_stopping_rounds=None,\n",
    "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
    "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
    "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
    "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
    "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
    "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
    "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
    "              predictor=None, random_state=42, ...) 18\n",
    "catboost.core.CatBoostClassifier object at 0x000001E1F6F96910> 27\n",
    "LGBMClassifier(random_state=42) 27\n",
    "DummyClassifier() 2\n",
    "LogisticRegression(n_jobs=1, random_state=42, solver='sag') 5\n",
    "SGDClassifier() 12\n",
    "GaussianNB() 1\n",
    "MultinomialNB() 3\n",
    "KNeighborsClassifier() 8\n",
    "DecisionTreeClassifier(random_state=42) 8\n",
    "RandomForestClassifier(random_state=42) 18\n",
    "GradientBoostingClassifier(random_state=42) 9\n",
    "AdaBoostClassifier(random_state=42) 9\n",
    "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
    "              colsample_bylevel=None, colsample_bynode=None,\n",
    "              colsample_bytree=None, early_stopping_rounds=None,\n",
    "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
    "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
    "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
    "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
    "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
    "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
    "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
    "              predictor=None, random_state=42, ...) 18\n",
    "catboost.core.CatBoostClassifier object at 0x000001E1F6F96910> 27\n",
    "LGBMClassifier(random_state=42) 27\n",
    "DummyClassifier() 2\n",
    "LogisticRegression(n_jobs=1, random_state=42, solver='sag') 5\n",
    "SGDClassifier() 12\n",
    "GaussianNB() 1\n",
    "MultinomialNB() 3\n",
    "KNeighborsClassifier() 8\n",
    "DecisionTreeClassifier(random_state=42) 8\n",
    "RandomForestClassifier(random_state=42) 18\n",
    "GradientBoostingClassifier(random_state=42) 9\n",
    "AdaBoostClassifier(random_state=42) 9\n",
    "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
    "              colsample_bylevel=None, colsample_bynode=None,\n",
    "              colsample_bytree=None, early_stopping_rounds=None,\n",
    "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
    "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
    "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
    "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
    "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
    "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
    "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
    "              predictor=None, random_state=42, ...) 18\n",
    "catboost.core.CatBoostClassifier object at 0x000001E1F6F96910> 27\n",
    "LGBMClassifier(random_state=42) 27\n",
    "DummyClassifier() 2\n",
    "LogisticRegression(n_jobs=1, random_state=42, solver='sag') 5\n",
    "SGDClassifier() 12\n",
    "GaussianNB() 1\n",
    "MultinomialNB() 3\n",
    "KNeighborsClassifier() 8\n",
    "DecisionTreeClassifier(random_state=42) 8\n",
    "RandomForestClassifier(random_state=42) 18\n",
    "GradientBoostingClassifier(random_state=42) 9\n",
    "AdaBoostClassifier(random_state=42) 9\n",
    "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
    "              colsample_bylevel=None, colsample_bynode=None,\n",
    "              colsample_bytree=None, early_stopping_rounds=None,\n",
    "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
    "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
    "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
    "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
    "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
    "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
    "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
    "              predictor=None, random_state=42, ...) 18\n",
    "catboost.core.CatBoostClassifier object at 0x000001E1F6F96910> 27\n",
    "LGBMClassifier(random_state=42) 27\n",
    "</code>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_csv(d):\n",
    "    return d.loc[:, ~d.columns.str.match('Unnamed')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = MinMaxScaler(input_features=feature_names)\n",
    "scaler = MinMaxScaler()\n",
    "cws = [\n",
    "    None,\n",
    "    # {0: .8*oz, 1: zo/.8},\n",
    "    {0: oz, 1: zo},\n",
    "    # {0: oz/.8, 1: .8*zo},\n",
    "]\n",
    "cws1 = [\n",
    "    1,\n",
    "    oz,\n",
    "    zo,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.08781952865764357, 11.386988922457201)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oz, zo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo\n",
    "result_dfs = dict()\n",
    "for sampler in param_sampler[\"sampler\"][0:]:\n",
    "    # I create a different results table for each sampler.\n",
    "    # str(sampler) includes parentheses and the arguments inside, so i strip\n",
    "    # these out in order to keep only the name of the sampler.\n",
    "    nom_du_df = \"result_df_\" + str(sampler).split('(')[0] + \".csv\"\n",
    "    result_df = pd.DataFrame(columns=[\n",
    "        \"classifier\",\n",
    "        \"best_score\",\n",
    "        \"avg_score_folds\",\n",
    "        \"fold0_score\",\n",
    "        \"fold1_score\",\n",
    "        \"fold2_score\",\n",
    "        \"fold3_score\",\n",
    "        \"fold4_score\",\n",
    "        \"run_time (s)\",\n",
    "    ])\n",
    "    # I gridsearch each classifier with its own set of parameters.\n",
    "    for (n, clf, param) in list(zip(dA.nz, dA.clfs, dA.params))[0:]:\n",
    "        with timer(str(n)):\n",
    "            try:\n",
    "                result_df = pd.read_csv(nom_du_df)\n",
    "                result_df = clean_csv(result_df)\n",
    "            except ValueError:\n",
    "                print(\"An error occurred while reading the CSV file.\")\n",
    "            except FileNotFoundError:\n",
    "                print(\"The file could not be found.\")\n",
    "\n",
    "            t_clf = time.perf_counter()\n",
    "\n",
    "            # Without sampler i still try to optimize the gridsearch using class_weight.\n",
    "            if sampler is None:\n",
    "                # class_weight does not exist for dummy, NBayes, KN, GB, AdaB, XGB.\n",
    "                # CatBoost either.\n",
    "                if n in [1, 2, 6, 7, 8, 13]:\n",
    "                    param[\"classifier__class_weight\"] = cws\n",
    "                elif n in [12]:\n",
    "                    param[\"classifier__class_weights\"] = cws\n",
    "                elif n in [11]:\n",
    "                    param[\"classifier__scale_pos_weight\"] = cws1\n",
    "\n",
    "            # Train the model\n",
    "            # I need a MinMaxScaler in the pipe because (at least) MultinomialNB\n",
    "            # errors on negative values.\n",
    "            pipeline = imblearn.pipeline.Pipeline([(\"scaler\", scaler),\n",
    "                                                   (\"sampler\", sampler),\n",
    "                                                   (\"classifier\", clf)])\n",
    "            gs = GridSearchCV(\n",
    "                pipeline,\n",
    "                param,\n",
    "                cv=5,\n",
    "                n_jobs=None,\n",
    "                scoring=\"roc_auc\",\n",
    "                # scoring=[\"roc_auc\", \"accuracy\"],\n",
    "                # refit=\"roc_auc\",\n",
    "                # n_iter=5, # seulement pour RandomSearchCV ?\n",
    "                # random_state=42, # seulement pour RandomSearchCV ?\n",
    "            ).fit(X_train, y_train)\n",
    "\n",
    "            n_loops = math.prod([len(i) for i in param.values()])\n",
    "            t_mean = (time.perf_counter() - t_clf)/(n_loops)\n",
    "            if t_mean > 10:\n",
    "                t_mean = round(t_mean, 0)\n",
    "            elif t_mean > 1:\n",
    "                t_mean = round(t_mean, 2)\n",
    "            elif t_mean > .001:\n",
    "                t_mean = round(t_mean, 3)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "            # Save the results\n",
    "            print(\"Score:\", gs.best_score_)\n",
    "            print(\"Obtained with:\", gs.best_params_[\"classifier\"])\n",
    "            result_df.loc[n, :] = [\n",
    "                gs.best_params_[\"classifier\"],\n",
    "                round(gs.best_score_, 3),\n",
    "                round(np.mean([\n",
    "                    gs.cv_results_[\"split0_test_score\"].max(),\n",
    "                    gs.cv_results_[\"split1_test_score\"].max(),\n",
    "                    gs.cv_results_[\"split2_test_score\"].max(),\n",
    "                    gs.cv_results_[\"split3_test_score\"].max(),\n",
    "                    gs.cv_results_[\"split4_test_score\"].max(),\n",
    "                ]), 3),\n",
    "                round(gs.cv_results_[\"split0_test_score\"].max(), 3),\n",
    "                round(gs.cv_results_[\"split1_test_score\"].max(), 3),\n",
    "                round(gs.cv_results_[\"split2_test_score\"].max(), 3),\n",
    "                round(gs.cv_results_[\"split3_test_score\"].max(), 3),\n",
    "                round(gs.cv_results_[\"split4_test_score\"].max(), 3),\n",
    "                t_mean\n",
    "            ]\n",
    "\n",
    "            # Je save à chaque classifier pour pouvoir relancer la loop à partir\n",
    "            # du classifier qui bug en cas d'erreur.\n",
    "            #result_df.sort_index(by=\"best_score\", inplace=True)\n",
    "            result_df.sort_values(by=\"best_score\", inplace=True)\n",
    "            result_df.to_csv(nom_du_df)\n",
    "\n",
    "    result_dfs[str(sampler)] = result_df\n",
    "    #display(result_df[-2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">The file could not be found.\n",
    "Score: 0.5\n",
    "Obtained with: DummyClassifier(strategy='most_frequent')\n",
    "0 - done in 1s\n",
    "Score: 0.7250222708935026\n",
    "Obtained with: LogisticRegression(C=0.1, n_jobs=1, random_state=42, solver='sag')\n",
    "1 - done in 97s\n",
    "Score: 0.7099938152168361\n",
    "Obtained with: SGDClassifier(loss='log', penalty='elasticnet')\n",
    "2 - done in 60s\n",
    "Score: 0.4930100602023389\n",
    "Obtained with: GaussianNB()\n",
    "3 - done in 1s\n",
    "Score: 0.6243430795680865\n",
    "Obtained with: MultinomialNB(alpha=1)\n",
    "4 - done in 1s\n",
    "Score: 0.6522858164197481\n",
    "Obtained with: KNeighborsClassifier(n_neighbors=1000, weights='distance')\n",
    "5 - done in 10s\n",
    "Score: 0.6871594822939304\n",
    "Obtained with: DecisionTreeClassifier(criterion='entropy', max_depth=3, min_samples_split=3,\n",
    "                       random_state=42)\n",
    "7 - done in 47s\n",
    "Score: 0.7107564160032682\n",
    "Obtained with: RandomForestClassifier(criterion='entropy', max_depth=10, random_state=42)\n",
    "8 - done in 97s\n",
    "Score: 0.7420321268277735\n",
    "Obtained with: XGBClassifier(base_score=None, booster='dart', callbacks=None,\n",
    "              colsample_bylevel=None, colsample_bynode=None,\n",
    "              colsample_bytree=None, early_stopping_rounds=None,\n",
    "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
    "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
    "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
    "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
    "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
    "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
    "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
    "              predictor=None, random_state=42, ...)\n",
    "11 - done in 934s\n",
    "20 fits failed out of a total of 40.\n",
    "The score on these train-test partitions for these parameters will be set to nan.\n",
    "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
    "One or more of the test scores are non-finite: [       nan        nan        nan        nan 0.71175619 0.67402221\n",
    " 0.71084153 0.69628743]\n",
    "Score: 0.7117561947128614\n",
    "Obtained with: catboost.core.CatBoostClassifier object at 0x00000175D93E9DC0\n",
    "12 - done in 1463s\n",
    "Score: 0.745211332338472\n",
    "Obtained with: LGBMClassifier(boosting_type='dart', num_leaves=10, random_state=42)\n",
    "13 - done in 71s\n",
    "The file could not be found.\n",
    "Score: 0.5\n",
    "Obtained with: DummyClassifier(strategy='most_frequent')\n",
    "0 - done in 2s\n",
    "Score: 0.713460698256345\n",
    "Obtained with: LogisticRegression(C=0.01, n_jobs=1, random_state=42, solver='sag')\n",
    "1 - done in 157s\n",
    "Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
    "Score: 0.6917674294565902\n",
    "Obtained with: SGDClassifier(class_weight={0: 0.08781952865764357, 1: 11.386988922457201},\n",
    "              loss='log', penalty='elasticnet')\n",
    "2 - done in 189s\n",
    "Score: 0.4993332917231714\n",
    "Obtained with: GaussianNB()\n",
    "3 - done in 2s\n",
    "Score: 0.6189208971907467\n",
    "Obtained with: MultinomialNB(alpha=10)\n",
    "4 - done in 2s\n",
    "Score: 0.6488529780582051\n",
    "Obtained with: KNeighborsClassifier(n_neighbors=1000, weights='distance')\n",
    "5 - done in 19s\n",
    "Score: 0.6381124495713207\n",
    "Obtained with: DecisionTreeClassifier(max_depth=3, min_samples_split=10, random_state=42)\n",
    "7 - done in 226s\n",
    "Score: 0.6855991012205017\n",
    "Obtained with: RandomForestClassifier(random_state=42)\n",
    "8 - done in 348s\n",
    "Score: 0.7173236343828551\n",
    "Obtained with: XGBClassifier(base_score=None, booster='dart', callbacks=None,\n",
    "              colsample_bylevel=None, colsample_bynode=None,\n",
    "              colsample_bytree=None, early_stopping_rounds=None,\n",
    "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
    "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
    "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
    "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
    "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
    "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
    "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
    "              predictor=None, random_state=42, ...)\n",
    "11 - done in 1717s\n",
    "20 fits failed out of a total of 40.\n",
    "The score on these train-test partitions for these parameters will be set to nan.\n",
    "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
    "One or more of the test scores are non-finite: [       nan        nan        nan        nan 0.66966222 0.66499016\n",
    " 0.66001963 0.66197607]\n",
    "Score: 0.6696622200534501\n",
    "Obtained with: catboost.core.CatBoostClassifier object at 0x00000175D93E9DC0\n",
    "12 - done in 4823s\n",
    "Score: 0.7069649737004864\n",
    "Obtained with: LGBMClassifier(boosting_type='dart', random_state=42)\n",
    "13 - done in 194s\n",
    "</code>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#gs.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">{'mean_fit_time': array([1.12846975, 1.93213859, 3.49252276, 1.20664921, 1.90970011,\n",
    "        3.44738073, 1.19674945, 1.9298975 , 3.48896518, 1.01345282,\n",
    "        1.63482342, 3.1525496 , 1.09063888, 1.71527624, 3.28194938,\n",
    "        1.06873031, 1.62983508, 3.28338637]),\n",
    " 'std_fit_time': array([0.16328593, 0.02055966, 0.06306082, 0.01070929, 0.07148658,\n",
    "        0.11888143, 0.05199477, 0.06873583, 0.08543938, 0.02194296,\n",
    "        0.03327168, 0.13876321, 0.05604037, 0.03026382, 0.19121445,\n",
    "        0.05841236, 0.01412593, 0.19140034]),\n",
    " 'mean_score_time': array([0.0305635 , 0.0313375 , 0.0289206 , 0.02932396, 0.03036981,\n",
    "        0.03311548, 0.03042021, 0.03111563, 0.03199601, 0.02480702,\n",
    "        0.03254519, 0.03337388, 0.02807384, 0.02978086, 0.03095374,\n",
    "        0.02895303, 0.03263464, 0.03402157]),\n",
    " 'std_score_time': array([0.00258001, 0.00388554, 0.00182127, 0.0054116 , 0.00370879,\n",
    "        0.00366714, 0.00742412, 0.00523109, 0.0009727 , 0.00519239,\n",
    "        0.00427954, 0.00293639, 0.00158762, 0.00664471, 0.00373306,\n",
    "        0.00939595, 0.00483121, 0.00494056]),\n",
    " 'param_classifier': masked_array(data=[LGBMClassifier(boosting_type='dart', random_state=42),\n",
    "                    LGBMClassifier(boosting_type='dart', random_state=42),\n",
    "                    LGBMClassifier(boosting_type='dart', random_state=42),\n",
    "                    LGBMClassifier(boosting_type='dart', random_state=42),\n",
    "                    LGBMClassifier(boosting_type='dart', random_state=42),\n",
    "                    LGBMClassifier(boosting_type='dart', random_state=42),\n",
    "                    LGBMClassifier(boosting_type='dart', random_state=42),\n",
    "                    LGBMClassifier(boosting_type='dart', random_state=42),\n",
    "                    LGBMClassifier(boosting_type='dart', random_state=42),\n",
    "                    LGBMClassifier(boosting_type='dart', random_state=42),\n",
    "                    LGBMClassifier(boosting_type='dart', random_state=42),\n",
    "                    LGBMClassifier(boosting_type='dart', random_state=42),\n",
    "                    LGBMClassifier(boosting_type='dart', random_state=42),\n",
    "                    LGBMClassifier(boosting_type='dart', random_state=42),\n",
    "                    LGBMClassifier(boosting_type='dart', random_state=42),\n",
    "                    LGBMClassifier(boosting_type='dart', random_state=42),\n",
    "                    LGBMClassifier(boosting_type='dart', random_state=42),\n",
    "                    LGBMClassifier(boosting_type='dart', random_state=42)],\n",
    "              mask=[False, False, False, False, False, False, False, False,\n",
    "                    False, False, False, False, False, False, False, False,\n",
    "                    False, False],\n",
    "        fill_value='?',\n",
    "             dtype=object),\n",
    " 'param_classifier__boosting_type': masked_array(data=['dart', 'dart', 'dart', 'dart', 'dart', 'dart', 'dart',\n",
    "                    'dart', 'dart', 'dart', 'dart', 'dart', 'dart', 'dart',\n",
    "                    'dart', 'dart', 'dart', 'dart'],\n",
    "              mask=[False, False, False, False, False, False, False, False,\n",
    "                    False, False, False, False, False, False, False, False,\n",
    "                    False, False],\n",
    "        fill_value='?',\n",
    "             dtype=object),\n",
    " 'param_classifier__class_weight': masked_array(data=[None, None, None, None, None, None, None, None, None,\n",
    "                    {0: 0.08781952865764357, 1: 11.386988922457201},\n",
    "                    {0: 0.08781952865764357, 1: 11.386988922457201},\n",
    "                    {0: 0.08781952865764357, 1: 11.386988922457201},\n",
    "                    {0: 0.08781952865764357, 1: 11.386988922457201},\n",
    "                    {0: 0.08781952865764357, 1: 11.386988922457201},\n",
    "                    {0: 0.08781952865764357, 1: 11.386988922457201},\n",
    "                    {0: 0.08781952865764357, 1: 11.386988922457201},\n",
    "                    {0: 0.08781952865764357, 1: 11.386988922457201},\n",
    "                    {0: 0.08781952865764357, 1: 11.386988922457201}],\n",
    "              mask=[False, False, False, False, False, False, False, False,\n",
    "                    False, False, False, False, False, False, False, False,\n",
    "                    False, False],\n",
    "        fill_value='?',\n",
    "             dtype=object),\n",
    " 'param_classifier__learning_rate': masked_array(data=[0.01, 0.01, 0.01, 0.03162277660168379,\n",
    "                    0.03162277660168379, 0.03162277660168379, 0.1, 0.1,\n",
    "                    0.1, 0.01, 0.01, 0.01, 0.03162277660168379,\n",
    "                    0.03162277660168379, 0.03162277660168379, 0.1, 0.1,\n",
    "                    0.1],\n",
    "              mask=[False, False, False, False, False, False, False, False,\n",
    "                    False, False, False, False, False, False, False, False,\n",
    "                    False, False],\n",
    "        fill_value='?',\n",
    "             dtype=object),\n",
    " 'param_classifier__num_leaves': masked_array(data=[10, 31, 100, 10, 31, 100, 10, 31, 100, 10, 31, 100, 10,\n",
    "                    31, 100, 10, 31, 100],\n",
    "              mask=[False, False, False, False, False, False, False, False,\n",
    "                    False, False, False, False, False, False, False, False,\n",
    "                    False, False],\n",
    "        fill_value='?',\n",
    "             dtype=object),\n",
    " 'params': [{'classifier': LGBMClassifier(boosting_type='dart', random_state=42),\n",
    "   'classifier__boosting_type': 'dart',\n",
    "   'classifier__class_weight': None,\n",
    "   'classifier__learning_rate': 0.01,\n",
    "   'classifier__num_leaves': 10},\n",
    "  {'classifier': LGBMClassifier(boosting_type='dart', random_state=42),\n",
    "   'classifier__boosting_type': 'dart',\n",
    "   'classifier__class_weight': None,\n",
    "   'classifier__learning_rate': 0.01,\n",
    "   'classifier__num_leaves': 31},\n",
    "  {'classifier': LGBMClassifier(boosting_type='dart', random_state=42),\n",
    "   'classifier__boosting_type': 'dart',\n",
    "   'classifier__class_weight': None,\n",
    "   'classifier__learning_rate': 0.01,\n",
    "   'classifier__num_leaves': 100},\n",
    "  {'classifier': LGBMClassifier(boosting_type='dart', random_state=42),\n",
    "   'classifier__boosting_type': 'dart',\n",
    "   'classifier__class_weight': None,\n",
    "   'classifier__learning_rate': 0.03162277660168379,\n",
    "   'classifier__num_leaves': 10},\n",
    "  {'classifier': LGBMClassifier(boosting_type='dart', random_state=42),\n",
    "   'classifier__boosting_type': 'dart',\n",
    "   'classifier__class_weight': None,\n",
    "   'classifier__learning_rate': 0.03162277660168379,\n",
    "   'classifier__num_leaves': 31},\n",
    "  {'classifier': LGBMClassifier(boosting_type='dart', random_state=42),\n",
    "   'classifier__boosting_type': 'dart',\n",
    "   'classifier__class_weight': None,\n",
    "   'classifier__learning_rate': 0.03162277660168379,\n",
    "   'classifier__num_leaves': 100},\n",
    "  {'classifier': LGBMClassifier(boosting_type='dart', random_state=42),\n",
    "   'classifier__boosting_type': 'dart',\n",
    "   'classifier__class_weight': None,\n",
    "   'classifier__learning_rate': 0.1,\n",
    "   'classifier__num_leaves': 10},\n",
    "  {'classifier': LGBMClassifier(boosting_type='dart', random_state=42),\n",
    "   'classifier__boosting_type': 'dart',\n",
    "   'classifier__class_weight': None,\n",
    "   'classifier__learning_rate': 0.1,\n",
    "   'classifier__num_leaves': 31},\n",
    "  {'classifier': LGBMClassifier(boosting_type='dart', random_state=42),\n",
    "   'classifier__boosting_type': 'dart',\n",
    "   'classifier__class_weight': None,\n",
    "   'classifier__learning_rate': 0.1,\n",
    "   'classifier__num_leaves': 100},\n",
    "  {'classifier': LGBMClassifier(boosting_type='dart', random_state=42),\n",
    "   'classifier__boosting_type': 'dart',\n",
    "   'classifier__class_weight': {0: 0.08781952865764357, 1: 11.386988922457201},\n",
    "   'classifier__learning_rate': 0.01,\n",
    "   'classifier__num_leaves': 10},\n",
    "  {'classifier': LGBMClassifier(boosting_type='dart', random_state=42),\n",
    "   'classifier__boosting_type': 'dart',\n",
    "   'classifier__class_weight': {0: 0.08781952865764357, 1: 11.386988922457201},\n",
    "   'classifier__learning_rate': 0.01,\n",
    "   'classifier__num_leaves': 31},\n",
    "  {'classifier': LGBMClassifier(boosting_type='dart', random_state=42),\n",
    "   'classifier__boosting_type': 'dart',\n",
    "   'classifier__class_weight': {0: 0.08781952865764357, 1: 11.386988922457201},\n",
    "   'classifier__learning_rate': 0.01,\n",
    "   'classifier__num_leaves': 100},\n",
    "  {'classifier': LGBMClassifier(boosting_type='dart', random_state=42),\n",
    "   'classifier__boosting_type': 'dart',\n",
    "   'classifier__class_weight': {0: 0.08781952865764357, 1: 11.386988922457201},\n",
    "   'classifier__learning_rate': 0.03162277660168379,\n",
    "   'classifier__num_leaves': 10},\n",
    "  {'classifier': LGBMClassifier(boosting_type='dart', random_state=42),\n",
    "   'classifier__boosting_type': 'dart',\n",
    "   'classifier__class_weight': {0: 0.08781952865764357, 1: 11.386988922457201},\n",
    "   'classifier__learning_rate': 0.03162277660168379,\n",
    "   'classifier__num_leaves': 31},\n",
    "  {'classifier': LGBMClassifier(boosting_type='dart', random_state=42),\n",
    "   'classifier__boosting_type': 'dart',\n",
    "   'classifier__class_weight': {0: 0.08781952865764357, 1: 11.386988922457201},\n",
    "   'classifier__learning_rate': 0.03162277660168379,\n",
    "   'classifier__num_leaves': 100},\n",
    "  {'classifier': LGBMClassifier(boosting_type='dart', random_state=42),\n",
    "   'classifier__boosting_type': 'dart',\n",
    "   'classifier__class_weight': {0: 0.08781952865764357, 1: 11.386988922457201},\n",
    "   'classifier__learning_rate': 0.1,\n",
    "   'classifier__num_leaves': 10},\n",
    "  {'classifier': LGBMClassifier(boosting_type='dart', random_state=42),\n",
    "   'classifier__boosting_type': 'dart',\n",
    "   'classifier__class_weight': {0: 0.08781952865764357, 1: 11.386988922457201},\n",
    "   'classifier__learning_rate': 0.1,\n",
    "   'classifier__num_leaves': 31},\n",
    "  {'classifier': LGBMClassifier(boosting_type='dart', random_state=42),\n",
    "   'classifier__boosting_type': 'dart',\n",
    "   'classifier__class_weight': {0: 0.08781952865764357, 1: 11.386988922457201},\n",
    "   'classifier__learning_rate': 0.1,\n",
    "   'classifier__num_leaves': 100}],\n",
    " 'split0_test_score': array([0.64817095, 0.67550031, 0.64628714, 0.6726434 , 0.69122044,\n",
    "        0.68749539, 0.70733493, 0.71905764, 0.69418801, 0.60924937,\n",
    "        0.59878631, 0.59178729, 0.62355097, 0.63450485, 0.6273583 ,\n",
    "        0.65516429, 0.6262859 , 0.64346711]),\n",
    " 'split1_test_score': array([0.65688071, 0.65286344, 0.60819399, 0.65186196, 0.66716221,\n",
    "        0.63343244, 0.67547478, 0.69234392, 0.67710893, 0.64053643,\n",
    "        0.63311469, 0.64089106, 0.6497058 , 0.65401245, 0.62346586,\n",
    "        0.65688639, 0.65229603, 0.63346932]),\n",
    " 'split2_test_score': array([0.65185061, 0.6361702 , 0.62084726, 0.68161133, 0.64918945,\n",
    "        0.65259108, 0.68548392, 0.67246183, 0.65605797, 0.61199848,\n",
    "        0.60011972, 0.59785292, 0.62040184, 0.64187552, 0.60677262,\n",
    "        0.62763633, 0.60400933, 0.60970046]),\n",
    " 'split3_test_score': array([0.70101964, 0.70594193, 0.66230517, 0.7343664 , 0.7193839 ,\n",
    "        0.72008749, 0.73396921, 0.73971141, 0.72984981, 0.66129517,\n",
    "        0.63344379, 0.66828284, 0.66985457, 0.66448119, 0.65616577,\n",
    "        0.65703959, 0.62347154, 0.66181719]),\n",
    " 'split4_test_score': array([0.67793167, 0.65333156, 0.6414528 , 0.67950056, 0.68006514,\n",
    "        0.64267557, 0.67786926, 0.71125006, 0.6892799 , 0.62200761,\n",
    "        0.60928342, 0.60181912, 0.6276108 , 0.61687254, 0.63681138,\n",
    "        0.61947412, 0.65088318, 0.59407396]),\n",
    " 'mean_test_score': array([0.66717072, 0.66476149, 0.63581727, 0.68399673, 0.68140423,\n",
    "        0.6672564 , 0.69602642, 0.70696497, 0.68929692, 0.62901741,\n",
    "        0.61494959, 0.62012665, 0.6382248 , 0.64234931, 0.63011479,\n",
    "        0.64324015, 0.63138919, 0.62850561]),\n",
    " 'std_test_score': array([0.01981479, 0.02408659, 0.01913182, 0.02729304, 0.02358489,\n",
    "        0.03213749, 0.02204874, 0.02298333, 0.02417368, 0.0195146 ,\n",
    "        0.01539668, 0.02961278, 0.01885679, 0.01635038, 0.01624907,\n",
    "        0.01629192, 0.01819616, 0.02407205]),\n",
    " 'rank_test_score': array([ 7,  8, 12,  4,  5,  6,  2,  1,  3, 15, 18, 17, 11, 10, 14,  9, 13,\n",
    "        16])}\n",
    "</code>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo\n",
    "# Ce calcul date de la version 7 mais si je le refais ici en mettant à jour les\n",
    "# valeurs la conclusion sera identique.\n",
    "t_check = pd.DataFrame(columns=[\"clf\", \"t_tot\", \"rt_x_nl\", \"run_time\", \"n_loops\"])\n",
    "t_check.clf = dA.clf\n",
    "t_check.t_tot = [2, 153, 160, 2, 2, 18, 222, 346, 1397, 4513, 127]\n",
    "#t_check.run_time = result_df[\"run_time (s)\"] # non car il est sorted par score.\n",
    "t_check.run_time = [1, 19, 20, 1.6, 1.1, 2.3, 9.2, 14, 116, 564, 7]\n",
    "t_check.n_loops = nl\n",
    "t_check.rt_x_nl = t_check.run_time*t_check.n_loops\n",
    "t_check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a ```t_tot``` environ identique à ```rt_x_nl``` donc les temps sont\n",
    "correctment évalués."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.8. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_N = clean_csv(pd.read_csv(\"result_df_None.csv\"))\n",
    "#res_U = clean_csv(pd.read_csv(\"result_df_RandomUnderSampler.csv\")).sort_values(by=\"score\")\n",
    "#res_O = clean_csv(pd.read_csv(\"result_df_RandomOverSampler.csv\")).sort_values(by=\"score\")\n",
    "res_S = clean_csv(pd.read_csv(\"result_df_SMOTE.csv\"))\n",
    "#res = [res_N, res_U, res_O, res_S]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>best_score</th>\n",
       "      <th>avg_score_folds</th>\n",
       "      <th>fold0_score</th>\n",
       "      <th>fold1_score</th>\n",
       "      <th>fold2_score</th>\n",
       "      <th>fold3_score</th>\n",
       "      <th>fold4_score</th>\n",
       "      <th>run_time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GaussianNB()</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.492</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.481</td>\n",
       "      <td>0.723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DummyClassifier(strategy='most_frequent')</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MultinomialNB(alpha=1)</td>\n",
       "      <td>0.624</td>\n",
       "      <td>0.624</td>\n",
       "      <td>0.624</td>\n",
       "      <td>0.619</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNeighborsClassifier(n_neighbors=1000, weights...</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.631</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.642</td>\n",
       "      <td>1.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier(criterion='entropy', ma...</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.691</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.669</td>\n",
       "      <td>1.950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SGDClassifier(loss='log', penalty='elasticnet')</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0.691</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.691</td>\n",
       "      <td>7.530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifier(criterion='entropy', ma...</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.701</td>\n",
       "      <td>4.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&lt;catboost.core.CatBoostClassifier object at 0x...</td>\n",
       "      <td>0.712</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>183.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression(C=0.1, n_jobs=1, random_sta...</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.718</td>\n",
       "      <td>12.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XGBClassifier(base_score=None, booster='dart',...</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.739</td>\n",
       "      <td>78.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LGBMClassifier(boosting_type='dart', num_leave...</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.735</td>\n",
       "      <td>3.920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           classifier  best_score  \\\n",
       "0                                        GaussianNB()       0.493   \n",
       "1           DummyClassifier(strategy='most_frequent')       0.500   \n",
       "2                              MultinomialNB(alpha=1)       0.624   \n",
       "3   KNeighborsClassifier(n_neighbors=1000, weights...       0.652   \n",
       "4   DecisionTreeClassifier(criterion='entropy', ma...       0.687   \n",
       "5     SGDClassifier(loss='log', penalty='elasticnet')       0.710   \n",
       "6   RandomForestClassifier(criterion='entropy', ma...       0.711   \n",
       "7   <catboost.core.CatBoostClassifier object at 0x...       0.712   \n",
       "8   LogisticRegression(C=0.1, n_jobs=1, random_sta...       0.725   \n",
       "9   XGBClassifier(base_score=None, booster='dart',...       0.742   \n",
       "10  LGBMClassifier(boosting_type='dart', num_leave...       0.745   \n",
       "\n",
       "    avg_score_folds  fold0_score  fold1_score  fold2_score  fold3_score  \\\n",
       "0             0.493        0.493        0.496        0.492        0.503   \n",
       "1             0.500        0.500        0.500        0.500        0.500   \n",
       "2             0.624        0.624        0.619        0.620        0.662   \n",
       "3             0.653        0.674        0.631        0.638        0.681   \n",
       "4             0.688        0.691        0.683        0.690        0.705   \n",
       "5             0.710        0.715        0.691        0.704        0.749   \n",
       "6             0.714        0.731        0.704        0.699        0.735   \n",
       "7               NaN          NaN          NaN          NaN          NaN   \n",
       "8             0.725        0.739        0.702        0.706        0.760   \n",
       "9             0.745        0.747        0.754        0.728        0.758   \n",
       "10            0.746        0.739        0.755        0.744        0.758   \n",
       "\n",
       "    fold4_score  run_time (s)  \n",
       "0         0.481         0.723  \n",
       "1         0.500         0.302  \n",
       "2         0.596         0.401  \n",
       "3         0.642         1.300  \n",
       "4         0.669         1.950  \n",
       "5         0.691         7.530  \n",
       "6         0.701         4.030  \n",
       "7           NaN       183.000  \n",
       "8         0.718        12.000  \n",
       "9         0.739        78.000  \n",
       "10        0.735         3.920  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>best_score</th>\n",
       "      <th>avg_score_folds</th>\n",
       "      <th>fold0_score</th>\n",
       "      <th>fold1_score</th>\n",
       "      <th>fold2_score</th>\n",
       "      <th>fold3_score</th>\n",
       "      <th>fold4_score</th>\n",
       "      <th>run_time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GaussianNB()</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.492</td>\n",
       "      <td>1.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DummyClassifier(strategy='most_frequent')</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MultinomialNB(alpha=10)</td>\n",
       "      <td>0.619</td>\n",
       "      <td>0.619</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.601</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTreeClassifier(max_depth=3, min_sample...</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.626</td>\n",
       "      <td>0.621</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.666</td>\n",
       "      <td>9.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNeighborsClassifier(n_neighbors=1000, weights...</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.671</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.640</td>\n",
       "      <td>2.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;catboost.core.CatBoostClassifier object at 0x...</td>\n",
       "      <td>0.670</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>603.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifier(random_state=42)</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.683</td>\n",
       "      <td>15.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SGDClassifier(class_weight={0: 0.0878195286576...</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.681</td>\n",
       "      <td>24.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LGBMClassifier(boosting_type='dart', random_st...</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.711</td>\n",
       "      <td>11.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LogisticRegression(C=0.01, n_jobs=1, random_st...</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.691</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.708</td>\n",
       "      <td>20.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>XGBClassifier(base_score=None, booster='dart',...</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.729</td>\n",
       "      <td>0.726</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.732</td>\n",
       "      <td>143.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           classifier  best_score  \\\n",
       "0                                        GaussianNB()       0.499   \n",
       "1           DummyClassifier(strategy='most_frequent')       0.500   \n",
       "2                             MultinomialNB(alpha=10)       0.619   \n",
       "3   DecisionTreeClassifier(max_depth=3, min_sample...       0.638   \n",
       "4   KNeighborsClassifier(n_neighbors=1000, weights...       0.649   \n",
       "5   <catboost.core.CatBoostClassifier object at 0x...       0.670   \n",
       "6             RandomForestClassifier(random_state=42)       0.686   \n",
       "7   SGDClassifier(class_weight={0: 0.0878195286576...       0.692   \n",
       "8   LGBMClassifier(boosting_type='dart', random_st...       0.707   \n",
       "9   LogisticRegression(C=0.01, n_jobs=1, random_st...       0.713   \n",
       "10  XGBClassifier(base_score=None, booster='dart',...       0.717   \n",
       "\n",
       "    avg_score_folds  fold0_score  fold1_score  fold2_score  fold3_score  \\\n",
       "0             0.499        0.498        0.503        0.498        0.505   \n",
       "1             0.500        0.500        0.500        0.500        0.500   \n",
       "2             0.619        0.630        0.599        0.610        0.656   \n",
       "3             0.645        0.656        0.626        0.621        0.658   \n",
       "4             0.649        0.671        0.614        0.627        0.695   \n",
       "5               NaN          NaN          NaN          NaN          NaN   \n",
       "6             0.692        0.686        0.687        0.677        0.724   \n",
       "7             0.695        0.698        0.676        0.683        0.739   \n",
       "8             0.710        0.719        0.692        0.685        0.740   \n",
       "9             0.715        0.728        0.691        0.690        0.757   \n",
       "10            0.729        0.726        0.739        0.705        0.742   \n",
       "\n",
       "    fold4_score  run_time (s)  \n",
       "0         0.492          1.67  \n",
       "1         0.500          1.07  \n",
       "2         0.601          1.18  \n",
       "3         0.666          9.41  \n",
       "4         0.640          2.42  \n",
       "5           NaN        603.00  \n",
       "6         0.683         15.00  \n",
       "7         0.681         24.00  \n",
       "8         0.711         11.00  \n",
       "9         0.708         20.00  \n",
       "10        0.732        143.00  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partons sur les résultats de SMOTE (parce que ça fait partie de l'exercice)\n",
    "même s'ils ne sont pas les meilleurs, ça me donnera une marge de progression\n",
    "pour le fine tuning, au moins.  \n",
    "Je vais utiliser LGBM car il compute un peu plus vite que la LogisticReg et\n",
    "beaucoup plus vite que XGB ou CatB, et que c'est l'algo choisi par les\n",
    "meilleures équipes de la compétition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Fine tuning with the best classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "parm = {}\n",
    "parm[\"classifier__boosting_type\"] = [\n",
    "    \"gbdt\",\n",
    "    \"rf\",\n",
    "    \"dart\",\n",
    "]\n",
    "parm[\"classifier__learning_rate\"] = [\n",
    "    10**-2,\n",
    "    10**-1.5,\n",
    "    10**-1,\n",
    "]\n",
    "parm[\"classifier__num_leaves\"] = [\n",
    "    10**1,\n",
    "    10**1.5,\n",
    "    10**2,\n",
    "]\n",
    "parm[\"classifier__num_iterations\"] = [\n",
    "    10**3,\n",
    "    10**4,\n",
    "]\n",
    "parm[\"classifier__feature_fraction\"] = [\n",
    "    .8,\n",
    "    .9,\n",
    "    .95,\n",
    "]\n",
    "parm[\"classifier__lambda_l1\"] = [\n",
    "    10**-2,\n",
    "    10**-1.5,\n",
    "]\n",
    "parm[\"classifier__lambda_l2\"] = [\n",
    "    10**-2,\n",
    "    10**-1.5,\n",
    "]\n",
    "parm[\"classifier__min_gain_to_split\"] = [.02]\n",
    "parm[\"classifier__max_depth\"] = [\n",
    "    6,\n",
    "    8,\n",
    "]\n",
    "parm[\"classifier__min_sum_hessian_in_leaf\"] = [1]\n",
    "parm[\"classifier__bagging_fraction\"] = [\n",
    "    .8,\n",
    "    .9,\n",
    "    .95,\n",
    "]\n",
    "#parm[\"classifier__silent\"] = [-1]\n",
    "#parm[\"classifier__verbose\"] = [-1]\n",
    "parm[\"classifier\"] = [clf13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3888"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.prod([len(i) for i in parm.values()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C'est trop à mon avis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "parm = {}\n",
    "parm[\"classifier__boosting_type\"] = [\n",
    "    \"gbdt\",\n",
    "#    \"rf\",\n",
    "#    \"dart\",\n",
    "]\n",
    "parm[\"classifier__learning_rate\"] = [\n",
    "    10**-2,\n",
    "    10**-1.5,\n",
    "    10**-1,\n",
    "]\n",
    "#parm[\"classifier__num_leaves\"] = [\n",
    "#    10**1,\n",
    "#    10**1.5,\n",
    "#    10**2,\n",
    "#]\n",
    "#parm[\"classifier__num_iterations\"] = [\n",
    "#    10**3,\n",
    "#    10**4,\n",
    "#]\n",
    "parm[\"classifier__feature_fraction\"] = [\n",
    "    .8,\n",
    "    .9,\n",
    "    .95,\n",
    "]\n",
    "parm[\"classifier__lambda_l1\"] = [\n",
    "    10**-2,\n",
    "    10**-1.5,\n",
    "]\n",
    "parm[\"classifier__lambda_l2\"] = [\n",
    "    10**-2,\n",
    "    10**-1.5,\n",
    "]\n",
    "parm[\"classifier__min_gain_to_split\"] = [.02]\n",
    "parm[\"classifier__max_depth\"] = [\n",
    "    6,\n",
    "    8,\n",
    "]\n",
    "parm[\"classifier__min_sum_hessian_in_leaf\"] = [1]\n",
    "parm[\"classifier__bagging_fraction\"] = [\n",
    "    .8,\n",
    "    .9,\n",
    "    .95,\n",
    "]\n",
    "#parm[\"classifier__silent\"] = [-1]\n",
    "#parm[\"classifier__verbose\"] = [-1]\n",
    "parm[\"classifier\"] = [clf13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.prod([len(i) for i in parm.values()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok testons ça."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce premier fine tuning a donné:\n",
    "```\n",
    "parm = {}\n",
    "parm[\"classifier__boosting_type\"] = [\n",
    "    \"gbdt\",\n",
    "#    \"rf\",\n",
    "#    \"dart\",\n",
    "]\n",
    "parm[\"classifier__learning_rate\"] = [\n",
    "    10**-2,\n",
    "    10**-1.5,\n",
    "    10**-1,\n",
    "]\n",
    "    ? pas vu dans l'output, peut-être parce que c'est la valeur par\n",
    "    défaut et donc best_estimator_ pense que ce n'est pas nécessaire\n",
    "    de préciser que le meilleur learning_rate trouvé est .1.\n",
    "#parm[\"classifier__num_leaves\"] = [\n",
    "#    10**1,\n",
    "#    10**1.5,\n",
    "#    10**2,\n",
    "#]\n",
    "#parm[\"classifier__num_iterations\"] = [\n",
    "#    10**3,\n",
    "#    10**4,\n",
    "#]\n",
    "parm[\"classifier__feature_fraction\"] = [\n",
    "    .8,\n",
    "    .9,     <------------------------------------------------\n",
    "    .95,\n",
    "]\n",
    "parm[\"classifier__lambda_l1\"] = [\n",
    "    10**-2,     <------------------------------------------------\n",
    "    10**-1.5,\n",
    "]\n",
    "parm[\"classifier__lambda_l2\"] = [\n",
    "    10**-2,\n",
    "    10**-1.5,     <------------------------------------------------\n",
    "]\n",
    "parm[\"classifier__min_gain_to_split\"] = [.02]\n",
    "parm[\"classifier__max_depth\"] = [\n",
    "    6,\n",
    "    8,     <------------------------------------------------\n",
    "]\n",
    "parm[\"classifier__min_sum_hessian_in_leaf\"] = [1]\n",
    "parm[\"classifier__bagging_fraction\"] = [\n",
    "    .8,\n",
    "    .9,     <------------------------------------------------\n",
    "    .95,\n",
    "]\n",
    "#parm[\"classifier__silent\"] = [-1]\n",
    "parm[\"classifier__verbose\"] = [-1]\n",
    "parm[\"classifier\"] = [clf13]\n",
    "```\n",
    "\n",
    "Je teste maintenant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "parm = {}\n",
    "parm[\"classifier__boosting_type\"] = [\n",
    "    \"gbdt\",\n",
    "]\n",
    "parm[\"classifier__learning_rate\"] = [\n",
    "    10**-1.1,\n",
    "    10**-1,\n",
    "    10**-.9\n",
    "]\n",
    "parm[\"classifier__num_leaves\"] = [\n",
    "    25,\n",
    "    30,\n",
    "    35,\n",
    "]\n",
    "#parm[\"classifier__num_iterations\"] = [\n",
    "#    10**3,\n",
    "#    10**4,\n",
    "#]\n",
    "parm[\"classifier__feature_fraction\"] = [\n",
    "    .9,\n",
    "]\n",
    "parm[\"classifier__lambda_l1\"] = [\n",
    "    10**-2,\n",
    "]\n",
    "parm[\"classifier__lambda_l2\"] = [\n",
    "    10**-1.5,\n",
    "]\n",
    "parm[\"classifier__min_gain_to_split\"] = [.02]\n",
    "parm[\"classifier__max_depth\"] = [\n",
    "    7,\n",
    "    8,\n",
    "    9,\n",
    "]\n",
    "parm[\"classifier__min_sum_hessian_in_leaf\"] = [1]\n",
    "parm[\"classifier__bagging_fraction\"] = [\n",
    "    .9,\n",
    "]\n",
    "#parm[\"classifier__silent\"] = [-1]\n",
    "#parm[\"classifier__verbose\"] = [-1]\n",
    "parm[\"classifier\"] = [clf13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.prod([len(i) for i in parm.values()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je trouve:\n",
    "```\n",
    "parm = {}\n",
    "parm[\"classifier__boosting_type\"] = [\n",
    "    \"gbdt\",\n",
    "]\n",
    "parm[\"classifier__learning_rate\"] = [\n",
    "    10**-1.1,     <-------------------------------------- sans SMOTE\n",
    "    10**-1,     <-------------------------------------- avec SMOTE (car\n",
    "                                                        rien d'indiqué)\n",
    "    10**-.9\n",
    "]\n",
    "parm[\"classifier__num_leaves\"] = [\n",
    "    25,     <-------------------------------------- avec SMOTE\n",
    "    30,     <-------------------------------------- sans SMOTE\n",
    "    35,\n",
    "]\n",
    "#parm[\"classifier__num_iterations\"] = [\n",
    "#    10**3,\n",
    "#    10**4,\n",
    "#]\n",
    "parm[\"classifier__feature_fraction\"] = [\n",
    "    .9,\n",
    "]\n",
    "parm[\"classifier__lambda_l1\"] = [\n",
    "    10**-2,\n",
    "]\n",
    "parm[\"classifier__lambda_l2\"] = [\n",
    "    10**-1.5,\n",
    "]\n",
    "parm[\"classifier__min_gain_to_split\"] = [.02]\n",
    "parm[\"classifier__max_depth\"] = [\n",
    "    7,     <-------------------------------------- sans SMOTE\n",
    "    8,     <-------------------------------------- avec SMOTE\n",
    "    9,\n",
    "]\n",
    "parm[\"classifier__min_sum_hessian_in_leaf\"] = [1]\n",
    "parm[\"classifier__bagging_fraction\"] = [\n",
    "    .9,\n",
    "]\n",
    "#parm[\"classifier__silent\"] = [-1]\n",
    "parm[\"classifier__verbose\"] = [-1]\n",
    "parm[\"classifier\"] = [clf13]\n",
    "```\n",
    "Choisissons une seule valeur par paramètre pour pouvoir run plus rapidement\n",
    "pendant le debug des étapes suivantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "parm = {}\n",
    "parm[\"classifier__boosting_type\"] = [\n",
    "    \"gbdt\",\n",
    "]\n",
    "parm[\"classifier__learning_rate\"] = [\n",
    "    10**-1.1,\n",
    "#    10**-1,\n",
    "#    10**-.9\n",
    "]\n",
    "parm[\"classifier__num_leaves\"] = [\n",
    "    25,\n",
    "#    30,\n",
    "#    35,\n",
    "]\n",
    "#parm[\"classifier__num_iterations\"] = [\n",
    "#    10**3,\n",
    "#    10**4,\n",
    "#]\n",
    "parm[\"classifier__feature_fraction\"] = [\n",
    "    .9,\n",
    "]\n",
    "parm[\"classifier__lambda_l1\"] = [\n",
    "    10**-2,\n",
    "]\n",
    "parm[\"classifier__lambda_l2\"] = [\n",
    "    10**-1.5,\n",
    "]\n",
    "parm[\"classifier__min_gain_to_split\"] = [.02]\n",
    "parm[\"classifier__max_depth\"] = [\n",
    "    7,\n",
    "#    8,\n",
    "#    9,\n",
    "]\n",
    "parm[\"classifier__min_sum_hessian_in_leaf\"] = [1]\n",
    "parm[\"classifier__bagging_fraction\"] = [\n",
    "    .9,\n",
    "]\n",
    "#parm[\"classifier__silent\"] = [-1]\n",
    "#parm[\"classifier__verbose\"] = [-1]\n",
    "parm[\"classifier\"] = [clf13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.prod([len(i) for i in parm.values()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1. Sans SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.02, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.02\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.03162277660168379, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03162277660168379\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.02, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.02\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.03162277660168379, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03162277660168379\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.02, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.02\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.03162277660168379, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03162277660168379\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.02, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.02\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.03162277660168379, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03162277660168379\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.02, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.02\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.03162277660168379, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03162277660168379\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.02, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.02\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.03162277660168379, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03162277660168379\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.02, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.02\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.03162277660168379, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03162277660168379\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.02, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.02\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.03162277660168379, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03162277660168379\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.02, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.02\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.03162277660168379, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03162277660168379\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.02, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.02\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.03162277660168379, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03162277660168379\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.02, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.02\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.03162277660168379, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03162277660168379\n",
      "Score: 0.752\n",
      "Obtained with: LGBMClassifier(bagging_fraction=0.9, feature_fraction=0.9, lambda_l1=0.01,\n",
      "               lambda_l2=0.03162277660168379, learning_rate=0.07943282347242814,\n",
      "               max_depth=7, min_gain_to_split=0.02, min_sum_hessian_in_leaf=1,\n",
      "               num_leaves=25, random_state=42, verbose=-1)\n",
      "run_time per search (s) 18.0\n",
      "Fine tuning with class_weight and LGBM - done in 36s\n"
     ]
    }
   ],
   "source": [
    "with timer(\"Fine tuning with class_weight and LGBM\"):\n",
    "    t_clf = time.perf_counter()\n",
    "    parm[\"classifier__class_weight\"] = cws\n",
    "    pipeline = imblearn.pipeline.Pipeline([(\"scaler\", scaler),\n",
    "                                           (\"sampler\", None),\n",
    "                                           (\"classifier\", clf13)])\n",
    "    # verbose=-1 ne fonctionne pas donc je supprime tous les warnings.\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    gs_N = GridSearchCV(\n",
    "        pipeline,\n",
    "        parm,\n",
    "        cv=5,\n",
    "        n_jobs=None,\n",
    "        scoring=\"roc_auc\",\n",
    "        # scoring=[\"roc_auc\", \"accuracy\"],\n",
    "        # refit=\"roc_auc\",\n",
    "        # n_iter=5, # seulement pour RandomSearchCV ?\n",
    "        # random_state=42, # seulement pour RandomSearchCV ?\n",
    "    ).fit(X_train, y_train)\n",
    "\n",
    "    n_loops = math.prod([len(i) for i in parm.values()])\n",
    "    t_mean = (time.perf_counter() - t_clf)/(n_loops)\n",
    "    if t_mean > 10:\n",
    "        t_mean = round(t_mean, 0)\n",
    "    elif t_mean > 1:\n",
    "        t_mean = round(t_mean, 2)\n",
    "    elif t_mean > .001:\n",
    "        t_mean = round(t_mean, 3)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    print(\"Score:\", round(gs_N.best_score_, 3))\n",
    "    print(\"Obtained with:\", gs_N.best_params_[\"classifier\"])\n",
    "    print(\"run_time per search (s)\", t_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_N = gs_N.best_estimator_.predict(X_test)\n",
    "# On peut aussi faire un predict_proba avec un seuil < .5 au lieu de faire un\n",
    "# oversampling ou de jouer sur class_weights.\n",
    "y_pred_proba_N = gs_N.best_estimator_.predict_proba(X_test)\n",
    "y_pred_proba_positive_N = y_pred_proba_N[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7589120796748671"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr_N, tpr_N, thresholds_N = roc_curve(y_test, y_pred_proba_positive_N)\n",
    "roc_auc_N = auc(fpr_N, tpr_N)\n",
    "roc_auc_N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.756"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(fpr_N, tpr_N, label='ROC curve (area = %0.2f)' % roc_auc_N)\n",
    "ax.plot([0, 1], [0, 1], 'k--')  # diagonal line\n",
    "ax.set_xlim([0.0, 1.0])\n",
    "ax.set_ylim([0.0, 1.05])\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title('Receiver operating characteristic example')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1. Avec SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.02, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.02\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.03162277660168379, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03162277660168379\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.02, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.02\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.03162277660168379, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03162277660168379\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.02, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.02\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.03162277660168379, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03162277660168379\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.02, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.02\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.03162277660168379, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03162277660168379\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.02, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.02\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.03162277660168379, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03162277660168379\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.02, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.02\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.03162277660168379, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03162277660168379\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.02, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.02\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.03162277660168379, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03162277660168379\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.02, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.02\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.03162277660168379, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03162277660168379\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.02, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.02\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.03162277660168379, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03162277660168379\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.02, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.02\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.03162277660168379, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03162277660168379\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.02, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.02\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.03162277660168379, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03162277660168379\n",
      "Score: 0.735\n",
      "Obtained with: LGBMClassifier(bagging_fraction=0.9, feature_fraction=0.9, lambda_l1=0.01,\n",
      "               lambda_l2=0.03162277660168379, learning_rate=0.07943282347242814,\n",
      "               max_depth=7, min_gain_to_split=0.02, min_sum_hessian_in_leaf=1,\n",
      "               num_leaves=25, random_state=42, verbose=-1)\n",
      "run_time per search (s) 56.0\n",
      "Fine tuning with SMOTE and LGBM - done in 111s\n"
     ]
    }
   ],
   "source": [
    "with timer(\"Fine tuning with SMOTE and LGBM\"):\n",
    "    t_clf = time.perf_counter()\n",
    "    pipeline = imblearn.pipeline.Pipeline([(\"scaler\", scaler),\n",
    "                                           (\"sampler\", oversampler_2),\n",
    "                                           (\"classifier\", clf13)])\n",
    "    # verbose=-1 ne fonctionne pas donc je supprime tous les warnings.\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    gs_S = GridSearchCV(\n",
    "        pipeline,\n",
    "        parm,\n",
    "        cv=5,\n",
    "        n_jobs=None,\n",
    "        scoring=\"roc_auc\",\n",
    "        # scoring=[\"roc_auc\", \"accuracy\"],\n",
    "        # refit=\"roc_auc\",\n",
    "        # n_iter=5, # seulement pour RandomSearchCV ?\n",
    "        # random_state=42, # seulement pour RandomSearchCV ?\n",
    "    ).fit(X_train, y_train)\n",
    "\n",
    "    n_loops = math.prod([len(i) for i in parm.values()])\n",
    "    t_mean = (time.perf_counter() - t_clf)/(n_loops)\n",
    "    if t_mean > 10:\n",
    "        t_mean = round(t_mean, 0)\n",
    "    elif t_mean > 1:\n",
    "        t_mean = round(t_mean, 2)\n",
    "    elif t_mean > .001:\n",
    "        t_mean = round(t_mean, 3)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    print(\"Score:\", round(gs_S.best_score_, 3))\n",
    "    print(\"Obtained with:\", gs_S.best_params_[\"classifier\"])\n",
    "    print(\"run_time per search (s)\", t_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#y_pred = rs_cv.best_estimator_[best_algorithm].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_S = gs_S.best_estimator_.predict(X_test)\n",
    "# On peut aussi faire un predict_proba avec un seuil < .5 au lieu de faire un\n",
    "# oversampling ou de jouer sur class_weights.\n",
    "y_pred_proba_S = gs_S.best_estimator_.predict_proba(X_test)\n",
    "y_pred_proba_positive_S = y_pred_proba_S[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.739993261668979"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr_S, tpr_S, thresholds_S = roc_curve(y_test, y_pred_proba_positive_S)\n",
    "roc_auc_S = auc(fpr_S, tpr_S)\n",
    "roc_auc_S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.76"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(fpr_N, tpr_N, label='ROC curve (area = %0.2f)' % roc_auc_N)\n",
    "ax.plot(fpr_S, tpr_S, label='ROC curve (area = %0.2f)' % roc_auc_S)\n",
    "ax.plot([0, 1], [0, 1], 'k--')  # diagonal line\n",
    "ax.set_xlim([0.0, 1.0])\n",
    "ax.set_ylim([0.0, 1.05])\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title('Receiver operating characteristic example')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Fine tuning using an Fbeta scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    91904\n",
       "1.0     8093\n",
       "Name: TARGET, dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.TARGET.value_counts(\n",
    "    sort=True,\n",
    "    ascending=False,\n",
    "    dropna=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    18386\n",
       "1.0     1614\n",
       "Name: TARGET, dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts(\n",
    "    sort=True,\n",
    "    ascending=False,\n",
    "    dropna=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred_S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cf_matrix):\n",
    "\n",
    "    plt.figure(figsize=(7, 7))\n",
    "\n",
    "    group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "\n",
    "    group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "\n",
    "                    cf_matrix.flatten()]\n",
    "\n",
    "    group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "\n",
    "                         cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "\n",
    "    labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "\n",
    "              zip(group_names,group_counts,group_percentages)]\n",
    "\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "\n",
    "    sns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues')\n",
    "\n",
    "\n",
    "\n",
    "    plt.title(\"Prédiction des données\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>18361</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>1594</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Positive  Negative\n",
       "Positive     18361        25\n",
       "Negative      1594        20"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_df = pd.DataFrame(cm,\n",
    "                     index=['Positive', 'Negative'],\n",
    "                     columns=['Positive', 'Negative'])\n",
    "display(cm_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Confusion                 Predicted\n",
    "    Matrix               Positive    Negative\n",
    "              Positive      TP          FN     →  Recall (= Sensitivity, TPR)\n",
    "    Actual    Negative      FP          TN     →  FP Rate (= 1-Specificity)\n",
    "                            ↓           ↓\n",
    "                        Precision  False Omission Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                           1812          8\n",
    "                            171      \t9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Les \"négatifs\" sont les zéros et correspondent aux prêts remboursés.\n",
    "- Les \"positifs\" sont les uns et correspondent aux prêts non-remboursés.\n",
    "\n",
    "Donc là le modèle a accordé 171 prêts qui ne seront pas remboursés et a refusé\n",
    "8 prêts qui auraient été remboursés.  \n",
    "C'est très problématique.  \n",
    "- Un FN (prêt accordé non-remboursé) nous fait perdre la part non-remboursée du\n",
    "prêt. 100% dans le pire des cas.\n",
    "- Un FP (prêt remboursable non-accordé) nous fait perdre seulement le taux\n",
    "d'intérêts qu'on aurait touchés sur ce prêt, disons 10%.\n",
    "\n",
    "Considérons donc qu'un FN nous est 10fois plus coûteux qu'un FP et qu'on veut\n",
    "donc minimiser le nombre (10FN+FP)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je veux donc un $\\beta$ qui beaucoup plus d'importance au fait d'avoir un Recall\n",
    "proche de 1 qu'au fait d'avoir une Precision proche de 1.  \n",
    "Dans ce cas il faut choisir $\\beta = 2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "parm = {}\n",
    "parm[\"classifier__boosting_type\"] = [\n",
    "    \"gbdt\",\n",
    "]\n",
    "parm[\"classifier__learning_rate\"] = [\n",
    "    10**-1.1,\n",
    "    10**-1,\n",
    "    10**-.9\n",
    "]\n",
    "parm[\"classifier__num_leaves\"] = [\n",
    "    25,\n",
    "    30,\n",
    "    35,\n",
    "]\n",
    "#parm[\"classifier__num_iterations\"] = [\n",
    "#    10**3,\n",
    "#    10**4,\n",
    "#]\n",
    "parm[\"classifier__feature_fraction\"] = [\n",
    "    .9,\n",
    "]\n",
    "parm[\"classifier__lambda_l1\"] = [\n",
    "    10**-2.5,\n",
    "    10**-2,\n",
    "    10**-1.5,\n",
    "]\n",
    "parm[\"classifier__lambda_l2\"] = [\n",
    "    10**-2,\n",
    "    10**-1.5,\n",
    "    10**-1,\n",
    "]\n",
    "parm[\"classifier__min_gain_to_split\"] = [.02]\n",
    "parm[\"classifier__max_depth\"] = [\n",
    "    7,\n",
    "    8,\n",
    "    9,\n",
    "]\n",
    "parm[\"classifier__min_sum_hessian_in_leaf\"] = [1]\n",
    "parm[\"classifier__bagging_fraction\"] = [\n",
    "    .9,\n",
    "]\n",
    "#parm[\"classifier__silent\"] = [-1]\n",
    "#parm[\"classifier__verbose\"] = [-1]\n",
    "parm[\"classifier\"] = [clf13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "243"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.prod([len(i) for i in parm.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo\n",
    "with timer(\"Fine tuning with SMOTE and LGBM\"):\n",
    "    t_clf = time.perf_counter()\n",
    "    pipeline = imblearn.pipeline.Pipeline([(\"scaler\", scaler),\n",
    "                                           (\"sampler\", oversampler_2),\n",
    "                                           (\"classifier\", clf13)])\n",
    "    # verbose=-1 ne fonctionne pas donc je supprime tous les warnings.\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    fbeta_scorer = make_scorer(fbeta_score, beta=.5)\n",
    "    gs_Sb = GridSearchCV(\n",
    "        pipeline,\n",
    "        parm,\n",
    "        cv=5,\n",
    "        n_jobs=None,\n",
    "        scoring=fbeta_scorer,\n",
    "        # scoring=[\"roc_auc\", \"accuracy\"],\n",
    "        # refit=\"roc_auc\",\n",
    "        # n_iter=5, # seulement pour RandomSearchCV ?\n",
    "        # random_state=42, # seulement pour RandomSearchCV ?\n",
    "    ).fit(X_train, y_train)\n",
    "\n",
    "    n_loops = math.prod([len(i) for i in parm.values()])\n",
    "    t_mean = (time.perf_counter() - t_clf)/(n_loops)\n",
    "    if t_mean > 10:\n",
    "        t_mean = round(t_mean, 0)\n",
    "    elif t_mean > 1:\n",
    "        t_mean = round(t_mean, 2)\n",
    "    elif t_mean > .001:\n",
    "        t_mean = round(t_mean, 3)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    print(\"Score:\", round(gs_Sb.best_score_, 3))\n",
    "    print(\"Obtained with:\", gs_Sb.best_params_[\"classifier\"])\n",
    "    print(\"run_time per search (s)\", t_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo\n",
    "y_pred_Sb = gs_Sb.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo\n",
    "cm = confusion_matrix(y_test, y_pred_Sb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo\n",
    "cm_df = pd.DataFrame(cm,\n",
    "                     index=['Positive', 'Negative'],\n",
    "                     columns=['Positive', 'Negative'])\n",
    "display(cm_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "              Positive \tNegative\n",
    "    Positive \t1808 \t12\n",
    "    Negative \t172 \t8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#beta = .1\n",
    "#fb_score = fbeta_score(y_test, y_pred_S, beta=beta)\n",
    "#fb_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#beta = .01\n",
    "#fb_score = fbeta_score(y_test, y_pred_S, beta=beta)\n",
    "#fb_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo\n",
    "with timer(\"Fine tuning with SMOTE and LGBM\"):\n",
    "    t_clf = time.perf_counter()\n",
    "    pipeline = imblearn.pipeline.Pipeline([(\"scaler\", scaler),\n",
    "                                           (\"sampler\", oversampler_2),\n",
    "                                           (\"classifier\", clf13)])\n",
    "    # verbose=-1 ne fonctionne pas donc je supprime tous les warnings.\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    fbeta_scorer = make_scorer(fbeta_score, beta=2)\n",
    "    gs_Sb = GridSearchCV(\n",
    "        pipeline,\n",
    "        parm,\n",
    "        cv=5,\n",
    "        n_jobs=None,\n",
    "        scoring=fbeta_scorer,\n",
    "        # scoring=[\"roc_auc\", \"accuracy\"],\n",
    "        # refit=\"roc_auc\",\n",
    "        # n_iter=5, # seulement pour RandomSearchCV ?\n",
    "        # random_state=42, # seulement pour RandomSearchCV ?\n",
    "    ).fit(X_train, y_train)\n",
    "\n",
    "    n_loops = math.prod([len(i) for i in parm.values()])\n",
    "    t_mean = (time.perf_counter() - t_clf)/(n_loops)\n",
    "    if t_mean > 10:\n",
    "        t_mean = round(t_mean, 0)\n",
    "    elif t_mean > 1:\n",
    "        t_mean = round(t_mean, 2)\n",
    "    elif t_mean > .001:\n",
    "        t_mean = round(t_mean, 3)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    print(\"Score:\", round(gs_Sb.best_score_, 3))\n",
    "    print(\"Obtained with:\", gs_Sb.best_params_[\"classifier\"])\n",
    "    print(\"run_time per search (s)\", t_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo\n",
    "y_pred_Sb = gs_Sb.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo\n",
    "cm = confusion_matrix(y_test, y_pred_Sb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo\n",
    "cm_df = pd.DataFrame(cm,\n",
    "                     index=['Positive', 'Negative'],\n",
    "                     columns=['Positive', 'Negative'])\n",
    "display(cm_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec 10_000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \t           Positive \tNegative\n",
    "    Positive \t1809 \t11\n",
    "    Negative \t172 \t8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec 100_000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \t           Positive \tNegative\n",
    "    Positive \t18328 \t58\n",
    "    Negative \t1567 \t47"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ça s'améliore mais c'est tout de même extrêmement mauvais.\n",
    "Je vais essayer de créer ma fonction de scoring à la main."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt = [0, 1, 1, 0, 0]\n",
    "yp = [1, 0, 1, 0, 0]\n",
    "a = yt == yp\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics._classification._weighted_sum(a, None, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False,  True,  True,  True])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt = np.array(yt)\n",
    "yp = np.array(yp)\n",
    "a = yt == yp\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics._classification._weighted_sum(a, None, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo\n",
    "def my_scoring(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    *,\n",
    "    sample_weight=None,\n",
    "    # multioutput=\"uniform_average\",\n",
    "    normalize=True,\n",
    "):\n",
    "\n",
    "    y_type, y_true, y_pred = sklearn.metrics._classification._check_targets(\n",
    "        y_true, y_pred\n",
    "    )\n",
    "    sklearn.metrics._classification.check_consistent_length(\n",
    "        y_true, y_pred, sample_weight\n",
    "    )\n",
    "    FN = y_true - y_pred == 1\n",
    "    FN = sklearn.metrics._classification._weighted_sum(\n",
    "        FN, sample_weight, normalize\n",
    "    )\n",
    "    FP = y_true - y_pred == -1\n",
    "    FP = sklearn.metrics._classification._weighted_sum(\n",
    "        FP, sample_weight, normalize\n",
    "    )\n",
    "    # score = y_true == y_pred\n",
    "    # score = sklearn.metrics._classification._weighted_sum(\n",
    "    #     score, sample_weight, normalize\n",
    "    # )\n",
    "    score = 1 - (10*FN+FP)/11\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.02, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.02\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0031622776601683794, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0031622776601683794\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "Score: nan\n",
      "Obtained with: LGBMClassifier(bagging_fraction=0.9, feature_fraction=0.9,\n",
      "               lambda_l1=0.0031622776601683794, lambda_l2=0.01,\n",
      "               learning_rate=0.07943282347242814, max_depth=7,\n",
      "               min_gain_to_split=0.02, min_sum_hessian_in_leaf=1, num_leaves=25,\n",
      "               random_state=42, verbose=-1)\n",
      "run_time per search (s) 55.0\n",
      "Fine tuning with SMOTE and LGBM - done in 13393s\n"
     ]
    }
   ],
   "source": [
    "%%script echo\n",
    "with timer(\"Fine tuning with SMOTE and LGBM\"):\n",
    "    t_clf = time.perf_counter()\n",
    "    pipeline = imblearn.pipeline.Pipeline([(\"scaler\", scaler),\n",
    "                                           (\"sampler\", oversampler_2),\n",
    "                                           (\"classifier\", clf13)])\n",
    "    # verbose=-1 ne fonctionne pas donc je supprime tous les warnings.\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    gs_Sb = GridSearchCV(\n",
    "        pipeline,\n",
    "        parm,\n",
    "        cv=5,\n",
    "        n_jobs=None,\n",
    "        scoring=my_scoring,\n",
    "        # scoring=[\"roc_auc\", \"accuracy\"],\n",
    "        # refit=\"roc_auc\",\n",
    "        # n_iter=5, # seulement pour RandomSearchCV ?\n",
    "        # random_state=42, # seulement pour RandomSearchCV ?\n",
    "    ).fit(X_train, y_train)\n",
    "\n",
    "    n_loops = math.prod([len(i) for i in parm.values()])\n",
    "    t_mean = (time.perf_counter() - t_clf)/(n_loops)\n",
    "    if t_mean > 10:\n",
    "        t_mean = round(t_mean, 0)\n",
    "    elif t_mean > 1:\n",
    "        t_mean = round(t_mean, 2)\n",
    "    elif t_mean > .001:\n",
    "        t_mean = round(t_mean, 3)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    print(\"Score:\", round(gs_Sb.best_score_, 3))\n",
    "    print(\"Obtained with:\", gs_Sb.best_params_[\"classifier\"])\n",
    "    print(\"run_time per search (s)\", t_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtained with: LGBMClassifier(bagging_fraction=0.9, feature_fraction=0.9,\n",
    "               lambda_l1=0.0031622776601683794, lambda_l2=0.01,\n",
    "               learning_rate=0.07943282347242814, max_depth=7,\n",
    "               min_gain_to_split=0.02, min_sum_hessian_in_leaf=1, num_leaves=25,\n",
    "               random_state=42, verbose=-1)\n",
    "run_time per search (s) 55.0\n",
    "Fine tuning with SMOTE and LGBM - done in 13393s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo\n",
    "y_pred_Sb = gs_Sb.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo\n",
    "cm = confusion_matrix(y_test, y_pred_Sb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>18372</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>1598</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Positive  Negative\n",
       "Positive     18372        14\n",
       "Negative      1598        16"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%script echo\n",
    "cm_df = pd.DataFrame(cm,\n",
    "                     index=['Positive', 'Negative'],\n",
    "                     columns=['Positive', 'Negative'])\n",
    "display(cm_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \t           Positive \tNegative\n",
    "    Positive \t18372 \t14\n",
    "    Negative \t1598 \t16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo\n",
    "y_pred_proba_Sb = gs_Sb.best_estimator_.predict_proba(X_test)\n",
    "y_pred_proba_positive_Sb = y_pred_proba_Sb[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7402353172387104"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%script echo\n",
    "fpr_Sb, tpr_Sb, thresholds_Sb = roc_curve(y_test, y_pred_proba_positive_Sb)\n",
    "roc_auc_Sb = auc(fpr_Sb, tpr_Sb)\n",
    "roc_auc_Sb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_scoring(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    *,\n",
    "    sample_weight=None,\n",
    "    # multioutput=\"uniform_average\",\n",
    "    normalize=True,\n",
    "):\n",
    "\n",
    "    y_type, y_true, y_pred = sklearn.metrics._classification._check_targets(\n",
    "        y_true, y_pred\n",
    "    )\n",
    "    sklearn.metrics._classification.check_consistent_length(\n",
    "        y_true, y_pred, sample_weight\n",
    "    )\n",
    "    FN = y_true - y_pred == 1\n",
    "    FN = sklearn.metrics._classification._weighted_sum(\n",
    "        FN, sample_weight, normalize\n",
    "    )\n",
    "    FP = y_true - y_pred == -1\n",
    "    FP = sklearn.metrics._classification._weighted_sum(\n",
    "        FP, sample_weight, normalize\n",
    "    )\n",
    "    # score = y_true == y_pred\n",
    "    # score = sklearn.metrics._classification._weighted_sum(\n",
    "    #     score, sample_weight, normalize\n",
    "    # )\n",
    "    score = 1 - (FN+10*FP)/11\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.02, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.02\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0031622776601683794, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0031622776601683794\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "Score: nan\n",
      "Obtained with: LGBMClassifier(bagging_fraction=0.9, feature_fraction=0.9,\n",
      "               lambda_l1=0.0031622776601683794, lambda_l2=0.01,\n",
      "               learning_rate=0.07943282347242814, max_depth=7,\n",
      "               min_gain_to_split=0.02, min_sum_hessian_in_leaf=1, num_leaves=25,\n",
      "               random_state=42, verbose=-1)\n",
      "run_time per search (s) 55.0\n",
      "Fine tuning with SMOTE and LGBM - done in 13393s\n"
     ]
    }
   ],
   "source": [
    "with timer(\"Fine tuning with SMOTE and LGBM\"):\n",
    "    t_clf = time.perf_counter()\n",
    "    pipeline = imblearn.pipeline.Pipeline([(\"scaler\", scaler),\n",
    "                                           (\"sampler\", oversampler_2),\n",
    "                                           (\"classifier\", clf13)])\n",
    "    # verbose=-1 ne fonctionne pas donc je supprime tous les warnings.\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    gs_Sb = GridSearchCV(\n",
    "        pipeline,\n",
    "        parm,\n",
    "        cv=5,\n",
    "        n_jobs=None,\n",
    "        scoring=my_scoring,\n",
    "        # scoring=[\"roc_auc\", \"accuracy\"],\n",
    "        # refit=\"roc_auc\",\n",
    "        # n_iter=5, # seulement pour RandomSearchCV ?\n",
    "        # random_state=42, # seulement pour RandomSearchCV ?\n",
    "    ).fit(X_train, y_train)\n",
    "\n",
    "    n_loops = math.prod([len(i) for i in parm.values()])\n",
    "    t_mean = (time.perf_counter() - t_clf)/(n_loops)\n",
    "    if t_mean > 10:\n",
    "        t_mean = round(t_mean, 0)\n",
    "    elif t_mean > 1:\n",
    "        t_mean = round(t_mean, 2)\n",
    "    elif t_mean > .001:\n",
    "        t_mean = round(t_mean, 3)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    print(\"Score:\", round(gs_Sb.best_score_, 3))\n",
    "    print(\"Obtained with:\", gs_Sb.best_params_[\"classifier\"])\n",
    "    print(\"run_time per search (s)\", t_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_Sb = gs_Sb.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred_Sb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>18372</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>1598</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Positive  Negative\n",
       "Positive     18372        14\n",
       "Negative      1598        16"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_df = pd.DataFrame(cm,\n",
    "                     index=['Positive', 'Negative'],\n",
    "                     columns=['Positive', 'Negative'])\n",
    "display(cm_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \t           Positive \tNegative\n",
    "    Positive \t18372 \t14\n",
    "    Negative \t1598 \t16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba_Sb = gs_Sb.best_estimator_.predict_proba(X_test)\n",
    "y_pred_proba_positive_Sb = y_pred_proba_Sb[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7402353172387104"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr_Sb, tpr_Sb, thresholds_Sb = roc_curve(y_test, y_pred_proba_positive_Sb)\n",
    "roc_auc_Sb = auc(fpr_Sb, tpr_Sb)\n",
    "roc_auc_Sb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (870885351.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [124]\u001b[1;36m\u001b[0m\n\u001b[1;33m    =r\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "=r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Applying the fine-tuned best classifier for the final results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Features' importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.1. SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo\n",
    "# InvalidModelError: Model type not yet supported by TreeExplainer:\n",
    "# <class 'imblearn.pipeline.Pipeline'>\n",
    "explainer = shap.TreeExplainer(gs_S.best_estimator_)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "shap.summary_plot(shap_values, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pas nécessaire de le rappeler normalement\n",
    "feature_names = imputer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MemoryError: Unable to allocate 148. GiB for an array with shape\n",
    "# (3312, 5984000) and data type float64\n",
    "K = 10\n",
    "X_train_sample = shap.sample(X_train, K)\n",
    "print(X_train_sample.shape)\n",
    "explainer = shap.KernelExplainer(\n",
    "    gs_Sb.best_estimator_.predict_proba,\n",
    "    X_train_sample\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Je rajoute \".values\" uniquement pour supprimer le million de warnings \"X does\n",
    "# not have valid feature names, but MinMaxScaler was fitted with feature names\"\n",
    "# que SHAP sort.\n",
    "# Ça ne fonctionne pas donc je supprime tous les warnings.\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "shap_values = explainer.shap_values(X_test, feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_test.values, feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.get_feature_names_out(input_features=feature_names)[:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape, X_train_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.columns[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sample.columns[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.2. LIME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Precision:\",\n",
    "      precision_score(gs_S.predict(X_test), y_test))\n",
    "      # precision_score(rs.best_estimator_.predict(X_test), y_test))\n",
    "print(\"Recall:\",\n",
    "      recall_score(gs_S.best_estimator_.predict(X_test), y_test))\n",
    "print(\"ROC AUC Score:\",\n",
    "      roc_auc_score(gs_S.best_estimator_.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot la courbe roc du meilleur pour chaque sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap (et lime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo\n",
    "#rs_cv.fit(X_train, y_train)\n",
    "#rs_cv.fit(X_train_u, y_train_u)\n",
    "rs_cv.fit(X_train_o, y_train_o)\n",
    "\n",
    "for algorithm in classifiers.keys():\n",
    "    print(f\"Best parameters for {algorithm}: {rs_cv.best_params_[algorithm]}\")\n",
    "    print(f\"Best AUC score for {algorithm}: {rs_cv.best_score_[algorithm]['roc_auc']:.3f}\")\n",
    "    print(f\"Best accuracy score for {algorithm}: {rs_cv.best_score_[algorithm]['accuracy']:.3f}\")\n",
    "\n",
    "#best_algorithm = rs_cv.best_estimator_.keys()[0]\n",
    "best_algorithm = rs_cv.best_estimator_.named_steps.keys()\n",
    "print(f\"Overall best algorithm: {best_algorithm}\")\n",
    "print(f\"Best AUC score: {rs_cv.best_score_[best_algorithm]['roc_auc']:.3f}\")\n",
    "print(f\"Best accuracy score: {rs_cv.best_score_[best_algorithm]['accuracy']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_S.predict(X_test).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
