{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. (most) package imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "\n",
    "import gc\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "from contextlib import contextmanager\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\", 20, \"display.max_columns\", 30)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini = False\n",
    "offline = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Global functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(title):\n",
    "    t0 = time.perf_counter()\n",
    "    yield\n",
    "    print(\"{} - done in {:.0f}s\".format(title, time.perf_counter() - t0))\n",
    "\n",
    "def one_hot_encoder(df, nan_as_category=True):\n",
    "    original_columns = list(df.columns)\n",
    "    categorical_columns = [col for col in df.columns if df[col].dtype == \"object\"]\n",
    "    df = pd.get_dummies(df, columns=categorical_columns, dummy_na=nan_as_category)\n",
    "    new_columns = [c for c in df.columns if c not in original_columns]\n",
    "    return df, new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C_B', 'C_G', 'C_R', 'L_A', 'L_B', 'L_C', 'L_D']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C_B</th>\n",
       "      <th>C_G</th>\n",
       "      <th>C_R</th>\n",
       "      <th>C_nan</th>\n",
       "      <th>L_A</th>\n",
       "      <th>L_B</th>\n",
       "      <th>L_C</th>\n",
       "      <th>L_D</th>\n",
       "      <th>L_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   C_B  C_G  C_R  C_nan  L_A  L_B  L_C  L_D  L_nan\n",
       "0    0    0    1      0    1    0    0    0      0\n",
       "1    0    1    0      0    0    1    0    0      0\n",
       "2    1    0    0      0    0    0    1    0      0\n",
       "3    1    0    0      0    0    0    0    1      0\n",
       "4    0    0    1      0    1    0    0    0      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_ohe_test = pd.DataFrame({\n",
    "    \"C\": [\"R\", \"G\", \"B\", \"B\", \"R\"],\n",
    "    \"L\": [\"A\", \"B\", \"C\", \"D\", \"A\"]\n",
    "})\n",
    "\n",
    "display(one_hot_encoder(df_ohe_test, False)[1])\n",
    "display(one_hot_encoder(df_ohe_test, True)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Dataset overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "offline j'ai:\n",
    "\n",
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">filenames = [\n",
    "    \"home-credit-default-risk/application_test.csv\",\n",
    "    \"home-credit-default-risk/application_train.csv\",\n",
    "    \"home-credit-default-risk/bureau.csv\",\n",
    "    \"home-credit-default-risk/bureau_balance.csv\",\n",
    "    \"home-credit-default-risk/credit_card_balance.csv\",\n",
    "    \"home-credit-default-risk/installments_payments.csv\",\n",
    "    \"home-credit-default-risk/POS_CASH_balance.csv\",\n",
    "    \"home-credit-default-risk/previous_application.csv\",\n",
    "    \"home-credit-default-risk/sample_submission.csv\"\n",
    "    ]\n",
    "</code>\n",
    "</p>\n",
    "\n",
    "not offline (on Kaggle) j'ai:\n",
    "\n",
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">filenames = [\n",
    "    \"/kaggle/input/home-credit-default-risk/sample_submission.csv\",\n",
    "    \"/kaggle/input/home-credit-default-risk/bureau_balance.csv\",\n",
    "    \"/kaggle/input/home-credit-default-risk/POS_CASH_balance.csv\",\n",
    "    \"/kaggle/input/home-credit-default-risk/application_train.csv\",\n",
    "    \"/kaggle/input/home-credit-default-risk/application_test.csv\",\n",
    "    \"/kaggle/input/home-credit-default-risk/previous_application.csv\",\n",
    "    \"/kaggle/input/home-credit-default-risk/credit_card_balance.csv\",\n",
    "    \"/kaggle/input/home-credit-default-risk/installments_payments.csv\",\n",
    "    \"/kaggle/input/home-credit-default-risk/bureau.csv\"]\n",
    "    ]\n",
    "</code>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "home-credit-default-risk/application_test.csv\n",
      "home-credit-default-risk/application_train.csv\n",
      "home-credit-default-risk/bureau.csv\n",
      "home-credit-default-risk/bureau_balance.csv\n",
      "home-credit-default-risk/credit_card_balance.csv\n",
      "home-credit-default-risk/installments_payments.csv\n",
      "home-credit-default-risk/POS_CASH_balance.csv\n",
      "home-credit-default-risk/previous_application.csv\n",
      "home-credit-default-risk/sample_submission.csv\n"
     ]
    }
   ],
   "source": [
    "filenames = []\n",
    "\n",
    "if offline:\n",
    "    le_path = \"home-credit-default-risk/\"\n",
    "else:\n",
    "    le_path = \"/kaggle/input\"\n",
    "\n",
    "for dirname, _, filenamess in os.walk(le_path):\n",
    "    for filenamee in filenamess:\n",
    "#                        HomeCredit_columns_description.csv est illisible.\n",
    "        if filenamee != \"HomeCredit_columns_description.csv\":\n",
    "            filename = os.path.join(dirname, filenamee)\n",
    "            print(filename)\n",
    "            filenames.append(filename)\n",
    " #           df = pd.read_csv(filename)\n",
    " #           display(df[-1:])\n",
    " #           if filenamee != \"bureau_balance.csv\":\n",
    " #               print(set(df.SK_ID_CURR.value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not offline:\n",
    "    flnms = []\n",
    "    flnms.append(filenames[4])\n",
    "    flnms.append(filenames[3])\n",
    "    flnms.append(filenames[8])\n",
    "    flnms.append(filenames[1])\n",
    "    flnms.append(filenames[6])\n",
    "    flnms.append(filenames[7])\n",
    "    flnms.append(filenames[2])\n",
    "    flnms.append(filenames[5])\n",
    "    flnms.append(filenames[0])\n",
    "    filenames = flnms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipped\n",
    "for filename in (filenames[:4] + filenames[5:]):\n",
    "    df = pd.read_csv(filename)\n",
    "    print(filename)\n",
    "    display(df.head(2))\n",
    "    #display(df.info())\n",
    "    print(\"shape: \", df.shape)\n",
    "    display(df.nunique())\n",
    "    #display(df.isna().mean().sort_values())\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.read_csv(filenames[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1234567890123456789012345678901234567890123456789012345678901234567890123456789"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1234567890123456789012345678901234567890123456789012345678901234567890123456789"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. application_train_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1. tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipped\n",
    "num_rows = None\n",
    "nan_as_category = False\n",
    "df = pd.read_csv(\"../input/home-credit-default-risk/application_train.csv\", nrows=num_rows)\n",
    "test_df = pd.read_csv(\"../input/home-credit-default-risk/application_test.csv\", nrows=num_rows)\n",
    "print(\"Train samples: {}, test samples: {}\".format(len(df), len(test_df)))\n",
    "df = df.append(test_df).reset_index()\n",
    "display(df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipped\n",
    "pd.factorize(df[\"CODE_GENDER\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2. preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def application_train_test(num_rows=None, nan_as_category=False):\n",
    "    # Read data and merge\n",
    "    if mini:\n",
    "        df = pd.read_csv(filenames[1], nrows=num_rows)[-10:]\n",
    "        test_df = pd.read_csv(filenames[0], nrows=num_rows)[-2:]\n",
    "    else:\n",
    "        df = pd.read_csv(filenames[1], nrows=num_rows)\n",
    "        test_df = pd.read_csv(filenames[0], nrows=num_rows)\n",
    "    print(\"Train samples: {}, test samples: {}\".format(len(df), len(test_df)))\n",
    "    df = df.append(test_df).reset_index()\n",
    "    # Optional: Remove 4 applications with XNA CODE_GENDER (train set)\n",
    "    df = df[df[\"CODE_GENDER\"] != \"XNA\"]\n",
    "\n",
    "    # Categorical features with Binary encode (0 or 1; two categories)\n",
    "    for bin_feature in [\"CODE_GENDER\", \"FLAG_OWN_CAR\", \"FLAG_OWN_REALTY\"]:\n",
    "        df[bin_feature], uniques = pd.factorize(df[bin_feature])\n",
    "    # Categorical features with One-Hot encode\n",
    "    df, cat_cols = one_hot_encoder(df, nan_as_category)\n",
    "\n",
    "    # NaN values for DAYS_EMPLOYED: 365.243 -> nan\n",
    "    df[\"DAYS_EMPLOYED\"].replace(365243, np.nan, inplace=True)\n",
    "    # Some simple new features (percentages)\n",
    "    df[\"DAYS_EMPLOYED_PERC\"] = df[\"DAYS_EMPLOYED\"] / df[\"DAYS_BIRTH\"]\n",
    "    df[\"INCOME_CREDIT_PERC\"] = df[\"AMT_INCOME_TOTAL\"] / df[\"AMT_CREDIT\"]\n",
    "    df[\"INCOME_PER_PERSON\"] = df[\"AMT_INCOME_TOTAL\"] / df[\"CNT_FAM_MEMBERS\"]\n",
    "    df[\"ANNUITY_INCOME_PERC\"] = df[\"AMT_ANNUITY\"] / df[\"AMT_INCOME_TOTAL\"]\n",
    "    df[\"PAYMENT_RATE\"] = df[\"AMT_ANNUITY\"] / df[\"AMT_CREDIT\"]\n",
    "    del test_df\n",
    "    gc.collect()\n",
    "    #print(df.dtypes.value_counts())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. bureau_and_balance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1. tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipped\n",
    "bureau = pd.read_csv(\"../input/home-credit-default-risk/bureau.csv\", nrows=num_rows)\n",
    "bb = pd.read_csv(\"../input/home-credit-default-risk/bureau_balance.csv\", nrows=num_rows)\n",
    "bb, bb_cat = one_hot_encoder(bb, nan_as_category)\n",
    "bureau, bureau_cat = one_hot_encoder(bureau, nan_as_category)\n",
    "bb_aggregations = {\"MONTHS_BALANCE\": [\"min\", \"max\", \"size\"]}\n",
    "for col in bb_cat:\n",
    "    bb_aggregations[col] = [\"mean\"]\n",
    "print(bb_aggregations, \"\\n\", bb.columns, \"\\n\", bureau_cat, \"\\n\", bureau.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipped\n",
    "bb_agg = bb.groupby(\"SK_ID_BUREAU\").agg(bb_aggregations)\n",
    "bb_agg.columns = pd.Index([e[0] + \"_\" + e[1].upper() for e in bb_agg.columns.tolist()])\n",
    "bureau = bureau.join(bb_agg, how=\"left\", on=\"SK_ID_BUREAU\")\n",
    "bureau.drop([\"SK_ID_BUREAU\"], axis=1, inplace=True)\n",
    "bureau.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipped\n",
    "num_aggregations = {\n",
    "    \"DAYS_CREDIT\": [\"min\", \"max\", \"mean\", \"var\"],\n",
    "    \"DAYS_CREDIT_ENDDATE\": [\"min\", \"max\", \"mean\"],\n",
    "    \"DAYS_CREDIT_UPDATE\": [\"mean\"],\n",
    "    \"CREDIT_DAY_OVERDUE\": [\"max\", \"mean\"],\n",
    "    \"AMT_CREDIT_MAX_OVERDUE\": [\"mean\"],\n",
    "    \"AMT_CREDIT_SUM\": [\"max\", \"mean\", \"sum\"],\n",
    "    \"AMT_CREDIT_SUM_DEBT\": [\"max\", \"mean\", \"sum\"],\n",
    "    \"AMT_CREDIT_SUM_OVERDUE\": [\"mean\"],\n",
    "    \"AMT_CREDIT_SUM_LIMIT\": [\"mean\", \"sum\"],\n",
    "    \"AMT_ANNUITY\": [\"max\", \"mean\"],\n",
    "    \"CNT_CREDIT_PROLONG\": [\"sum\"],\n",
    "    \"MONTHS_BALANCE_MIN\": [\"min\"],\n",
    "    \"MONTHS_BALANCE_MAX\": [\"max\"],\n",
    "    \"MONTHS_BALANCE_SIZE\": [\"mean\", \"sum\"]\n",
    "}\n",
    "# Bureau and bureau_balance categorical features\n",
    "cat_aggregations = {}\n",
    "for cat in bureau_cat: cat_aggregations[cat] = [\"mean\"]\n",
    "for cat in bb_cat: cat_aggregations[cat + \"_MEAN\"] = [\"mean\"]\n",
    "\n",
    "bureau_agg = bureau.groupby(\"SK_ID_CURR\").agg({**num_aggregations, **cat_aggregations})\n",
    "bureau_agg.columns = pd.Index([\"BURO_\" + e[0] + \"_\" + e[1].upper() for e in bureau_agg.columns.tolist()])\n",
    "# Bureau: Active credits - using only numerical aggregations\n",
    "active = bureau[bureau[\"CREDIT_ACTIVE_Active\"] == 1]\n",
    "active.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2. preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bureau_and_balance(num_rows=None, nan_as_category=True):\n",
    "    if mini:\n",
    "        bureau = pd.read_csv(filenames[2], nrows=num_rows)[-5:-3]\n",
    "        bb = pd.read_csv(filenames[3], nrows=num_rows)[-5:-3]\n",
    "    else:\n",
    "        bureau = pd.read_csv(filenames[2], nrows=num_rows)\n",
    "        bb = pd.read_csv(filenames[3], nrows=num_rows)\n",
    "    bb, bb_cat = one_hot_encoder(bb, nan_as_category)\n",
    "    bureau, bureau_cat = one_hot_encoder(bureau, nan_as_category)\n",
    "\n",
    "    # Bureau balance: Perform aggregations and merge with bureau.csv\n",
    "    bb_aggregations = {\"MONTHS_BALANCE\": [\"min\", \"max\", \"size\"]}\n",
    "    for col in bb_cat:\n",
    "        bb_aggregations[col] = [\"mean\"]\n",
    "    bb_agg = bb.groupby(\"SK_ID_BUREAU\").agg(bb_aggregations)\n",
    "    bb_agg.columns = pd.Index([e[0] + \"_\" + e[1].upper() for e in bb_agg.columns.tolist()])\n",
    "    bureau = bureau.join(bb_agg, how=\"left\", on=\"SK_ID_BUREAU\")\n",
    "    bureau.drop([\"SK_ID_BUREAU\"], axis=1, inplace=True)\n",
    "    del bb, bb_agg\n",
    "    gc.collect()\n",
    "\n",
    "    # Bureau and bureau_balance numeric features\n",
    "    num_aggregations = {\n",
    "        \"DAYS_CREDIT\": [\"min\", \"max\", \"mean\", \"var\"],\n",
    "        \"DAYS_CREDIT_ENDDATE\": [\"min\", \"max\", \"mean\"],\n",
    "        \"DAYS_CREDIT_UPDATE\": [\"mean\"],\n",
    "        \"CREDIT_DAY_OVERDUE\": [\"max\", \"mean\"],\n",
    "        \"AMT_CREDIT_MAX_OVERDUE\": [\"mean\"],\n",
    "        \"AMT_CREDIT_SUM\": [\"max\", \"mean\", \"sum\"],\n",
    "        \"AMT_CREDIT_SUM_DEBT\": [\"max\", \"mean\", \"sum\"],\n",
    "        \"AMT_CREDIT_SUM_OVERDUE\": [\"mean\"],\n",
    "        \"AMT_CREDIT_SUM_LIMIT\": [\"mean\", \"sum\"],\n",
    "        \"AMT_ANNUITY\": [\"max\", \"mean\"],\n",
    "        \"CNT_CREDIT_PROLONG\": [\"sum\"],\n",
    "        \"MONTHS_BALANCE_MIN\": [\"min\"],\n",
    "        \"MONTHS_BALANCE_MAX\": [\"max\"],\n",
    "        \"MONTHS_BALANCE_SIZE\": [\"mean\", \"sum\"]\n",
    "    }\n",
    "    # Bureau and bureau_balance categorical features\n",
    "    cat_aggregations = {}\n",
    "    for cat in bureau_cat: cat_aggregations[cat] = [\"mean\"]\n",
    "    for cat in bb_cat: cat_aggregations[cat + \"_MEAN\"] = [\"mean\"]\n",
    "\n",
    "    bureau_agg = bureau.groupby(\"SK_ID_CURR\").agg({**num_aggregations, **cat_aggregations})\n",
    "    bureau_agg.columns = pd.Index([\"BURO_\" + e[0] + \"_\" + e[1].upper() for e in bureau_agg.columns.tolist()])\n",
    "    # Bureau: Active credits - using only numerical aggregations\n",
    "    active = bureau[bureau[\"CREDIT_ACTIVE_Active\"] == 1]\n",
    "    active_agg = active.groupby(\"SK_ID_CURR\").agg(num_aggregations)\n",
    "    active_agg.columns = pd.Index([\"ACTIVE_\" + e[0] + \"_\" + e[1].upper() for e in active_agg.columns.tolist()])\n",
    "    bureau_agg = bureau_agg.join(active_agg, how=\"left\", on=\"SK_ID_CURR\")\n",
    "    del active, active_agg\n",
    "    gc.collect()\n",
    "    # Bureau: Closed credits - using only numerical aggregations\n",
    "    closed = bureau[bureau[\"CREDIT_ACTIVE_Closed\"] == 1]\n",
    "    closed_agg = closed.groupby(\"SK_ID_CURR\").agg(num_aggregations)\n",
    "    closed_agg.columns = pd.Index([\"CLOSED_\" + e[0] + \"_\" + e[1].upper() for e in closed_agg.columns.tolist()])\n",
    "    bureau_agg = bureau_agg.join(closed_agg, how=\"left\", on=\"SK_ID_CURR\")\n",
    "    del closed, closed_agg, bureau\n",
    "    gc.collect()\n",
    "    #print(bureau_agg.dtypes.value_counts())\n",
    "    return bureau_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3. more tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipped\n",
    "df = pd.read_csv(filenames[2])[-5:]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipped\n",
    "prev.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. previous_applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1. preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def previous_applications(num_rows=None, nan_as_category=True):\n",
    "    if mini:\n",
    "        prev = pd.read_csv(filenames[7], nrows=num_rows)[-7:-5]\n",
    "    else:\n",
    "        prev = pd.read_csv(filenames[7], nrows=num_rows)\n",
    "    prev, cat_cols = one_hot_encoder(prev, nan_as_category=True)\n",
    "    # Days 365.243 values -> nan\n",
    "    prev[\"DAYS_FIRST_DRAWING\"].replace(365243, np.nan, inplace=True)\n",
    "    prev[\"DAYS_FIRST_DUE\"].replace(365243, np.nan, inplace=True)\n",
    "    prev[\"DAYS_LAST_DUE_1ST_VERSION\"].replace(365243, np.nan, inplace=True)\n",
    "    prev[\"DAYS_LAST_DUE\"].replace(365243, np.nan, inplace=True)\n",
    "    prev[\"DAYS_TERMINATION\"].replace(365243, np.nan, inplace=True)\n",
    "    # Add feature: value ask / value received percentage\n",
    "    prev[\"APP_CREDIT_PERC\"] = prev[\"AMT_APPLICATION\"] / prev[\"AMT_CREDIT\"]\n",
    "    # Previous applications numeric features\n",
    "    num_aggregations = {\n",
    "        \"AMT_ANNUITY\": [\"min\", \"max\", \"mean\"],\n",
    "        \"AMT_APPLICATION\": [\"min\", \"max\", \"mean\"],\n",
    "        \"AMT_CREDIT\": [\"min\", \"max\", \"mean\"],\n",
    "        \"APP_CREDIT_PERC\": [\"min\", \"max\", \"mean\", \"var\"],\n",
    "        \"AMT_DOWN_PAYMENT\": [\"min\", \"max\", \"mean\"],\n",
    "        \"AMT_GOODS_PRICE\": [\"min\", \"max\", \"mean\"],\n",
    "        \"HOUR_APPR_PROCESS_START\": [\"min\", \"max\", \"mean\"],\n",
    "        \"RATE_DOWN_PAYMENT\": [\"min\", \"max\", \"mean\"],\n",
    "        \"DAYS_DECISION\": [\"min\", \"max\", \"mean\"],\n",
    "        \"CNT_PAYMENT\": [\"mean\", \"sum\"],\n",
    "    }\n",
    "    # Previous applications categorical features\n",
    "    cat_aggregations = {}\n",
    "    for cat in cat_cols:\n",
    "        cat_aggregations[cat] = [\"mean\"]\n",
    "\n",
    "    prev_agg = prev.groupby(\"SK_ID_CURR\").agg({**num_aggregations, **cat_aggregations})\n",
    "    prev_agg.columns = pd.Index([\"PREV_\" + e[0] + \"_\" + e[1].upper() for e in prev_agg.columns.tolist()])\n",
    "    # Previous Applications: Approved Applications - only numerical features\n",
    "    approved = prev[prev[\"NAME_CONTRACT_STATUS_Approved\"] == 1]\n",
    "    approved_agg = approved.groupby(\"SK_ID_CURR\").agg(num_aggregations)\n",
    "    approved_agg.columns = pd.Index([\"APPROVED_\" + e[0] + \"_\" + e[1].upper() for e in approved_agg.columns.tolist()])\n",
    "    prev_agg = prev_agg.join(approved_agg, how=\"left\", on=\"SK_ID_CURR\")\n",
    "    # Previous Applications: Refused Applications - only numerical features\n",
    "    refused = prev[prev[\"NAME_CONTRACT_STATUS_Refused\"] == 1]\n",
    "    refused_agg = refused.groupby(\"SK_ID_CURR\").agg(num_aggregations)\n",
    "    refused_agg.columns = pd.Index([\"REFUSED_\" + e[0] + \"_\" + e[1].upper() for e in refused_agg.columns.tolist()])\n",
    "    prev_agg = prev_agg.join(refused_agg, how=\"left\", on=\"SK_ID_CURR\")\n",
    "    del refused, refused_agg, approved, approved_agg, prev\n",
    "    gc.collect()\n",
    "    #print(prev_agg.dtypes.value_counts())\n",
    "    return prev_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2. tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipped\n",
    "df = pd.read_csv(filenames[7])[-7:]\n",
    "df.NAME_CONTRACT_STATUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipped\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. pos_cash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.1. preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_cash(num_rows=None, nan_as_category=True):\n",
    "    if mini:\n",
    "        pos = pd.read_csv(filenames[6], nrows=num_rows)[-2:]\n",
    "    else:\n",
    "        pos = pd.read_csv(filenames[6], nrows=num_rows)\n",
    "    pos, cat_cols = one_hot_encoder(pos, nan_as_category=True)\n",
    "    # Features\n",
    "    aggregations = {\n",
    "        \"MONTHS_BALANCE\": [\"max\", \"mean\", \"size\"],\n",
    "        \"SK_DPD\": [\"max\", \"mean\"],\n",
    "        \"SK_DPD_DEF\": [\"max\", \"mean\"]\n",
    "    }\n",
    "    for cat in cat_cols:\n",
    "        aggregations[cat] = [\"mean\"]\n",
    "\n",
    "    pos_agg = pos.groupby(\"SK_ID_CURR\").agg(aggregations)\n",
    "    pos_agg.columns = pd.Index([\"POS_\" + e[0] + \"_\" + e[1].upper() for e in pos_agg.columns.tolist()])\n",
    "    # Count pos cash accounts\n",
    "    pos_agg[\"POS_COUNT\"] = pos.groupby(\"SK_ID_CURR\").size()\n",
    "    del pos\n",
    "    gc.collect()\n",
    "    #print(pos_agg.dtypes.value_counts())\n",
    "    return pos_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. installment_payments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.1. preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def installments_payments(num_rows=None, nan_as_category=True):\n",
    "    if mini:\n",
    "        ins = pd.read_csv(filenames[5], nrows=num_rows)[-2:]\n",
    "    else:\n",
    "        ins = pd.read_csv(filenames[5], nrows=num_rows)\n",
    "    ins, cat_cols = one_hot_encoder(ins, nan_as_category=True)\n",
    "    # Percentage and difference paid in each installment (amount paid and installment value)\n",
    "    ins[\"PAYMENT_PERC\"] = ins[\"AMT_PAYMENT\"] / ins[\"AMT_INSTALMENT\"]\n",
    "    ins[\"PAYMENT_DIFF\"] = ins[\"AMT_INSTALMENT\"] - ins[\"AMT_PAYMENT\"]\n",
    "    # Days past due and days before due (no negative values)\n",
    "    ins[\"DPD\"] = ins[\"DAYS_ENTRY_PAYMENT\"] - ins[\"DAYS_INSTALMENT\"]\n",
    "    ins[\"DBD\"] = ins[\"DAYS_INSTALMENT\"] - ins[\"DAYS_ENTRY_PAYMENT\"]\n",
    "    ins[\"DPD\"] = ins[\"DPD\"].apply(lambda x: x if x > 0 else 0)\n",
    "    ins[\"DBD\"] = ins[\"DBD\"].apply(lambda x: x if x > 0 else 0)\n",
    "    # Features: Perform aggregations\n",
    "    aggregations = {\n",
    "        \"NUM_INSTALMENT_VERSION\": [\"nunique\"],\n",
    "        \"DPD\": [\"max\", \"mean\", \"sum\"],\n",
    "        \"DBD\": [\"max\", \"mean\", \"sum\"],\n",
    "        \"PAYMENT_PERC\": [\"max\", \"mean\", \"sum\", \"var\"],\n",
    "        \"PAYMENT_DIFF\": [\"max\", \"mean\", \"sum\", \"var\"],\n",
    "        \"AMT_INSTALMENT\": [\"max\", \"mean\", \"sum\"],\n",
    "        \"AMT_PAYMENT\": [\"min\", \"max\", \"mean\", \"sum\"],\n",
    "        \"DAYS_ENTRY_PAYMENT\": [\"max\", \"mean\", \"sum\"]\n",
    "    }\n",
    "    for cat in cat_cols:\n",
    "        aggregations[cat] = [\"mean\"]\n",
    "    ins_agg = ins.groupby(\"SK_ID_CURR\").agg(aggregations)\n",
    "    ins_agg.columns = pd.Index([\"INSTAL_\" + e[0] + \"_\" + e[1].upper() for e in ins_agg.columns.tolist()])\n",
    "    # Count installments accounts\n",
    "    ins_agg[\"INSTAL_COUNT\"] = ins.groupby(\"SK_ID_CURR\").size()\n",
    "    del ins\n",
    "    gc.collect()\n",
    "    #print(ins_agg.dtypes.value_counts())\n",
    "    return ins_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6. credit_card_balance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6.1. preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def credit_card_balance(num_rows=None, nan_as_category=True):\n",
    "    if mini:\n",
    "        cc = pd.read_csv(filenames[4], nrows=num_rows)[-2:]\n",
    "    else:\n",
    "        cc = pd.read_csv(filenames[4], nrows=num_rows)\n",
    "    cc, cat_cols = one_hot_encoder(cc, nan_as_category=True)\n",
    "    # General aggregations\n",
    "    cc.drop([\"SK_ID_PREV\"], axis=1, inplace =True)\n",
    "    cc_agg = cc.groupby(\"SK_ID_CURR\").agg([\"min\", \"max\", \"mean\", \"sum\", \"var\"])\n",
    "    cc_agg.columns = pd.Index([\"CC_\" + e[0] + \"_\" + e[1].upper() for e in cc_agg.columns.tolist()])\n",
    "    # Count credit card lines\n",
    "    cc_agg[\"CC_COUNT\"] = cc.groupby(\"SK_ID_CURR\").size()\n",
    "    del cc\n",
    "    gc.collect()\n",
    "    #print(cc_agg.dtypes.value_counts())\n",
    "    return cc_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. functions from the original notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM GBDT with KFold or Stratified KFold\n",
    "# Parameters from Tilii kernel: https://www.kaggle.com/tilii7/olivier-lightgbm-parameters-by-bayesian-opt/code\n",
    "def kfold_lightgbm(df, num_folds, stratified=False, debug=False):\n",
    "    # Divide in training/validation and test data\n",
    "    train_df = df[df[\"TARGET\"].notnull()]\n",
    "    test_df = df[df[\"TARGET\"].isnull()]\n",
    "    print(\"Starting LightGBM. Train shape: {}, test shape: {}\".format(train_df.shape, test_df.shape))\n",
    "    del df\n",
    "    gc.collect()\n",
    "    # Cross validation model\n",
    "    if stratified:\n",
    "        folds = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=1001)\n",
    "    else:\n",
    "        folds = KFold(n_splits=num_folds, shuffle=True, random_state=1001)\n",
    "    # Create arrays and dataframes to store results\n",
    "    oof_preds = np.zeros(train_df.shape[0])\n",
    "    sub_preds = np.zeros(test_df.shape[0])\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    feats = [f for f in train_df.columns if f not in [\"TARGET\",\"SK_ID_CURR\",\"SK_ID_BUREAU\",\"SK_ID_PREV\",\"index\"]]\n",
    "\n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], train_df[\"TARGET\"])):\n",
    "        train_x, train_y = train_df[feats].iloc[train_idx], train_df[\"TARGET\"].iloc[train_idx]\n",
    "        valid_x, valid_y = train_df[feats].iloc[valid_idx], train_df[\"TARGET\"].iloc[valid_idx]\n",
    "\n",
    "        # LightGBM parameters found by Bayesian optimization\n",
    "        clf = LGBMClassifier(\n",
    "            nthread=4,\n",
    "            n_estimators=10000,\n",
    "            learning_rate=0.02,\n",
    "            num_leaves=34,\n",
    "            colsample_bytree=0.9497036,\n",
    "            subsample=0.8715623,\n",
    "            max_depth=8,\n",
    "            reg_alpha=0.041545473,\n",
    "            reg_lambda=0.0735294,\n",
    "            min_split_gain=0.0222415,\n",
    "            min_child_weight=39.3259775,\n",
    "            silent=-1,\n",
    "            verbose=-1,\n",
    "        )\n",
    "\n",
    "        clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], \n",
    "            eval_metric=\"auc\", verbose=200, early_stopping_rounds=200)\n",
    "\n",
    "        oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration=clf.best_iteration_)[:, 1]\n",
    "        sub_preds += clf.predict_proba(test_df[feats], num_iteration=clf.best_iteration_)[:, 1] / folds.n_splits\n",
    "\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = feats\n",
    "        fold_importance_df[\"importance\"] = clf.feature_importances_\n",
    "        fold_importance_df[\"fold\"] = n_fold + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "        print(\"Fold %2d AUC : %.6f\" % (n_fold + 1, roc_auc_score(valid_y, oof_preds[valid_idx])))\n",
    "        del clf, train_x, train_y, valid_x, valid_y\n",
    "        gc.collect()\n",
    "\n",
    "    print(\"Full AUC score %.6f\" % roc_auc_score(train_df[\"TARGET\"], oof_preds))\n",
    "    # Write submission file and plot feature importance\n",
    "    if not debug:\n",
    "        test_df[\"TARGET\"] = sub_preds\n",
    "        test_df[[\"SK_ID_CURR\", \"TARGET\"]].to_csv(submission_file_name, index=False)\n",
    "    display_importances(feature_importance_df)\n",
    "    return feature_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display/plot feature importance\n",
    "def display_importances(feature_importance_df_):\n",
    "    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\")\\\n",
    "           .mean().sort_values(by=\"importance\", ascending=False)[:40].index\n",
    "    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n",
    "    plt.figure(figsize=(8, 10))\n",
    "    sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "    plt.title(\"LightGBM Features (avg over folds)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"lgbm_importances01.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(debug=False):\n",
    "    num_rows = 1000 if debug else None\n",
    "#    mini = 0 if debug else non sinon il est jamais full le df\n",
    "#    if debug: mini = 0 En fait même celui-ci ne fontionne pas car lors de la\n",
    "#    def des fcts mini valait 1 et lors le l'appel des fcts soit le \"if mini\"\n",
    "#    ne sera pas lu car il a déjà été évalué lors du def ou alors le \"if mini\"\n",
    "#    est lu mais ne regarde pas la valeur actuelle de mini seulement celle qui\n",
    "#    était active lors du def. Je ne sais pas exactement mais le résultat est\n",
    "#    que c'est trop tard ici pour dire \"mini = 0\".\n",
    "    df = application_train_test(num_rows)\n",
    "    print(\"Application train test df shape:\", df.shape)\n",
    "#    print(df.dtypes.value_counts())\n",
    "    with timer(\"Process bureau and bureau_balance\"):\n",
    "        bureau = bureau_and_balance(num_rows)\n",
    "        print(\"Bureau df shape:\", bureau.shape)\n",
    "        df = df.join(bureau, how=\"left\", on=\"SK_ID_CURR\")\n",
    "#        print(df.dtypes.value_counts())\n",
    "        del bureau\n",
    "        gc.collect()\n",
    "    with timer(\"Process previous_applications\"):\n",
    "        prev = previous_applications(num_rows)\n",
    "        print(\"Previous applications df shape:\", prev.shape)\n",
    "        df = df.join(prev, how=\"left\", on=\"SK_ID_CURR\")\n",
    "#        print(df.dtypes.value_counts())\n",
    "        del prev\n",
    "        gc.collect()\n",
    "    with timer(\"Process POS-CASH balance\"):\n",
    "        pos = pos_cash(num_rows)\n",
    "        print(\"Pos-cash balance df shape:\", pos.shape)\n",
    "        df = df.join(pos, how=\"left\", on=\"SK_ID_CURR\")\n",
    "#        print(df.dtypes.value_counts())\n",
    "        del pos\n",
    "        gc.collect()\n",
    "    with timer(\"Process installments payments\"):\n",
    "        ins = installments_payments(num_rows)\n",
    "        print(\"Installments payments df shape:\", ins.shape)\n",
    "        df = df.join(ins, how=\"left\", on=\"SK_ID_CURR\")\n",
    "#        print(df.dtypes.value_counts())\n",
    "        del ins\n",
    "        gc.collect()\n",
    "    with timer(\"Process credit card balance\"):\n",
    "        cc = credit_card_balance(num_rows)\n",
    "        print(\"Credit card balance df shape:\", cc.shape)\n",
    "        df = df.join(cc, how=\"left\", on=\"SK_ID_CURR\")\n",
    "#        print(df.dtypes.value_counts())\n",
    "        del cc\n",
    "        gc.collect()\n",
    "#    with timer(\"Run LightGBM with kfold\"):\n",
    "#        feat_importance = kfold_lightgbm(df, num_folds=10, stratified=False, debug=debug)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1234567890123456789012345678901234567890123456789012345678901234567890123456789"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1234567890123456789012345678901234567890123456789012345678901234567890123456789"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Run the preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. A first full run just to measure the target imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 307511, test samples: 48744\n",
      "Application train test df shape: (356251, 248)\n",
      "Bureau df shape: (305811, 116)\n",
      "Process bureau and bureau_balance - done in 14s\n",
      "Previous applications df shape: (338857, 249)\n",
      "Process previous_applications - done in 16s\n",
      "Pos-cash balance df shape: (337252, 18)\n",
      "Process POS-CASH balance - done in 8s\n",
      "Installments payments df shape: (339587, 26)\n",
      "Process installments payments - done in 22s\n",
      "Credit card balance df shape: (103558, 141)\n",
      "Process credit card balance - done in 11s\n",
      "Full model run - done in 74s\n",
      "282682.00   24825.00   48744.00\n"
     ]
    }
   ],
   "source": [
    "%%script echo\n",
    "# I ran this cell only once, just to get the exact values of zo and oz.\n",
    "if __name__ == \"__main__\":\n",
    "    submission_file_name = \"submission_kernel02.csv\"\n",
    "    with timer(\"Full model run\"):\n",
    "#        main()\n",
    "        df = main(debug=False)\n",
    "\n",
    "zeros_full = df.TARGET.value_counts(\n",
    "    sort=True,\n",
    "    ascending=False,\n",
    "    dropna=True,\n",
    ")[0]\n",
    "ones_full = df.TARGET.value_counts(\n",
    "    sort=True,\n",
    "    ascending=False,\n",
    "    dropna=True,\n",
    ")[1]\n",
    "nans_full = df.TARGET.isna().sum()\n",
    "print(\"TARGET has\",\n",
    "      f\"{zeros_full:10.0f} zeros,\",\n",
    "      f\"{ones_full:10.0f} ones and\",\n",
    "      f\"{nans_full:10.0f} NaNs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros_full, ones_full, nans_full = 282682, 24825, 48744"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is zo = 11.39 more zeros than ones in TARGET. (and oz = 0.09)\n"
     ]
    }
   ],
   "source": [
    "zo = zeros_full/ones_full\n",
    "oz = ones_full/zeros_full\n",
    "print(\"There is zo =\",\n",
    "      f\"{zo:.2f} more zeros than ones in TARGET. (and oz =\",\n",
    "      f\"{oz:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Subsampled run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1. kinda the original run code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%script echo\n",
    "if __name__ == \"__main__\":\n",
    "    submission_file_name = \"submission_kernel02.csv\"\n",
    "    with timer(\"Full model run\"):\n",
    "#        main()\n",
    "        df = main(debug=True)\n",
    "\n",
    "zeros = df.TARGET.value_counts(\n",
    "    sort=True,\n",
    "    ascending=False,\n",
    "    dropna=True,\n",
    ")[0]\n",
    "ones = df.TARGET.value_counts(\n",
    "    sort=True,\n",
    "    ascending=False,\n",
    "    dropna=True,\n",
    ")[1]\n",
    "nans = df.TARGET.isna().sum()\n",
    "print(\"TARGET has\",\n",
    "      f\"{zeros:10.0f} zeros,\",\n",
    "      f\"{ones:10.0f} ones and\",\n",
    "      f\"{nans:10.0f} NaNs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2. An easier to debug version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    submission_file_name = \"submission_kernel02.csv\"\n",
    "    with timer(\"Full model run\"):\n",
    "        debug = True\n",
    "        num_rows = 1000 if debug else None\n",
    "#        if debug: mini = 0\n",
    "        mini = 0 if debug else mini\n",
    "        df = application_train_test(num_rows)\n",
    "        print(\"Application train test df shape:\", df.shape)\n",
    "#        print(df.dtypes.value_counts())\n",
    "        with timer(\"Process bureau and bureau_balance\"):\n",
    "            bureau = bureau_and_balance(num_rows)\n",
    "            print(\"Bureau df shape:\", bureau.shape)\n",
    "            df = df.join(bureau, how=\"left\", on=\"SK_ID_CURR\")\n",
    "#            print(df.dtypes.value_counts())\n",
    "            del bureau\n",
    "            gc.collect()\n",
    "        with timer(\"Process previous_applications\"):\n",
    "            prev = previous_applications(num_rows)\n",
    "            print(\"Previous applications df shape:\", prev.shape)\n",
    "            df = df.join(prev, how=\"left\", on=\"SK_ID_CURR\")\n",
    "#            print(df.dtypes.value_counts())\n",
    "            del prev\n",
    "            gc.collect()\n",
    "        with timer(\"Process POS-CASH balance\"):\n",
    "            pos = pos_cash(num_rows)\n",
    "            print(\"Pos-cash balance df shape:\", pos.shape)\n",
    "            df = df.join(pos, how=\"left\", on=\"SK_ID_CURR\")\n",
    "#            print(df.dtypes.value_counts())\n",
    "            del pos\n",
    "            gc.collect()\n",
    "        with timer(\"Process installments payments\"):\n",
    "            ins = installments_payments(num_rows)\n",
    "            print(\"Installments payments df shape:\", ins.shape)\n",
    "            df = df.join(ins, how=\"left\", on=\"SK_ID_CURR\")\n",
    "#            print(df.dtypes.value_counts())\n",
    "            del ins\n",
    "            gc.collect()\n",
    "        with timer(\"Process credit card balance\"):\n",
    "            cc = credit_card_balance(num_rows)\n",
    "            print(\"Credit card balance df shape:\", cc.shape)\n",
    "            df = df.join(cc, how=\"left\", on=\"SK_ID_CURR\")\n",
    "#            print(df.dtypes.value_counts())\n",
    "            del cc\n",
    "            gc.collect()\n",
    "\n",
    "zeros = df.TARGET.value_counts(\n",
    "    sort=True,\n",
    "    ascending=False,\n",
    "    dropna=True,\n",
    ")[0]\n",
    "ones = df.TARGET.value_counts(\n",
    "    sort=True,\n",
    "    ascending=False,\n",
    "    dropna=True,\n",
    ")[1]\n",
    "nans = df.TARGET.isna().sum()\n",
    "print(\"TARGET has\",\n",
    "      f\"{zeros:10.0f} zeros,\",\n",
    "      f\"{ones:10.0f} ones and\",\n",
    "      f\"{nans:10.0f} NaNs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3. Measure of the target imbalance after the subsampling is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zo_sub = zeros/ones\n",
    "oz_sub = ones/zeros\n",
    "print(\"There is zo_sub =\",\n",
    "      f\"{zo_sub:.2f} more zeros than ones in TARGET. (and oz_sub =\",\n",
    "      f\"{oz_sub:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'imbalance de 11.39 des targets du dataset est de 11.00 après subsampling.\n"
     ]
    }
   ],
   "source": [
    "if (zo/zo_sub >= 3/2 or zo/zo_sub <= 2/3):\n",
    "    for _ in range(8):\n",
    "        print(\"!\")\n",
    "    print(\n",
    "        \"L'imbalance des targets a été fortement modifiée par le subsampling.\",\n",
    "        f\"Elle est passée de {zo:.2f} à {zo_sub:.2f}.\",\n",
    "    )\n",
    "    for _ in range(8):\n",
    "        print(\"!\")\n",
    "else:\n",
    "    print(\n",
    "        f\"L'imbalance de {zo:.2f} des targets du dataset est de {zo_sub:.2f}\",\n",
    "        \"après subsampling.\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1234567890123456789012345678901234567890123456789012345678901234567890123456789"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Tentatives infructueuses de sauvegarde du dataset nettoyé dans Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"df_agg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"../input/df_agg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"../df_agg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"../working/df_agg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.read_csv('../df_agg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipped\n",
    "df = pd.read_csv(\"df_agg.csv\")\n",
    "print(df.shape)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "%%script echo skipped\n",
    "for dirname, _, filenames in os.walk(\"..\"):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "%%script echo skipped\n",
    "for dirname, _, filenames in os.walk(\"/kaggle\"):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Suppression du caractère illisible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_of_df = list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipped\n",
    "# Ce code prend un temps infini à run. Prende la cell en-dessous.\n",
    "for j in cols_of_df:\n",
    "    df = df.rename(columns={j: re.sub(r\"[ ]\", r\"_a_\", j)})\n",
    "    df = df.rename(columns={j: re.sub(r\"[-]\", r\"_b_\", j)})\n",
    "    df = df.rename(columns={j: re.sub(r\"[:]\", r\"_c_\", j)})\n",
    "    df = df.rename(columns={j: re.sub(r\"[/]\", r\"_d_\", j)})\n",
    "    df = df.rename(columns={j: re.sub(r\"[,]\", r\"_e_\", j)})\n",
    "    df = df.rename(columns={j: re.sub(r\"[:]\", r\"_f_\", j)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipped\n",
    "df = df.rename(columns=lambda x: x.replace(\" \", \"_a_\")\\\n",
    "                                  .replace(\"-\", \"_b_\")\\\n",
    "                                  .replace(\":\", \"_c_\")\\\n",
    "                                  .replace(\"/\", \"_d_\")\\\n",
    "                                  .replace(\",\", \"_e_\")\\\n",
    "                                  .replace(\":\", \"_f_\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns=lambda x: x.replace(\":\", \"_f_\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Classification run from the original notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipped\n",
    "with timer(\"Run LightGBM with kfold\"):\n",
    "    feat_importance = kfold_lightgbm(df, num_folds=10, stratified=False, debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1. train_test_split \"à la main\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo mauvaise idée\n",
    "#surtout pas de random split car TARGET a des NaN en plus des 0 ou 1\n",
    "X = df.drop(\"TARGET\", axis=\"columns\")\n",
    "y = df[\"TARGET\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "...     X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1234567890123456789012345678901234567890123456789012345678901234567890123456789"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[df[\"TARGET\"].notnull()]\n",
    "X_train = train_df.drop(\"TARGET\", axis=\"columns\")\n",
    "y_train = train_df[\"TARGET\"]\n",
    "test_df = df[df[\"TARGET\"].isnull()]\n",
    "X_test = test_df.drop(\"TARGET\", axis=\"columns\")\n",
    "y_test = test_df[\"TARGET\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2. SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_old = X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "X_train_i = imputer.fit_transform(X_train)\n",
    "X_test = imputer.fit_transform(X_test_old)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3. Balancing the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipped\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "undersampler = RandomUnderSampler(sampling_strategy=\"majority\")\n",
    "X_train_u, y_train_u = undersampler.fit_resample(X_train_i, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "#oversampler = RandomOverSampler(sampling_strategy='minority')\n",
    "oversampler = SMOTE()\n",
    "X_train_o, y_train_o = oversampler.fit_resample(X_train_i, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.4. Declaring the classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo Cette approche ne permet pas le SearchCV multi-estimateurs\n",
    "classifiers = {\n",
    "    \"dummy\": DummyClassifier(),\n",
    "    \"naive_bayes\": GaussianNB(),\n",
    "    \"sgd\": SGDClassifier(),\n",
    "    \"knn\": KNeighborsClassifier(),\n",
    "    \"svc\": SVC(),\n",
    "    \"random_forest\": RandomForestClassifier(),\n",
    "    \"xgb\": XGBClassifier(),\n",
    "    \"catboost\": CatBoostClassifier(),\n",
    "    \"adaboost\": AdaBoostClassifier(),\n",
    "    \"lightgbm\": LGBMClassifier(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pas très joli mais ça fonctionne.\n",
    "clf0 = DummyClassifier()\n",
    "clf1 = LogisticRegression(random_state=42)\n",
    "clf2 = SGDClassifier()\n",
    "clf3 = GaussianNB()\n",
    "clf4 = MultinomialNB()\n",
    "clf5 = KNeighborsClassifier()\n",
    "clf6 = SVC(probability=True, random_state=42)\n",
    "clf7 = DecisionTreeClassifier(random_state=42)\n",
    "clf8 = RandomForestClassifier(random_state=42)\n",
    "clf9 = GradientBoostingClassifier(random_state=42)\n",
    "clf10 = AdaBoostClassifier(random_state=42)\n",
    "clf11 = XGBClassifier(random_state=42)\n",
    "clf12 = CatBoostClassifier(random_state=42)\n",
    "clf13 = LGBMClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ça me plaît davantage comme ça mais ça pourrait bloquer le fonctionnement du\n",
    "# SearchCV si je ne range pas chaque classifier dans un objet (?)\n",
    "classifiers = []\n",
    "classifiers.append(DummyClassifier())\n",
    "classifiers.append(LogisticRegression(random_state=42))\n",
    "classifiers.append(SGDClassifier())\n",
    "classifiers.append(GaussianNB())\n",
    "classifiers.append(MultinomialNB())\n",
    "classifiers.append(KNeighborsClassifier())\n",
    "classifiers.append(SVC(probability=True, random_state=42))\n",
    "classifiers.append(DecisionTreeClassifier(random_state=42))\n",
    "classifiers.append(RandomForestClassifier(random_state=42))\n",
    "classifiers.append(GradientBoostingClassifier(random_state=42))\n",
    "classifiers.append(AdaBoostClassifier(random_state=42))\n",
    "classifiers.append(XGBClassifier(random_state=42))\n",
    "classifiers.append(CatBoostClassifier(random_state=42))\n",
    "classifiers.append(LGBMClassifier(random_state=42))\n",
    "#classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.5. Declaring the classifiers' parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5.0. DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.append({})\n",
    "params[0][\"classifier__strategy\"] = [\"most_frequent\",\n",
    "                                     \"prior\"]\n",
    "params[0][\"classifier\"] = [clf0]\n",
    "params[0][\"classifier\"] = [classifiers[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5.1. LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.append({})\n",
    "params[1][\"classifier__C\"] = [10**-2,\n",
    "                              10**-1,\n",
    "                              10**0,\n",
    "                              10**1,\n",
    "                              10**2]\n",
    "params[1][\"classifier__penalty\"] = [\"l1\",\n",
    "                                    \"l2\",\n",
    "                                    \"elasticnet\"]\n",
    "#params[1][\"classifier__class_weight\"] = [{0: 1, 1: 1},\n",
    "#                                         {0: oz, 1: zo}]\n",
    "#params[1][\"classifier__class_weight\"] = [None]\n",
    "params[1][\"classifier__class_weight\"] = [None,\n",
    "                                         {0: oz, 1: zo}]\n",
    "# J'ai déjà fait un oversampling donc normalement je n'ai plus besoin de mettre\n",
    "# les poids. Je teste juste ici.\n",
    "params[1][\"classifier\"] = [clf1]\n",
    "params[1][\"classifier\"] = [classifiers[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5.2. SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.append({})\n",
    "params[2][\"classifier__loss\"] = [\"hinge\",\n",
    "                                 \"log\",\n",
    "                                 \"squared_hinge\",\n",
    "                                 \"modified_huber\"]\n",
    "params[2][\"classifier__penalty\"] = [\"l2\",\n",
    "                                    \"l1\",\n",
    "                                    \"elasticnet\"]\n",
    "params[2][\"classifier\"] = [clf2]\n",
    "params[2][\"classifier\"] = [classifiers[2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5.3. GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.append({})\n",
    "params[3][\"classifier\"] = [clf3]\n",
    "params[3][\"classifier\"] = [classifiers[3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5.4. MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.append({})\n",
    "params[4][\"classifier__alpha\"] = [10**0,\n",
    "                                  10**1,\n",
    "                                  10**2]\n",
    "params[4][\"classifier\"] = [clf4]\n",
    "params[4][\"classifier\"] = [classifiers[4]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5.5. KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.append({})\n",
    "params[5][\"classifier__n_neighbors\"] = [10**.5,\n",
    "                                        10**1,\n",
    "                                        10**1.5,\n",
    "                                        10**2]\n",
    "params[5][\"classifier__weights\"] = [\"uniform\",\n",
    "                                    \"distance\"]\n",
    "params[5][\"classifier\"] = [clf5]\n",
    "params[5][\"classifier\"] = [classifiers[5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5.6. SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.append({})\n",
    "params[6][\"classifier__kernel\"] = [\"linear\",\n",
    "                                   \"rbf\",\n",
    "                                   \"poly\",\n",
    "                                   \"sigmoid\"]\n",
    "params[6][\"classifier__C\"] = [10**-2,\n",
    "                              10**-1,\n",
    "                              10**0,\n",
    "                              10**1,\n",
    "                              10**2,\n",
    "                              10**3]\n",
    "params[6][\"classifier__gamma\"] = [\"auto\",\n",
    "                                  \"scale\"]\n",
    "#params[6][\"classifier__class_weight\"] = [None,\n",
    "#                                         {0: oz, 1: zo}]\n",
    "# J'ai déjà fait un oversampling donc plus besoin de mettre les poids.\n",
    "params[6][\"classifier__class_weight\"] = [None]\n",
    "params[6][\"classifier\"] = [clf6]\n",
    "params[6][\"classifier\"] = [classifiers[6]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5.7. DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.append({})\n",
    "params[7][\"classifier__max_depth\"] = [3,\n",
    "                                      10**1,\n",
    "                                      30,\n",
    "                                      None]\n",
    "params[7][\"classifier__min_samples_split\"] = [10**.5,\n",
    "                                              10**1]\n",
    "#params[7][\"classifier__class_weight\"] = [{0: oz, 1: zo}]\n",
    "# J'ai déjà fait un oversampling donc plus besoin de mettre les poids.\n",
    "params[7][\"classifier__class_weight\"] = [None]\n",
    "params[7][\"classifier\"] = [clf7]\n",
    "params[7][\"classifier\"] = [classifiers[7]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5.8. RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.append({})\n",
    "params[8][\"classifier__n_estimators\"] = [10**1,\n",
    "                                         10**2,\n",
    "                                         10**3]\n",
    "params[8][\"classifier__max_depth\"] = [3,\n",
    "                                      10**1,\n",
    "                                      30]\n",
    "params[8][\"classifier__criterion\"] = [\"gini\",\n",
    "                                      \"entropy\"]\n",
    "#params[8][\"classifier__class_weight\"] = [None,\n",
    "#                                         {0: oz, 1: zo}]\n",
    "# J'ai déjà fait un oversampling donc plus besoin de mettre les poids.\n",
    "params[8][\"classifier__class_weight\"] = [None]\n",
    "params[8][\"classifier\"] = [clf8]\n",
    "params[8][\"classifier\"] = [classifiers[8]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5.9. GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.append({})\n",
    "params[9][\"classifier__n_estimators\"] = [10**1,\n",
    "                                         10**2,\n",
    "                                         10**3]\n",
    "params[9][\"classifier__max_depth\"] = [3,\n",
    "                                      10**1,\n",
    "                                      30]\n",
    "params[9][\"classifier\"] = [clf9]\n",
    "params[9][\"classifier\"] = [classifiers[9]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5.10. AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.append({})\n",
    "params[10][\"classifier__n_estimators\"] = [10**1,\n",
    "                                          10**2,\n",
    "                                          10**3]\n",
    "params[10][\"classifier__learning_rate\"] = [10**-3,\n",
    "                                           10**-2,\n",
    "                                           10**-1]\n",
    "params[10][\"classifier\"] = [clf10]\n",
    "params[10][\"classifier\"] = [classifiers[10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5.11. XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.append({})\n",
    "params[11][\"classifier__booster\"] = [\"gbtree\",\n",
    "                                     \"gblinear\",\n",
    "                                     \"dart\"]\n",
    "params[11][\"classifier__learning_rate\"] = [10**-3,\n",
    "                                           10**-2,\n",
    "                                           10**-1]\n",
    "params[11][\"classifier__max_depth\"] = [10**0,\n",
    "                                       3,\n",
    "                                       10**1]\n",
    "params[11][\"classifier\"] = [clf11]\n",
    "params[11][\"classifier\"] = [classifiers[11]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5.12. CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.append({})\n",
    "params[12][\"classifier__iterations\"] = [10**1,\n",
    "                                        10**2,\n",
    "                                        10**3]\n",
    "params[12][\"classifier__learning_rate\"] = [10**-3,\n",
    "                                           10**-2,\n",
    "                                           10**-1]\n",
    "params[12][\"classifier__depth\"] = [10**0,\n",
    "                                   3,\n",
    "                                   10**1]\n",
    "params[12][\"classifier\"] = [clf12]\n",
    "params[12][\"classifier\"] = [classifiers[12]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5.13. LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.append({})\n",
    "params[13][\"classifier__boosting_type\"] = [\"gbdt\",\n",
    "                                           \"dart\",\n",
    "                                           \"goss\"]\n",
    "params[13][\"classifier__learning_rate\"] = [10**-3,\n",
    "                                           10**-2,\n",
    "                                           10**-1]\n",
    "params[13][\"classifier__num_leaves\"] = [10**1,\n",
    "                                        10**1.5,\n",
    "                                        10**2]\n",
    "params[13][\"classifier\"] = [clf13]\n",
    "params[13][\"classifier\"] = [classifiers[13]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5.14. Déclaration des paramètres sous la forme d'un dictionnaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo\n",
    "# J\"aurais préféré input comme ceci mais il faut toujours exactement le keyword\n",
    "# \"classifier\" pour que le SearchCV multi-estimateur fonctionne et donc je ne\n",
    "# peux pas utiliser un dictionnaire pour ça.\n",
    "param_distributions = {\n",
    "    \"dummy\": {\"class_weight\": [{0: 1, 1: 1}, {0: oz, 1: zo}]},\n",
    "    \"sgd\": {\"loss\": [\"hinge\", \"log\", \"squared_hinge\", \"modified_huber\"],\n",
    "            \"penalty\": [\"l2\", \"l1\", \"elasticnet\"],\n",
    "            \"class_weight\": [{0: oz, 1: zo}]},\n",
    "    \"naive_bayes\": {\"class_weight\": [{0: oz, 1: zo}]},\n",
    "    \"knn\": {\"n_neighbors\": range(1, 11),\n",
    "            \"weights\": [\"uniform\", \"distance\"],\n",
    "            \"class_weight\": [{0: oz, 1: zo}]},\n",
    "    \"svc\": {\"kernel\": [\"linear\", \"rbf\", \"poly\", \"sigmoid\"],\n",
    "            \"C\": [0.1, 1, 10, 100, 1000],\n",
    "            \"gamma\": [\"auto\", \"scale\"],\n",
    "            \"class_weight\": [{0: oz, 1: zo}]},\n",
    "    \"random_forest\": {\"n_estimators\": [10, 100, 1000],\n",
    "                      \"criterion\": [\"gini\", \"entropy\"],\n",
    "                      \"class_weight\": [{0: oz, 1: zo}]},\n",
    "    \"adaboost\": {\"n_estimators\": [10, 100, 1000],\n",
    "                 \"learning_rate\": [0.1, 0.01, 0.001],\n",
    "                 \"class_weight\": [{0: oz, 1: zo}]},\n",
    "    \"xgb\": {\"booster\": [\"gbtree\", \"gblinear\", \"dart\"],\n",
    "            \"learning_rate\": [0.1, 0.01, 0.001],\n",
    "            \"max_depth\": range(1, 11),\n",
    "            \"class_weight\": [{0: oz, 1: zo}]},\n",
    "    \"catboost\": {\"iterations\": [10, 100, 1000],\n",
    "                 \"learning_rate\": [0.1, 0.01, 0.001],\n",
    "                 \"depth\": range(1, 11),\n",
    "                 \"class_weight\": [{0: oz, 1: zo}]},\n",
    "    \"lightgbm\": {\"boosting_type\": [\"gbdt\", \"dart\", \"goss\"],\n",
    "                 \"learning_rate\": [0.1, 0.01, 0.001],\n",
    "                 \"num_leaves\": range(10, 110, 10),\n",
    "                 \"class_weight\": [{0: oz, 1: zo}]},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo\n",
    "param_distributions = {\n",
    "    \"dummy\": {},\n",
    "    \"naive_bayes\": {},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.6. Tentative infructueuse d'itérer sur les classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo\n",
    "# Non. Pipeline ne fonctionne pas du tout comme ça.\n",
    "pipe = Pipeline(steps=[(name, estimator) for name, estimator in classifiers.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo\n",
    "# Non. Pipeline ne fonctionne pas comme ça non plus. Elle ne prend qu'un seul\n",
    "# estimateur à la fois.\n",
    "# Peut-être cependant qu'en mettant en bout de pipe un columntransformer qui\n",
    "# définit tous les estimateurs en parallèle ça pourrait fonctionner mais j'y\n",
    "# crois peu.\n",
    "rs_cv = RandomizedSearchCV(estimator=Pipeline(classifiers),\n",
    "                           param_distributions=param_distributions,\n",
    "                           n_iter=10,\n",
    "                           cv=5,\n",
    "                           scoring=[\"roc_auc\", \"accuracy\"],\n",
    "                           refit=\"roc_auc\",\n",
    "                           random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo\n",
    "#rs_cv.fit(X_train, y_train)\n",
    "#rs_cv.fit(X_train_u, y_train_u)\n",
    "rs_cv.fit(X_train_o, y_train_o)\n",
    "\n",
    "for algorithm in classifiers.keys():\n",
    "    print(f\"Best parameters for {algorithm}: {rs_cv.best_params_[algorithm]}\")\n",
    "    print(f\"Best AUC score for {algorithm}: {rs_cv.best_score_[algorithm]['roc_auc']:.3f}\")\n",
    "    print(f\"Best accuracy score for {algorithm}: {rs_cv.best_score_[algorithm]['accuracy']:.3f}\")\n",
    "\n",
    "#best_algorithm = rs_cv.best_estimator_.keys()[0]\n",
    "best_algorithm = rs_cv.best_estimator_.named_steps.keys()\n",
    "print(f\"Overall best algorithm: {best_algorithm}\")\n",
    "print(f\"Best AUC score: {rs_cv.best_score_[best_algorithm]['roc_auc']:.3f}\")\n",
    "print(f\"Best accuracy score: {rs_cv.best_score_[best_algorithm]['accuracy']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.7. Itération sur les classifiers avec une méthode étrange\n",
    "En fait ici on ne donne au SearchCV qu'une seule pipe de travail ne contenant\n",
    "qu'un seul estimateur, mais il va quand même itérer sur tous les classifiers\n",
    "car ils sont tous renseignés dans ```params```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([(\"classifier\", clf0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rs = RandomizedSearchCV(\n",
    "    pipeline,\n",
    "    params,\n",
    "    n_iter=5,\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    scoring=\"roc_auc\"\n",
    "#).fit(X_train, y_train)\n",
    "#).fit(X_train_u, y_train_u)\n",
    ").fit(X_train_o, y_train_o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.8. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo\n",
    "# Il n'y a pas de targets dans notre test set, c'est en fait un predict set\n",
    "# pas un test set, donc on ne peut pas calculer ces scores.\n",
    "print(\"Precision:\",\n",
    "      precision_score(rs.predict(X_test), y_test))\n",
    "print(\"Recall:\",\n",
    "      recall_score(rs.predict(X_test), y_test))\n",
    "print(\"ROC AUC Score:\",\n",
    "      roc_auc_score(rs.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Fine tuning with the best classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1. GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.2. Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Applying the fine-tuned best classifier for the final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#y_pred = rs_cv.best_estimator_[best_algorithm].predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Features' importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.1. SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.2. LIME"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
