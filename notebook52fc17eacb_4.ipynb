{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\", 20, \"display.max_columns\", 30)\n",
    "import gc\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "from contextlib import contextmanager\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "home-credit-default-risk/application_test.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>NAME_TYPE_SUITE</th>\n",
       "      <th>NAME_INCOME_TYPE</th>\n",
       "      <th>NAME_EDUCATION_TYPE</th>\n",
       "      <th>NAME_FAMILY_STATUS</th>\n",
       "      <th>NAME_HOUSING_TYPE</th>\n",
       "      <th>...</th>\n",
       "      <th>FLAG_DOCUMENT_13</th>\n",
       "      <th>FLAG_DOCUMENT_14</th>\n",
       "      <th>FLAG_DOCUMENT_15</th>\n",
       "      <th>FLAG_DOCUMENT_16</th>\n",
       "      <th>FLAG_DOCUMENT_17</th>\n",
       "      <th>FLAG_DOCUMENT_18</th>\n",
       "      <th>FLAG_DOCUMENT_19</th>\n",
       "      <th>FLAG_DOCUMENT_20</th>\n",
       "      <th>FLAG_DOCUMENT_21</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48743</th>\n",
       "      <td>456250</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>312768.0</td>\n",
       "      <td>24709.5</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>Unaccompanied</td>\n",
       "      <td>Working</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SK_ID_CURR NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR FLAG_OWN_REALTY  \\\n",
       "48743      456250         Cash loans           F            Y               N   \n",
       "\n",
       "       CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
       "48743             0          135000.0    312768.0      24709.5   \n",
       "\n",
       "       AMT_GOODS_PRICE NAME_TYPE_SUITE NAME_INCOME_TYPE  \\\n",
       "48743         270000.0   Unaccompanied          Working   \n",
       "\n",
       "                 NAME_EDUCATION_TYPE NAME_FAMILY_STATUS  NAME_HOUSING_TYPE  \\\n",
       "48743  Secondary / secondary special            Married  House / apartment   \n",
       "\n",
       "       ...  FLAG_DOCUMENT_13  FLAG_DOCUMENT_14  FLAG_DOCUMENT_15  \\\n",
       "48743  ...                 0                 0                 0   \n",
       "\n",
       "       FLAG_DOCUMENT_16  FLAG_DOCUMENT_17  FLAG_DOCUMENT_18  FLAG_DOCUMENT_19  \\\n",
       "48743                 0                 0                 0                 0   \n",
       "\n",
       "       FLAG_DOCUMENT_20  FLAG_DOCUMENT_21  AMT_REQ_CREDIT_BUREAU_HOUR  \\\n",
       "48743                 0                 0                         0.0   \n",
       "\n",
       "       AMT_REQ_CREDIT_BUREAU_DAY  AMT_REQ_CREDIT_BUREAU_WEEK  \\\n",
       "48743                        0.0                         0.0   \n",
       "\n",
       "      AMT_REQ_CREDIT_BUREAU_MON  AMT_REQ_CREDIT_BUREAU_QRT  \\\n",
       "48743                       0.0                        1.0   \n",
       "\n",
       "       AMT_REQ_CREDIT_BUREAU_YEAR  \n",
       "48743                         4.0  \n",
       "\n",
       "[1 rows x 121 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1}\n",
      "home-credit-default-risk/application_train.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>NAME_TYPE_SUITE</th>\n",
       "      <th>NAME_INCOME_TYPE</th>\n",
       "      <th>NAME_EDUCATION_TYPE</th>\n",
       "      <th>NAME_FAMILY_STATUS</th>\n",
       "      <th>...</th>\n",
       "      <th>FLAG_DOCUMENT_13</th>\n",
       "      <th>FLAG_DOCUMENT_14</th>\n",
       "      <th>FLAG_DOCUMENT_15</th>\n",
       "      <th>FLAG_DOCUMENT_16</th>\n",
       "      <th>FLAG_DOCUMENT_17</th>\n",
       "      <th>FLAG_DOCUMENT_18</th>\n",
       "      <th>FLAG_DOCUMENT_19</th>\n",
       "      <th>FLAG_DOCUMENT_20</th>\n",
       "      <th>FLAG_DOCUMENT_21</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>307510</th>\n",
       "      <td>456255</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>675000.0</td>\n",
       "      <td>49117.5</td>\n",
       "      <td>675000.0</td>\n",
       "      <td>Unaccompanied</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SK_ID_CURR  TARGET NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR  \\\n",
       "307510      456255       0         Cash loans           F            N   \n",
       "\n",
       "       FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  \\\n",
       "307510               N             0          157500.0    675000.0   \n",
       "\n",
       "        AMT_ANNUITY  AMT_GOODS_PRICE NAME_TYPE_SUITE      NAME_INCOME_TYPE  \\\n",
       "307510      49117.5         675000.0   Unaccompanied  Commercial associate   \n",
       "\n",
       "       NAME_EDUCATION_TYPE NAME_FAMILY_STATUS  ... FLAG_DOCUMENT_13  \\\n",
       "307510    Higher education            Married  ...                0   \n",
       "\n",
       "        FLAG_DOCUMENT_14  FLAG_DOCUMENT_15  FLAG_DOCUMENT_16  \\\n",
       "307510                 0                 0                 0   \n",
       "\n",
       "        FLAG_DOCUMENT_17  FLAG_DOCUMENT_18  FLAG_DOCUMENT_19  \\\n",
       "307510                 0                 0                 0   \n",
       "\n",
       "        FLAG_DOCUMENT_20  FLAG_DOCUMENT_21  AMT_REQ_CREDIT_BUREAU_HOUR  \\\n",
       "307510                 0                 0                         0.0   \n",
       "\n",
       "        AMT_REQ_CREDIT_BUREAU_DAY  AMT_REQ_CREDIT_BUREAU_WEEK  \\\n",
       "307510                        0.0                         0.0   \n",
       "\n",
       "        AMT_REQ_CREDIT_BUREAU_MON AMT_REQ_CREDIT_BUREAU_QRT  \\\n",
       "307510                        2.0                       0.0   \n",
       "\n",
       "        AMT_REQ_CREDIT_BUREAU_YEAR  \n",
       "307510                         1.0  \n",
       "\n",
       "[1 rows x 122 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1}\n",
      "home-credit-default-risk/bureau.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>SK_ID_BUREAU</th>\n",
       "      <th>CREDIT_ACTIVE</th>\n",
       "      <th>CREDIT_CURRENCY</th>\n",
       "      <th>DAYS_CREDIT</th>\n",
       "      <th>CREDIT_DAY_OVERDUE</th>\n",
       "      <th>DAYS_CREDIT_ENDDATE</th>\n",
       "      <th>DAYS_ENDDATE_FACT</th>\n",
       "      <th>AMT_CREDIT_MAX_OVERDUE</th>\n",
       "      <th>CNT_CREDIT_PROLONG</th>\n",
       "      <th>AMT_CREDIT_SUM</th>\n",
       "      <th>AMT_CREDIT_SUM_DEBT</th>\n",
       "      <th>AMT_CREDIT_SUM_LIMIT</th>\n",
       "      <th>AMT_CREDIT_SUM_OVERDUE</th>\n",
       "      <th>CREDIT_TYPE</th>\n",
       "      <th>DAYS_CREDIT_UPDATE</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1716427</th>\n",
       "      <td>246829</td>\n",
       "      <td>5057778</td>\n",
       "      <td>Closed</td>\n",
       "      <td>currency 1</td>\n",
       "      <td>-463</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-387.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>22500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Microloan</td>\n",
       "      <td>-387</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         SK_ID_CURR  SK_ID_BUREAU CREDIT_ACTIVE CREDIT_CURRENCY  DAYS_CREDIT  \\\n",
       "1716427      246829       5057778        Closed      currency 1         -463   \n",
       "\n",
       "         CREDIT_DAY_OVERDUE  DAYS_CREDIT_ENDDATE  DAYS_ENDDATE_FACT  \\\n",
       "1716427                   0                  NaN             -387.0   \n",
       "\n",
       "         AMT_CREDIT_MAX_OVERDUE  CNT_CREDIT_PROLONG  AMT_CREDIT_SUM  \\\n",
       "1716427                     NaN                   0         22500.0   \n",
       "\n",
       "         AMT_CREDIT_SUM_DEBT  AMT_CREDIT_SUM_LIMIT  AMT_CREDIT_SUM_OVERDUE  \\\n",
       "1716427                  0.0                   NaN                     0.0   \n",
       "\n",
       "        CREDIT_TYPE  DAYS_CREDIT_UPDATE  AMT_ANNUITY  \n",
       "1716427   Microloan                -387          NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 78, 94, 116}\n",
      "home-credit-default-risk/bureau_balance.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_BUREAU</th>\n",
       "      <th>MONTHS_BALANCE</th>\n",
       "      <th>STATUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27299924</th>\n",
       "      <td>5041336</td>\n",
       "      <td>-51</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          SK_ID_BUREAU  MONTHS_BALANCE STATUS\n",
       "27299924       5041336             -51      X"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "home-credit-default-risk/credit_card_balance.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_PREV</th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>MONTHS_BALANCE</th>\n",
       "      <th>AMT_BALANCE</th>\n",
       "      <th>AMT_CREDIT_LIMIT_ACTUAL</th>\n",
       "      <th>AMT_DRAWINGS_ATM_CURRENT</th>\n",
       "      <th>AMT_DRAWINGS_CURRENT</th>\n",
       "      <th>AMT_DRAWINGS_OTHER_CURRENT</th>\n",
       "      <th>AMT_DRAWINGS_POS_CURRENT</th>\n",
       "      <th>AMT_INST_MIN_REGULARITY</th>\n",
       "      <th>AMT_PAYMENT_CURRENT</th>\n",
       "      <th>AMT_PAYMENT_TOTAL_CURRENT</th>\n",
       "      <th>AMT_RECEIVABLE_PRINCIPAL</th>\n",
       "      <th>AMT_RECIVABLE</th>\n",
       "      <th>AMT_TOTAL_RECEIVABLE</th>\n",
       "      <th>CNT_DRAWINGS_ATM_CURRENT</th>\n",
       "      <th>CNT_DRAWINGS_CURRENT</th>\n",
       "      <th>CNT_DRAWINGS_OTHER_CURRENT</th>\n",
       "      <th>CNT_DRAWINGS_POS_CURRENT</th>\n",
       "      <th>CNT_INSTALMENT_MATURE_CUM</th>\n",
       "      <th>NAME_CONTRACT_STATUS</th>\n",
       "      <th>SK_DPD</th>\n",
       "      <th>SK_DPD_DEF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3840311</th>\n",
       "      <td>2411345</td>\n",
       "      <td>236760</td>\n",
       "      <td>-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         SK_ID_PREV  SK_ID_CURR  MONTHS_BALANCE  AMT_BALANCE  \\\n",
       "3840311     2411345      236760             -10          0.0   \n",
       "\n",
       "         AMT_CREDIT_LIMIT_ACTUAL  AMT_DRAWINGS_ATM_CURRENT  \\\n",
       "3840311                   157500                       0.0   \n",
       "\n",
       "         AMT_DRAWINGS_CURRENT  AMT_DRAWINGS_OTHER_CURRENT  \\\n",
       "3840311                   0.0                         0.0   \n",
       "\n",
       "         AMT_DRAWINGS_POS_CURRENT  AMT_INST_MIN_REGULARITY  \\\n",
       "3840311                       0.0                      0.0   \n",
       "\n",
       "         AMT_PAYMENT_CURRENT  AMT_PAYMENT_TOTAL_CURRENT  \\\n",
       "3840311                  0.0                        0.0   \n",
       "\n",
       "         AMT_RECEIVABLE_PRINCIPAL  AMT_RECIVABLE  AMT_TOTAL_RECEIVABLE  \\\n",
       "3840311                       0.0            0.0                   0.0   \n",
       "\n",
       "         CNT_DRAWINGS_ATM_CURRENT  CNT_DRAWINGS_CURRENT  \\\n",
       "3840311                       0.0                     0   \n",
       "\n",
       "         CNT_DRAWINGS_OTHER_CURRENT  CNT_DRAWINGS_POS_CURRENT  \\\n",
       "3840311                         0.0                       0.0   \n",
       "\n",
       "         CNT_INSTALMENT_MATURE_CUM NAME_CONTRACT_STATUS  SK_DPD  SK_DPD_DEF  \n",
       "3840311                       21.0            Completed       0           0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 140, 178, 192}\n",
      "home-credit-default-risk/installments_payments.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_PREV</th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>NUM_INSTALMENT_VERSION</th>\n",
       "      <th>NUM_INSTALMENT_NUMBER</th>\n",
       "      <th>DAYS_INSTALMENT</th>\n",
       "      <th>DAYS_ENTRY_PAYMENT</th>\n",
       "      <th>AMT_INSTALMENT</th>\n",
       "      <th>AMT_PAYMENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13605400</th>\n",
       "      <td>2448869</td>\n",
       "      <td>434321</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11504.25</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          SK_ID_PREV  SK_ID_CURR  NUM_INSTALMENT_VERSION  \\\n",
       "13605400     2448869      434321                     1.0   \n",
       "\n",
       "          NUM_INSTALMENT_NUMBER  DAYS_INSTALMENT  DAYS_ENTRY_PAYMENT  \\\n",
       "13605400                     19            -27.0                 NaN   \n",
       "\n",
       "          AMT_INSTALMENT  AMT_PAYMENT  \n",
       "13605400        11504.25          NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 301, 302, 304, 305, 306, 308, 309, 310, 311, 312, 313, 314, 315, 317, 318, 323, 324, 332, 336, 337, 344, 347, 350, 372}\n",
      "home-credit-default-risk/POS_CASH_balance.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_PREV</th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>MONTHS_BALANCE</th>\n",
       "      <th>CNT_INSTALMENT</th>\n",
       "      <th>CNT_INSTALMENT_FUTURE</th>\n",
       "      <th>NAME_CONTRACT_STATUS</th>\n",
       "      <th>SK_DPD</th>\n",
       "      <th>SK_DPD_DEF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10001357</th>\n",
       "      <td>1259607</td>\n",
       "      <td>174278</td>\n",
       "      <td>-52</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          SK_ID_PREV  SK_ID_CURR  MONTHS_BALANCE  CNT_INSTALMENT  \\\n",
       "10001357     1259607      174278             -52            16.0   \n",
       "\n",
       "          CNT_INSTALMENT_FUTURE NAME_CONTRACT_STATUS  SK_DPD  SK_DPD_DEF  \n",
       "10001357                    0.0            Completed       0           0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 202, 203, 204, 205, 206, 207, 208, 211, 214, 215, 216, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 229, 230, 232, 233, 234, 235, 237, 239, 244, 245, 246, 247, 295}\n",
      "home-credit-default-risk/previous_application.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_PREV</th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_APPLICATION</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_DOWN_PAYMENT</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>WEEKDAY_APPR_PROCESS_START</th>\n",
       "      <th>HOUR_APPR_PROCESS_START</th>\n",
       "      <th>FLAG_LAST_APPL_PER_CONTRACT</th>\n",
       "      <th>NFLAG_LAST_APPL_IN_DAY</th>\n",
       "      <th>RATE_DOWN_PAYMENT</th>\n",
       "      <th>RATE_INTEREST_PRIMARY</th>\n",
       "      <th>RATE_INTEREST_PRIVILEGED</th>\n",
       "      <th>...</th>\n",
       "      <th>NAME_GOODS_CATEGORY</th>\n",
       "      <th>NAME_PORTFOLIO</th>\n",
       "      <th>NAME_PRODUCT_TYPE</th>\n",
       "      <th>CHANNEL_TYPE</th>\n",
       "      <th>SELLERPLACE_AREA</th>\n",
       "      <th>NAME_SELLER_INDUSTRY</th>\n",
       "      <th>CNT_PAYMENT</th>\n",
       "      <th>NAME_YIELD_GROUP</th>\n",
       "      <th>PRODUCT_COMBINATION</th>\n",
       "      <th>DAYS_FIRST_DRAWING</th>\n",
       "      <th>DAYS_FIRST_DUE</th>\n",
       "      <th>DAYS_LAST_DUE_1ST_VERSION</th>\n",
       "      <th>DAYS_LAST_DUE</th>\n",
       "      <th>DAYS_TERMINATION</th>\n",
       "      <th>NFLAG_INSURED_ON_APPROVAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1670213</th>\n",
       "      <td>2418762</td>\n",
       "      <td>261212</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>16431.3</td>\n",
       "      <td>360000.0</td>\n",
       "      <td>360000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360000.0</td>\n",
       "      <td>SUNDAY</td>\n",
       "      <td>10</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>XNA</td>\n",
       "      <td>Cash</td>\n",
       "      <td>x-sell</td>\n",
       "      <td>AP+ (Cash loan)</td>\n",
       "      <td>-1</td>\n",
       "      <td>XNA</td>\n",
       "      <td>48.0</td>\n",
       "      <td>middle</td>\n",
       "      <td>Cash X-Sell: middle</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>-1163.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>-443.0</td>\n",
       "      <td>-423.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         SK_ID_PREV  SK_ID_CURR NAME_CONTRACT_TYPE  AMT_ANNUITY  \\\n",
       "1670213     2418762      261212         Cash loans      16431.3   \n",
       "\n",
       "         AMT_APPLICATION  AMT_CREDIT  AMT_DOWN_PAYMENT  AMT_GOODS_PRICE  \\\n",
       "1670213         360000.0    360000.0               NaN         360000.0   \n",
       "\n",
       "        WEEKDAY_APPR_PROCESS_START  HOUR_APPR_PROCESS_START  \\\n",
       "1670213                     SUNDAY                       10   \n",
       "\n",
       "        FLAG_LAST_APPL_PER_CONTRACT  NFLAG_LAST_APPL_IN_DAY  \\\n",
       "1670213                           Y                       1   \n",
       "\n",
       "         RATE_DOWN_PAYMENT  RATE_INTEREST_PRIMARY  RATE_INTEREST_PRIVILEGED  \\\n",
       "1670213                NaN                    NaN                       NaN   \n",
       "\n",
       "         ... NAME_GOODS_CATEGORY NAME_PORTFOLIO  NAME_PRODUCT_TYPE  \\\n",
       "1670213  ...                 XNA           Cash             x-sell   \n",
       "\n",
       "            CHANNEL_TYPE SELLERPLACE_AREA NAME_SELLER_INDUSTRY CNT_PAYMENT  \\\n",
       "1670213  AP+ (Cash loan)               -1                  XNA        48.0   \n",
       "\n",
       "        NAME_YIELD_GROUP  PRODUCT_COMBINATION DAYS_FIRST_DRAWING  \\\n",
       "1670213           middle  Cash X-Sell: middle           365243.0   \n",
       "\n",
       "        DAYS_FIRST_DUE  DAYS_LAST_DUE_1ST_VERSION DAYS_LAST_DUE  \\\n",
       "1670213        -1163.0                      247.0        -443.0   \n",
       "\n",
       "         DAYS_TERMINATION NFLAG_INSURED_ON_APPROVAL  \n",
       "1670213            -423.0                       0.0  \n",
       "\n",
       "[1 rows x 37 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 72, 73, 77}\n",
      "home-credit-default-risk/sample_submission.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48743</th>\n",
       "      <td>456250</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       SK_ID_CURR  TARGET\n",
       "48743      456250     0.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1}\n"
     ]
    }
   ],
   "source": [
    "filenames = []\n",
    "for dirname, _, filenamess in os.walk('home-credit-default-risk/'):\n",
    "    for filenamee in filenamess:\n",
    "        if filenamee != \"HomeCredit_columns_description.csv\":\n",
    "            filename = os.path.join(dirname, filenamee)\n",
    "            print(filename)\n",
    "            filenames.append(filename)\n",
    "            df = pd.read_csv(filename)\n",
    "            display(df[-1:])\n",
    "            if filenamee != \"bureau_balance.csv\":\n",
    "                print(set(df.SK_ID_CURR.value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipped\n",
    "for filename in (filenames[:4] + filenames[5:]):\n",
    "    df = pd.read_csv(filename)\n",
    "    print(filename)\n",
    "    display(df.head(2))\n",
    "    #display(df.info())\n",
    "    print(\"shape: \", df.shape)\n",
    "    display(df.nunique())\n",
    "    #display(df.isna().mean().sort_values())\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.read_csv(filenames[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(title):\n",
    "    t0 = time.perf_counter()\n",
    "    yield\n",
    "    print(\"{} - done in {:.0f}s\".format(title, time.perf_counter() - t0))\n",
    "    \n",
    "def one_hot_encoder(df, nan_as_category=True):\n",
    "    original_columns = list(df.columns)\n",
    "    categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
    "    df = pd.get_dummies(df, columns=categorical_columns, dummy_na=nan_as_category)\n",
    "    new_columns = [c for c in df.columns if c not in original_columns]\n",
    "    return df, new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C_B', 'C_G', 'C_R', 'L_A', 'L_B', 'L_C', 'L_D']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C_B</th>\n",
       "      <th>C_G</th>\n",
       "      <th>C_R</th>\n",
       "      <th>C_nan</th>\n",
       "      <th>L_A</th>\n",
       "      <th>L_B</th>\n",
       "      <th>L_C</th>\n",
       "      <th>L_D</th>\n",
       "      <th>L_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   C_B  C_G  C_R  C_nan  L_A  L_B  L_C  L_D  L_nan\n",
       "0    0    0    1      0    1    0    0    0      0\n",
       "1    0    1    0      0    0    1    0    0      0\n",
       "2    1    0    0      0    0    0    1    0      0\n",
       "3    1    0    0      0    0    0    0    1      0\n",
       "4    0    0    1      0    1    0    0    0      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_ohe_test = pd.DataFrame({\n",
    "    'C': ['R', 'G', 'B', 'B', 'R'],\n",
    "    'L': ['A', 'B', 'C', 'D', 'A']\n",
    "})\n",
    "\n",
    "display(one_hot_encoder(df_ohe_test, False)[1])\n",
    "display(one_hot_encoder(df_ohe_test, True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1234567890123456789012345678901234567890123456789012345678901234567890123456789"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1234567890123456789012345678901234567890123456789012345678901234567890123456789"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipped\n",
    "num_rows = None\n",
    "nan_as_category = False\n",
    "df = pd.read_csv('../input/home-credit-default-risk/application_train.csv', nrows=num_rows)\n",
    "test_df = pd.read_csv('../input/home-credit-default-risk/application_test.csv', nrows=num_rows)\n",
    "print(\"Train samples: {}, test samples: {}\".format(len(df), len(test_df)))\n",
    "df = df.append(test_df).reset_index()\n",
    "display(df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipped\n",
    "pd.factorize(df['CODE_GENDER'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess application_train.csv and application_test.csv\n",
    "def application_train_test(num_rows=None, nan_as_category=False):\n",
    "    # Read data and merge\n",
    "    if mini:\n",
    "        df = pd.read_csv(filenames[1], nrows=num_rows)[-10:]\n",
    "        test_df = pd.read_csv(filenames[0], nrows=num_rows)[-2:]\n",
    "    else:\n",
    "        df = pd.read_csv(filenames[1], nrows=num_rows)\n",
    "        test_df = pd.read_csv(filenames[0], nrows=num_rows)\n",
    "    print(\"Train samples: {}, test samples: {}\".format(len(df), len(test_df)))\n",
    "    df = df.append(test_df).reset_index()\n",
    "    # Optional: Remove 4 applications with XNA CODE_GENDER (train set)\n",
    "    df = df[df['CODE_GENDER'] != 'XNA']\n",
    "    \n",
    "    # Categorical features with Binary encode (0 or 1; two categories)\n",
    "    for bin_feature in ['CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY']:\n",
    "        df[bin_feature], uniques = pd.factorize(df[bin_feature])\n",
    "    # Categorical features with One-Hot encode\n",
    "    df, cat_cols = one_hot_encoder(df, nan_as_category)\n",
    "    \n",
    "    # NaN values for DAYS_EMPLOYED: 365.243 -> nan\n",
    "    df['DAYS_EMPLOYED'].replace(365243, np.nan, inplace=True)\n",
    "    # Some simple new features (percentages)\n",
    "    df['DAYS_EMPLOYED_PERC'] = df['DAYS_EMPLOYED'] / df['DAYS_BIRTH']\n",
    "    df['INCOME_CREDIT_PERC'] = df['AMT_INCOME_TOTAL'] / df['AMT_CREDIT']\n",
    "    df['INCOME_PER_PERSON'] = df['AMT_INCOME_TOTAL'] / df['CNT_FAM_MEMBERS']\n",
    "    df['ANNUITY_INCOME_PERC'] = df['AMT_ANNUITY'] / df['AMT_INCOME_TOTAL']\n",
    "    df['PAYMENT_RATE'] = df['AMT_ANNUITY'] / df['AMT_CREDIT']\n",
    "    del test_df\n",
    "    gc.collect()\n",
    "    #print(df.dtypes.value_counts())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipped\n",
    "bureau = pd.read_csv('../input/home-credit-default-risk/bureau.csv', nrows=num_rows)\n",
    "bb = pd.read_csv('../input/home-credit-default-risk/bureau_balance.csv', nrows=num_rows)\n",
    "bb, bb_cat = one_hot_encoder(bb, nan_as_category)\n",
    "bureau, bureau_cat = one_hot_encoder(bureau, nan_as_category)\n",
    "bb_aggregations = {'MONTHS_BALANCE': ['min', 'max', 'size']}\n",
    "for col in bb_cat:\n",
    "    bb_aggregations[col] = ['mean']\n",
    "print(bb_aggregations, \"\\n\", bb.columns, \"\\n\", bureau_cat, \"\\n\", bureau.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipped\n",
    "bb_agg = bb.groupby('SK_ID_BUREAU').agg(bb_aggregations)\n",
    "bb_agg.columns = pd.Index([e[0] + \"_\" + e[1].upper() for e in bb_agg.columns.tolist()])\n",
    "bureau = bureau.join(bb_agg, how='left', on='SK_ID_BUREAU')\n",
    "bureau.drop(['SK_ID_BUREAU'], axis=1, inplace=True)\n",
    "bureau.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipped\n",
    "num_aggregations = {\n",
    "    'DAYS_CREDIT': ['min', 'max', 'mean', 'var'],\n",
    "    'DAYS_CREDIT_ENDDATE': ['min', 'max', 'mean'],\n",
    "    'DAYS_CREDIT_UPDATE': ['mean'],\n",
    "    'CREDIT_DAY_OVERDUE': ['max', 'mean'],\n",
    "    'AMT_CREDIT_MAX_OVERDUE': ['mean'],\n",
    "    'AMT_CREDIT_SUM': ['max', 'mean', 'sum'],\n",
    "    'AMT_CREDIT_SUM_DEBT': ['max', 'mean', 'sum'],\n",
    "    'AMT_CREDIT_SUM_OVERDUE': ['mean'],\n",
    "    'AMT_CREDIT_SUM_LIMIT': ['mean', 'sum'],\n",
    "    'AMT_ANNUITY': ['max', 'mean'],\n",
    "    'CNT_CREDIT_PROLONG': ['sum'],\n",
    "    'MONTHS_BALANCE_MIN': ['min'],\n",
    "    'MONTHS_BALANCE_MAX': ['max'],\n",
    "    'MONTHS_BALANCE_SIZE': ['mean', 'sum']\n",
    "}\n",
    "# Bureau and bureau_balance categorical features\n",
    "cat_aggregations = {}\n",
    "for cat in bureau_cat: cat_aggregations[cat] = ['mean']\n",
    "for cat in bb_cat: cat_aggregations[cat + \"_MEAN\"] = ['mean']\n",
    "\n",
    "bureau_agg = bureau.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n",
    "bureau_agg.columns = pd.Index(['BURO_' + e[0] + \"_\" + e[1].upper() for e in bureau_agg.columns.tolist()])\n",
    "# Bureau: Active credits - using only numerical aggregations\n",
    "active = bureau[bureau['CREDIT_ACTIVE_Active'] == 1]\n",
    "active.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess bureau.csv and bureau_balance.csv\n",
    "def bureau_and_balance(num_rows=None, nan_as_category=True):\n",
    "    if mini:\n",
    "        bureau = pd.read_csv(filenames[2], nrows=num_rows)[-5:-3]\n",
    "        bb = pd.read_csv(filenames[3], nrows=num_rows)[-5:-3]\n",
    "    else:\n",
    "        bureau = pd.read_csv(filenames[2], nrows=num_rows)\n",
    "        bb = pd.read_csv(filenames[3], nrows=num_rows)\n",
    "    bb, bb_cat = one_hot_encoder(bb, nan_as_category)\n",
    "    bureau, bureau_cat = one_hot_encoder(bureau, nan_as_category)\n",
    "    \n",
    "    # Bureau balance: Perform aggregations and merge with bureau.csv\n",
    "    bb_aggregations = {'MONTHS_BALANCE': ['min', 'max', 'size']}\n",
    "    for col in bb_cat:\n",
    "        bb_aggregations[col] = ['mean']\n",
    "    bb_agg = bb.groupby('SK_ID_BUREAU').agg(bb_aggregations)\n",
    "    bb_agg.columns = pd.Index([e[0] + \"_\" + e[1].upper() for e in bb_agg.columns.tolist()])\n",
    "    bureau = bureau.join(bb_agg, how='left', on='SK_ID_BUREAU')\n",
    "    bureau.drop(['SK_ID_BUREAU'], axis=1, inplace=True)\n",
    "    del bb, bb_agg\n",
    "    gc.collect()\n",
    "    \n",
    "    # Bureau and bureau_balance numeric features\n",
    "    num_aggregations = {\n",
    "        'DAYS_CREDIT': ['min', 'max', 'mean', 'var'],\n",
    "        'DAYS_CREDIT_ENDDATE': ['min', 'max', 'mean'],\n",
    "        'DAYS_CREDIT_UPDATE': ['mean'],\n",
    "        'CREDIT_DAY_OVERDUE': ['max', 'mean'],\n",
    "        'AMT_CREDIT_MAX_OVERDUE': ['mean'],\n",
    "        'AMT_CREDIT_SUM': ['max', 'mean', 'sum'],\n",
    "        'AMT_CREDIT_SUM_DEBT': ['max', 'mean', 'sum'],\n",
    "        'AMT_CREDIT_SUM_OVERDUE': ['mean'],\n",
    "        'AMT_CREDIT_SUM_LIMIT': ['mean', 'sum'],\n",
    "        'AMT_ANNUITY': ['max', 'mean'],\n",
    "        'CNT_CREDIT_PROLONG': ['sum'],\n",
    "        'MONTHS_BALANCE_MIN': ['min'],\n",
    "        'MONTHS_BALANCE_MAX': ['max'],\n",
    "        'MONTHS_BALANCE_SIZE': ['mean', 'sum']\n",
    "    }\n",
    "    # Bureau and bureau_balance categorical features\n",
    "    cat_aggregations = {}\n",
    "    for cat in bureau_cat: cat_aggregations[cat] = ['mean']\n",
    "    for cat in bb_cat: cat_aggregations[cat + \"_MEAN\"] = ['mean']\n",
    "    \n",
    "    bureau_agg = bureau.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n",
    "    bureau_agg.columns = pd.Index(['BURO_' + e[0] + \"_\" + e[1].upper() for e in bureau_agg.columns.tolist()])\n",
    "    # Bureau: Active credits - using only numerical aggregations\n",
    "    active = bureau[bureau['CREDIT_ACTIVE_Active'] == 1]\n",
    "    active_agg = active.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    active_agg.columns = pd.Index(['ACTIVE_' + e[0] + \"_\" + e[1].upper() for e in active_agg.columns.tolist()])\n",
    "    bureau_agg = bureau_agg.join(active_agg, how='left', on='SK_ID_CURR')\n",
    "    del active, active_agg\n",
    "    gc.collect()\n",
    "    # Bureau: Closed credits - using only numerical aggregations\n",
    "    closed = bureau[bureau['CREDIT_ACTIVE_Closed'] == 1]\n",
    "    closed_agg = closed.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    closed_agg.columns = pd.Index(['CLOSED_' + e[0] + \"_\" + e[1].upper() for e in closed_agg.columns.tolist()])\n",
    "    bureau_agg = bureau_agg.join(closed_agg, how='left', on='SK_ID_CURR')\n",
    "    del closed, closed_agg, bureau\n",
    "    gc.collect()\n",
    "    #print(bureau_agg.dtypes.value_counts())\n",
    "    return bureau_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipped\n",
    "df = pd.read_csv(filenames[2])[-5:]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipped\n",
    "prev.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess previous_applications.csv\n",
    "def previous_applications(num_rows=None, nan_as_category=True):\n",
    "    if mini:\n",
    "        prev = pd.read_csv(filenames[7], nrows=num_rows)[-7:-5]\n",
    "    else:\n",
    "        prev = pd.read_csv(filenames[7], nrows=num_rows)\n",
    "    prev, cat_cols = one_hot_encoder(prev, nan_as_category=True)\n",
    "    # Days 365.243 values -> nan\n",
    "    prev['DAYS_FIRST_DRAWING'].replace(365243, np.nan, inplace=True)\n",
    "    prev['DAYS_FIRST_DUE'].replace(365243, np.nan, inplace=True)\n",
    "    prev['DAYS_LAST_DUE_1ST_VERSION'].replace(365243, np.nan, inplace=True)\n",
    "    prev['DAYS_LAST_DUE'].replace(365243, np.nan, inplace=True)\n",
    "    prev['DAYS_TERMINATION'].replace(365243, np.nan, inplace=True)\n",
    "    # Add feature: value ask / value received percentage\n",
    "    prev['APP_CREDIT_PERC'] = prev['AMT_APPLICATION'] / prev['AMT_CREDIT']\n",
    "    # Previous applications numeric features\n",
    "    num_aggregations = {\n",
    "        'AMT_ANNUITY': ['min', 'max', 'mean'],\n",
    "        'AMT_APPLICATION': ['min', 'max', 'mean'],\n",
    "        'AMT_CREDIT': ['min', 'max', 'mean'],\n",
    "        'APP_CREDIT_PERC': ['min', 'max', 'mean', 'var'],\n",
    "        'AMT_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
    "        'AMT_GOODS_PRICE': ['min', 'max', 'mean'],\n",
    "        'HOUR_APPR_PROCESS_START': ['min', 'max', 'mean'],\n",
    "        'RATE_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
    "        'DAYS_DECISION': ['min', 'max', 'mean'],\n",
    "        'CNT_PAYMENT': ['mean', 'sum'],\n",
    "    }\n",
    "    # Previous applications categorical features\n",
    "    cat_aggregations = {}\n",
    "    for cat in cat_cols:\n",
    "        cat_aggregations[cat] = ['mean']\n",
    "    \n",
    "    prev_agg = prev.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n",
    "    prev_agg.columns = pd.Index(['PREV_' + e[0] + \"_\" + e[1].upper() for e in prev_agg.columns.tolist()])\n",
    "    # Previous Applications: Approved Applications - only numerical features\n",
    "    approved = prev[prev['NAME_CONTRACT_STATUS_Approved'] == 1]\n",
    "    approved_agg = approved.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    approved_agg.columns = pd.Index(['APPROVED_' + e[0] + \"_\" + e[1].upper() for e in approved_agg.columns.tolist()])\n",
    "    prev_agg = prev_agg.join(approved_agg, how='left', on='SK_ID_CURR')\n",
    "    # Previous Applications: Refused Applications - only numerical features\n",
    "    refused = prev[prev['NAME_CONTRACT_STATUS_Refused'] == 1]\n",
    "    refused_agg = refused.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    refused_agg.columns = pd.Index(['REFUSED_' + e[0] + \"_\" + e[1].upper() for e in refused_agg.columns.tolist()])\n",
    "    prev_agg = prev_agg.join(refused_agg, how='left', on='SK_ID_CURR')\n",
    "    del refused, refused_agg, approved, approved_agg, prev\n",
    "    gc.collect()\n",
    "    #print(prev_agg.dtypes.value_counts())\n",
    "    return prev_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipped\n",
    "df = pd.read_csv(filenames[7])[-7:]\n",
    "df.NAME_CONTRACT_STATUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipped\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess POS_CASH_balance.csv\n",
    "def pos_cash(num_rows=None, nan_as_category=True):\n",
    "    if mini:\n",
    "        pos = pd.read_csv(filenames[6], nrows=num_rows)[-2:]\n",
    "    else:\n",
    "        pos = pd.read_csv(filenames[6], nrows=num_rows)\n",
    "    pos, cat_cols = one_hot_encoder(pos, nan_as_category=True)\n",
    "    # Features\n",
    "    aggregations = {\n",
    "        'MONTHS_BALANCE': ['max', 'mean', 'size'],\n",
    "        'SK_DPD': ['max', 'mean'],\n",
    "        'SK_DPD_DEF': ['max', 'mean']\n",
    "    }\n",
    "    for cat in cat_cols:\n",
    "        aggregations[cat] = ['mean']\n",
    "    \n",
    "    pos_agg = pos.groupby('SK_ID_CURR').agg(aggregations)\n",
    "    pos_agg.columns = pd.Index(['POS_' + e[0] + \"_\" + e[1].upper() for e in pos_agg.columns.tolist()])\n",
    "    # Count pos cash accounts\n",
    "    pos_agg['POS_COUNT'] = pos.groupby('SK_ID_CURR').size()\n",
    "    del pos\n",
    "    gc.collect()\n",
    "    #print(pos_agg.dtypes.value_counts())\n",
    "    return pos_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess installments_payments.csv\n",
    "def installments_payments(num_rows=None, nan_as_category=True):\n",
    "    if mini:\n",
    "        ins = pd.read_csv(filenames[5], nrows=num_rows)[-2:]\n",
    "    else:\n",
    "        ins = pd.read_csv(filenames[5], nrows=num_rows)\n",
    "    ins, cat_cols = one_hot_encoder(ins, nan_as_category=True)\n",
    "    # Percentage and difference paid in each installment (amount paid and installment value)\n",
    "    ins['PAYMENT_PERC'] = ins['AMT_PAYMENT'] / ins['AMT_INSTALMENT']\n",
    "    ins['PAYMENT_DIFF'] = ins['AMT_INSTALMENT'] - ins['AMT_PAYMENT']\n",
    "    # Days past due and days before due (no negative values)\n",
    "    ins['DPD'] = ins['DAYS_ENTRY_PAYMENT'] - ins['DAYS_INSTALMENT']\n",
    "    ins['DBD'] = ins['DAYS_INSTALMENT'] - ins['DAYS_ENTRY_PAYMENT']\n",
    "    ins['DPD'] = ins['DPD'].apply(lambda x: x if x > 0 else 0)\n",
    "    ins['DBD'] = ins['DBD'].apply(lambda x: x if x > 0 else 0)\n",
    "    # Features: Perform aggregations\n",
    "    aggregations = {\n",
    "        'NUM_INSTALMENT_VERSION': ['nunique'],\n",
    "        'DPD': ['max', 'mean', 'sum'],\n",
    "        'DBD': ['max', 'mean', 'sum'],\n",
    "        'PAYMENT_PERC': ['max', 'mean', 'sum', 'var'],\n",
    "        'PAYMENT_DIFF': ['max', 'mean', 'sum', 'var'],\n",
    "        'AMT_INSTALMENT': ['max', 'mean', 'sum'],\n",
    "        'AMT_PAYMENT': ['min', 'max', 'mean', 'sum'],\n",
    "        'DAYS_ENTRY_PAYMENT': ['max', 'mean', 'sum']\n",
    "    }\n",
    "    for cat in cat_cols:\n",
    "        aggregations[cat] = ['mean']\n",
    "    ins_agg = ins.groupby('SK_ID_CURR').agg(aggregations)\n",
    "    ins_agg.columns = pd.Index(['INSTAL_' + e[0] + \"_\" + e[1].upper() for e in ins_agg.columns.tolist()])\n",
    "    # Count installments accounts\n",
    "    ins_agg['INSTAL_COUNT'] = ins.groupby('SK_ID_CURR').size()\n",
    "    del ins\n",
    "    gc.collect()\n",
    "    #print(ins_agg.dtypes.value_counts())\n",
    "    return ins_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess credit_card_balance.csv\n",
    "def credit_card_balance(num_rows=None, nan_as_category=True):\n",
    "    if mini:\n",
    "        cc = pd.read_csv(filenames[4], nrows=num_rows)[-2:]\n",
    "    else:\n",
    "        cc = pd.read_csv(filenames[4], nrows=num_rows)\n",
    "    cc, cat_cols = one_hot_encoder(cc, nan_as_category=True)\n",
    "    # General aggregations\n",
    "    cc.drop(['SK_ID_PREV'], axis=1, inplace =True)\n",
    "    cc_agg = cc.groupby('SK_ID_CURR').agg(['min', 'max', 'mean', 'sum', 'var'])\n",
    "    cc_agg.columns = pd.Index(['CC_' + e[0] + \"_\" + e[1].upper() for e in cc_agg.columns.tolist()])\n",
    "    # Count credit card lines\n",
    "    cc_agg['CC_COUNT'] = cc.groupby('SK_ID_CURR').size()\n",
    "    del cc\n",
    "    gc.collect()\n",
    "    #print(cc_agg.dtypes.value_counts())\n",
    "    return cc_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM GBDT with KFold or Stratified KFold\n",
    "# Parameters from Tilii kernel: https://www.kaggle.com/tilii7/olivier-lightgbm-parameters-by-bayesian-opt/code\n",
    "def kfold_lightgbm(df, num_folds, stratified=False, debug=False):\n",
    "    # Divide in training/validation and test data\n",
    "    train_df = df[df['TARGET'].notnull()]\n",
    "    test_df = df[df['TARGET'].isnull()]\n",
    "    print(\"Starting LightGBM. Train shape: {}, test shape: {}\".format(train_df.shape, test_df.shape))\n",
    "    del df\n",
    "    gc.collect()\n",
    "    # Cross validation model\n",
    "    if stratified:\n",
    "        folds = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=1001)\n",
    "    else:\n",
    "        folds = KFold(n_splits=num_folds, shuffle=True, random_state=1001)\n",
    "    # Create arrays and dataframes to store results\n",
    "    oof_preds = np.zeros(train_df.shape[0])\n",
    "    sub_preds = np.zeros(test_df.shape[0])\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    feats = [f for f in train_df.columns if f not in ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV','index']]\n",
    "    \n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], train_df['TARGET'])):\n",
    "        train_x, train_y = train_df[feats].iloc[train_idx], train_df['TARGET'].iloc[train_idx]\n",
    "        valid_x, valid_y = train_df[feats].iloc[valid_idx], train_df['TARGET'].iloc[valid_idx]\n",
    "\n",
    "        # LightGBM parameters found by Bayesian optimization\n",
    "        clf = LGBMClassifier(\n",
    "            nthread=4,\n",
    "            n_estimators=10000,\n",
    "            learning_rate=0.02,\n",
    "            num_leaves=34,\n",
    "            colsample_bytree=0.9497036,\n",
    "            subsample=0.8715623,\n",
    "            max_depth=8,\n",
    "            reg_alpha=0.041545473,\n",
    "            reg_lambda=0.0735294,\n",
    "            min_split_gain=0.0222415,\n",
    "            min_child_weight=39.3259775,\n",
    "            silent=-1,\n",
    "            verbose=-1,\n",
    "        )\n",
    "\n",
    "        clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], \n",
    "            eval_metric='auc', verbose=200, early_stopping_rounds=200)\n",
    "\n",
    "        oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration=clf.best_iteration_)[:, 1]\n",
    "        sub_preds += clf.predict_proba(test_df[feats], num_iteration=clf.best_iteration_)[:, 1] / folds.n_splits\n",
    "\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = feats\n",
    "        fold_importance_df[\"importance\"] = clf.feature_importances_\n",
    "        fold_importance_df[\"fold\"] = n_fold + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "        print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(valid_y, oof_preds[valid_idx])))\n",
    "        del clf, train_x, train_y, valid_x, valid_y\n",
    "        gc.collect()\n",
    "\n",
    "    print('Full AUC score %.6f' % roc_auc_score(train_df['TARGET'], oof_preds))\n",
    "    # Write submission file and plot feature importance\n",
    "    if not debug:\n",
    "        test_df['TARGET'] = sub_preds\n",
    "        test_df[['SK_ID_CURR', 'TARGET']].to_csv(submission_file_name, index=False)\n",
    "    display_importances(feature_importance_df)\n",
    "    return feature_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display/plot feature importance\n",
    "def display_importances(feature_importance_df_):\n",
    "    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\")\\\n",
    "           .mean().sort_values(by=\"importance\", ascending=False)[:40].index\n",
    "    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n",
    "    plt.figure(figsize=(8, 10))\n",
    "    sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "    plt.title('LightGBM Features (avg over folds)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('lgbm_importances01.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(debug=False):\n",
    "    num_rows = 1000 if debug else None\n",
    "#    mini = 0 if debug else non sinon il est jamais full le df\n",
    "#    if debug: mini = 0 En fait même celui-ci ne fontionne pas car lors de la\n",
    "#    def des fcts mini valait 1 et lors le l'appel des fcts soit le \"if mini\"\n",
    "#    ne sera pas lu car il a déjà été évalué lors du def ou alors le \"if mini\"\n",
    "#    est lu mais ne regarde pas la valeur actuelle de mini seulement celle qui\n",
    "#    était active lors du def. Je ne sais pas exactement mais le résultat est\n",
    "#    que c'est trop tard ici pour dire \"mini = 0\".\n",
    "    df = application_train_test(num_rows)\n",
    "    print(\"Application train test df shape:\", df.shape)\n",
    "#    print(df.dtypes.value_counts())\n",
    "    with timer(\"Process bureau and bureau_balance\"):\n",
    "        bureau = bureau_and_balance(num_rows)\n",
    "        print(\"Bureau df shape:\", bureau.shape)\n",
    "        df = df.join(bureau, how='left', on='SK_ID_CURR')\n",
    "#        print(df.dtypes.value_counts())\n",
    "        del bureau\n",
    "        gc.collect()\n",
    "    with timer(\"Process previous_applications\"):\n",
    "        prev = previous_applications(num_rows)\n",
    "        print(\"Previous applications df shape:\", prev.shape)\n",
    "        df = df.join(prev, how='left', on='SK_ID_CURR')\n",
    "#        print(df.dtypes.value_counts())\n",
    "        del prev\n",
    "        gc.collect()\n",
    "    with timer(\"Process POS-CASH balance\"):\n",
    "        pos = pos_cash(num_rows)\n",
    "        print(\"Pos-cash balance df shape:\", pos.shape)\n",
    "        df = df.join(pos, how='left', on='SK_ID_CURR')\n",
    "#        print(df.dtypes.value_counts())\n",
    "        del pos\n",
    "        gc.collect()\n",
    "    with timer(\"Process installments payments\"):\n",
    "        ins = installments_payments(num_rows)\n",
    "        print(\"Installments payments df shape:\", ins.shape)\n",
    "        df = df.join(ins, how='left', on='SK_ID_CURR')\n",
    "#        print(df.dtypes.value_counts())\n",
    "        del ins\n",
    "        gc.collect()\n",
    "    with timer(\"Process credit card balance\"):\n",
    "        cc = credit_card_balance(num_rows)\n",
    "        print(\"Credit card balance df shape:\", cc.shape)\n",
    "        df = df.join(cc, how='left', on='SK_ID_CURR')\n",
    "#        print(df.dtypes.value_counts())\n",
    "        del cc\n",
    "        gc.collect()\n",
    "#    with timer(\"Run LightGBM with kfold\"):\n",
    "#        feat_importance = kfold_lightgbm(df, num_folds=10, stratified=False, debug=debug)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1234567890123456789012345678901234567890123456789012345678901234567890123456789"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1234567890123456789012345678901234567890123456789012345678901234567890123456789"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipped\n",
    "# I ran this cell only once, just to get the exact values of zo and oz.\n",
    "if __name__ == \"__main__\":\n",
    "    submission_file_name = \"submission_kernel02.csv\"\n",
    "    with timer(\"Full model run\"):\n",
    "#        main()\n",
    "        df = main(debug=False)\n",
    "\n",
    "zeros_full = df.TARGET.value_counts(\n",
    "    sort=True,\n",
    "    ascending=False,\n",
    "    dropna=True,\n",
    ")[0]\n",
    "ones_full = df.TARGET.value_counts(\n",
    "    sort=True,\n",
    "    ascending=False,\n",
    "    dropna=True,\n",
    ")[1]\n",
    "print(f\"{zeros_full:.2f}\", f\"{ones_full:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros_full, ones_full = 282682, 24825"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.39 0.09\n"
     ]
    }
   ],
   "source": [
    "zo = zeros_full/ones_full\n",
    "oz = ones_full/zeros_full\n",
    "print(f\"{zo:.2f}\", f\"{oz:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo\n",
    "if __name__ == \"__main__\":\n",
    "    submission_file_name = \"submission_kernel02.csv\"\n",
    "    with timer(\"Full model run\"):\n",
    "#        main()\n",
    "        df = main(debug=True)\n",
    "\n",
    "zeros = df.TARGET.value_counts(\n",
    "    sort=True,\n",
    "    ascending=False,\n",
    "    dropna=True,\n",
    ")[0]\n",
    "ones = df.TARGET.value_counts(\n",
    "    sort=True,\n",
    "    ascending=False,\n",
    "    dropna=True,\n",
    ")[1]\n",
    "print(f\"{zeros:.2f}\", f\"{ones:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 1000, test samples: 1000\n",
      "Application train test df shape: (2000, 235)\n",
      "Bureau df shape: (205, 99)\n",
      "Process bureau and bureau_balance - done in 0s\n",
      "Previous applications df shape: (985, 221)\n",
      "Process previous_applications - done in 0s\n",
      "Pos-cash balance df shape: (989, 12)\n",
      "Process POS-CASH balance - done in 0s\n",
      "Installments payments df shape: (965, 26)\n",
      "Process installments payments - done in 0s\n",
      "Credit card balance df shape: (1000, 116)\n",
      "Process credit card balance - done in 0s\n",
      "Full model run - done in 1s\n",
      "930.00 70.00\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    submission_file_name = \"submission_kernel02.csv\"\n",
    "    with timer(\"Full model run\"):\n",
    "        debug = True\n",
    "        num_rows = 1000 if debug else None\n",
    "#        mini = 0 if debug else non sinon il est jamais full le df\n",
    "        if debug: mini = 0\n",
    "        df = application_train_test(num_rows)\n",
    "        print(\"Application train test df shape:\", df.shape)\n",
    "#        print(df.dtypes.value_counts())\n",
    "        with timer(\"Process bureau and bureau_balance\"):\n",
    "            bureau = bureau_and_balance(num_rows)\n",
    "            print(\"Bureau df shape:\", bureau.shape)\n",
    "            df = df.join(bureau, how='left', on='SK_ID_CURR')\n",
    "#            print(df.dtypes.value_counts())\n",
    "            del bureau\n",
    "            gc.collect()\n",
    "        with timer(\"Process previous_applications\"):\n",
    "            prev = previous_applications(num_rows)\n",
    "            print(\"Previous applications df shape:\", prev.shape)\n",
    "            df = df.join(prev, how='left', on='SK_ID_CURR')\n",
    "#            print(df.dtypes.value_counts())\n",
    "            del prev\n",
    "            gc.collect()\n",
    "        with timer(\"Process POS-CASH balance\"):\n",
    "            pos = pos_cash(num_rows)\n",
    "            print(\"Pos-cash balance df shape:\", pos.shape)\n",
    "            df = df.join(pos, how='left', on='SK_ID_CURR')\n",
    "#            print(df.dtypes.value_counts())\n",
    "            del pos\n",
    "            gc.collect()\n",
    "        with timer(\"Process installments payments\"):\n",
    "            ins = installments_payments(num_rows)\n",
    "            print(\"Installments payments df shape:\", ins.shape)\n",
    "            df = df.join(ins, how='left', on='SK_ID_CURR')\n",
    "#            print(df.dtypes.value_counts())\n",
    "            del ins\n",
    "            gc.collect()\n",
    "        with timer(\"Process credit card balance\"):\n",
    "            cc = credit_card_balance(num_rows)\n",
    "            print(\"Credit card balance df shape:\", cc.shape)\n",
    "            df = df.join(cc, how='left', on='SK_ID_CURR')\n",
    "#            print(df.dtypes.value_counts())\n",
    "            del cc\n",
    "            gc.collect()\n",
    "\n",
    "zeros = df.TARGET.value_counts(\n",
    "    sort=True,\n",
    "    ascending=False,\n",
    "    dropna=True,\n",
    ")[0]\n",
    "ones = df.TARGET.value_counts(\n",
    "    sort=True,\n",
    "    ascending=False,\n",
    "    dropna=True,\n",
    ")[1]\n",
    "print(f\"{zeros:.2f}\", f\"{ones:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.29 0.08\n"
     ]
    }
   ],
   "source": [
    "zo_sub = zeros/ones\n",
    "oz_sub = ones/zeros\n",
    "print(f\"{zo_sub:.2f}\", f\"{oz_sub:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'imbalance de 11.39 des targets du dataset est de 13.29 après subsampling.\n"
     ]
    }
   ],
   "source": [
    "if (zo/zo_sub >= 3/2 or zo/zo_sub <= 2/3):\n",
    "    for _ in range(50):\n",
    "        print(\"!\")\n",
    "    print(\n",
    "        \"L'imbalance des targets a été fortement modifiée par le\",\n",
    "        \"subsampling. Elle est passée de\",\n",
    "        f\"{zo:.2f}\",\n",
    "        \"à\",\n",
    "        f\"{zo_sub:.2f}\",\n",
    "        \".\",\n",
    "    )\n",
    "else:\n",
    "    print(\n",
    "        \"L'imbalance de\",\n",
    "        f\"{zo:.2f}\",\n",
    "        \"des targets du dataset est de\",\n",
    "        f\"{zo_sub:.2f}\",\n",
    "        \"après subsampling.\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1234567890123456789012345678901234567890123456789012345678901234567890123456789"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1234567890123456789012345678901234567890123456789012345678901234567890123456789"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"df_agg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"../input/df_agg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"../df_agg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"../working/df_agg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.read_csv('../df_agg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipped\n",
    "df = pd.read_csv(\"df_agg.csv\")\n",
    "print(df.shape)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipped\n",
    "for dirname, _, filenames in os.walk('..'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipped\n",
    "for dirname, _, filenames in os.walk('/kaggle'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_of_df = list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipped\n",
    "for j in cols_of_df:\n",
    "    df = df.rename(columns={j: re.sub(r\"[ ]\", r\"_a_\", j)})\n",
    "    df = df.rename(columns={j: re.sub(r\"[-]\", r\"_b_\", j)})\n",
    "    df = df.rename(columns={j: re.sub(r\"[:]\", r\"_c_\", j)})\n",
    "    df = df.rename(columns={j: re.sub(r\"[/]\", r\"_d_\", j)})\n",
    "    df = df.rename(columns={j: re.sub(r\"[,]\", r\"_e_\", j)})\n",
    "    df = df.rename(columns={j: re.sub(r\"[:]\", r\"_f_\", j)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns=lambda x: x.replace(\" \", \"_a_\")\\\n",
    "                                  .replace(\"-\", \"_b_\")\\\n",
    "                                  .replace(\":\", \"_c_\")\\\n",
    "                                  .replace(\"/\", \"_d_\")\\\n",
    "                                  .replace(\",\", \"_e_\")\\\n",
    "                                  .replace(\":\", \"_f_\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipped\n",
    "with timer(\"Run LightGBM with kfold\"):\n",
    "    feat_importance = kfold_lightgbm(df, num_folds=10, stratified=False, debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo mauvaise idée\n",
    "#surtout pas de random split car TARGET a des NaN en plus des 0 ou 1\n",
    "X = df.drop(\"TARGET\", axis=\"columns\")\n",
    "y = df[\"TARGET\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "...     X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1234567890123456789012345678901234567890123456789012345678901234567890123456789"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1234567890123456789012345678901234567890123456789012345678901234567890123456789"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[df['TARGET'].notnull()]\n",
    "X_train = train_df.drop(\"TARGET\", axis=\"columns\")\n",
    "y_train = train_df[\"TARGET\"]\n",
    "test_df = df[df['TARGET'].isnull()]\n",
    "X_test = test_df.drop(\"TARGET\", axis=\"columns\")\n",
    "y_test = test_df[\"TARGET\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    930\n",
       "1.0     70\n",
       "Name: TARGET, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_train_i = imputer.fit_transform(X_train)\n",
    "X_test_i = imputer.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipped\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "undersampler = RandomUnderSampler(sampling_strategy='majority')\n",
    "X_train_u, y_train_u = undersampler.fit_resample(X_train_i, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "#oversampler = RandomOverSampler(sampling_strategy='minority')\n",
    "oversampler = SMOTE()\n",
    "X_train_o, y_train_o = oversampler.fit_resample(X_train_i, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distributions = {\n",
    "    'dummy': {'class_weight': [{0: 1, 1: 1}, {0: oz, 1: zo}]},\n",
    "    'naive_bayes': {'class_weight': [{0: oz, 1: zo}]},\n",
    "    'sgd': {'loss': ['hinge', 'log', 'squared_hinge', 'modified_huber'],\n",
    "            'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "            'class_weight': [{0: oz, 1: zo}]},\n",
    "    'knn': {'n_neighbors': range(1, 11),\n",
    "            'weights': ['uniform', 'distance'],\n",
    "            'class_weight': [{0: oz, 1: zo}]},\n",
    "    'svc': {'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
    "            'C': [0.1, 1, 10, 100, 1000],\n",
    "            'gamma': ['auto', 'scale'],\n",
    "            'class_weight': [{0: oz, 1: zo}]},\n",
    "    'random_forest': {'n_estimators': [10, 100, 1000],\n",
    "                      'criterion': ['gini', 'entropy'],\n",
    "                      'class_weight': [{0: oz, 1: zo}]},\n",
    "    'xgb': {'booster': ['gbtree', 'gblinear', 'dart'],\n",
    "            'learning_rate': [0.1, 0.01, 0.001],\n",
    "            'max_depth': range(1, 11),\n",
    "            'class_weight': [{0: oz, 1: zo}]},\n",
    "    'catboost': {'iterations': [10, 100, 1000],\n",
    "                 'learning_rate': [0.1, 0.01, 0.001],\n",
    "                 'depth': range(1, 11),\n",
    "                 'class_weight': [{0: oz, 1: zo}]},\n",
    "    'adaboost': {'n_estimators': [10, 100, 1000],\n",
    "                 'learning_rate': [0.1, 0.01, 0.001],\n",
    "                 'class_weight': [{0: oz, 1: zo}]},\n",
    "    'lightgbm': {'boosting_type': ['gbdt', 'dart', 'goss'],\n",
    "                 'learning_rate': [0.1, 0.01, 0.001],\n",
    "                 'num_leaves': range(10, 110, 10),\n",
    "                 'class_weight': [{0: oz, 1: zo}]},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distributions = {\n",
    "    'dummy': {},\n",
    "    'naive_bayes': {},\n",
    "    'sgd': {'loss': ['hinge', 'log', 'squared_hinge', 'modified_huber'],\n",
    "             'penalty': ['l2', 'l1', 'elasticnet']},\n",
    "    'knn': {'n_neighbors': range(1, 11),\n",
    "            'weights': ['uniform', 'distance']},\n",
    "    'svc': {'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
    "            'C': [0.1, 1, 10, 100, 1000],\n",
    "            'gamma': ['auto', 'scale']},\n",
    "    'random_forest': {'n_estimators': [10, 100, 1000],\n",
    "                      'criterion': ['gini', 'entropy']},\n",
    "    'xgb': {'booster': ['gbtree', 'gblinear', 'dart'],\n",
    "            'learning_rate': [0.1, 0.01, 0.001],\n",
    "            'max_depth': range(1, 11)},\n",
    "    'catboost': {'iterations': [10, 100, 1000],\n",
    "                 'learning_rate': [0.1, 0.01, 0.001],\n",
    "                 'depth': range(1, 11)},\n",
    "    'adaboost': {'n_estimators': [10, 100, 1000],\n",
    "                 'learning_rate': [0.1, 0.01, 0.001]},\n",
    "    'lightgbm': {'boosting_type': ['gbdt', 'dart', 'goss'],\n",
    "                 'learning_rate': [0.1, 0.01, 0.001],\n",
    "                 'num_leaves': range(10, 110, 10)},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distributions = {\n",
    "    'dummy': {},\n",
    "    'naive_bayes': {},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    'dummy': DummyClassifier(),\n",
    "    'naive_bayes': GaussianNB(),\n",
    "    'sgd': SGDClassifier(),\n",
    "    'knn': KNeighborsClassifier(),\n",
    "    'svc': SVC(),\n",
    "    'random_forest': RandomForestClassifier(),\n",
    "    'xgb': XGBClassifier(),\n",
    "    'catboost': CatBoostClassifier(),\n",
    "    'adaboost': AdaBoostClassifier(),\n",
    "    'lightgbm': LGBMClassifier(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    'dummy': DummyClassifier(),\n",
    "    'naive_bayes': GaussianNB(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (870885351.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [68]\u001b[1;36m\u001b[0m\n\u001b[1;33m    =r\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "=r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[(name, estimator) for name, estimator in classifiers.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_cv = RandomizedSearchCV(estimator=Pipeline(classifiers),\n",
    "                           param_distributions=param_distributions,\n",
    "                           n_iter=10,\n",
    "                           cv=5,\n",
    "                           scoring=['roc_auc', 'accuracy'],\n",
    "                           refit='roc_auc',\n",
    "                           random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rs_cv.fit(X_train, y_train)\n",
    "#rs_cv.fit(X_train_u, y_train_u)\n",
    "rs_cv.fit(X_train_o, y_train_o)\n",
    "\n",
    "for algorithm in classifiers.keys():\n",
    "    print(f\"Best parameters for {algorithm}: {rs_cv.best_params_[algorithm]}\")\n",
    "    print(f\"Best AUC score for {algorithm}: {rs_cv.best_score_[algorithm]['roc_auc']:.3f}\")\n",
    "    print(f\"Best accuracy score for {algorithm}: {rs_cv.best_score_[algorithm]['accuracy']:.3f}\")\n",
    "\n",
    "#best_algorithm = rs_cv.best_estimator_.keys()[0]\n",
    "best_algorithm = rs_cv.best_estimator_.named_steps.keys()\n",
    "print(f\"Overall best algorithm: {best_algorithm}\")\n",
    "print(f\"Best AUC score: {rs_cv.best_score_[best_algorithm]['roc_auc']:.3f}\")\n",
    "print(f\"Best accuracy score: {rs_cv.best_score_[best_algorithm]['accuracy']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = RandomForestClassifier(random_state=42)\n",
    "clf2 = SVC(probability=True, random_state=42)\n",
    "clf3 = LogisticRegression(random_state=42)\n",
    "clf4 = DecisionTreeClassifier(random_state=42)\n",
    "clf5 = KNeighborsClassifier()\n",
    "clf6 = MultinomialNB()\n",
    "clf7 = GradientBoostingClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param1 = {}\n",
    "param1['classifier__n_estimators'] = [10, 50, 100, 250]\n",
    "param1['classifier__max_depth'] = [5, 10, 20]\n",
    "param1['classifier__class_weight'] = [None, {0:1,1:5}, {0:1,1:10}, {0:1,1:25}]\n",
    "param1['classifier'] = [clf1]\n",
    "\n",
    "param2 = {}\n",
    "param2['classifier__C'] = [10**-2, 10**-1, 10**0, 10**1, 10**2]\n",
    "param2['classifier__class_weight'] = [None, {0:1,1:5}, {0:1,1:10}, {0:1,1:25}]\n",
    "param2['classifier'] = [clf2]\n",
    "\n",
    "param3 = {}\n",
    "param3['classifier__C'] = [10**-2, 10**-1, 10**0, 10**1, 10**2]\n",
    "param3['classifier__penalty'] = ['l1', 'l2']\n",
    "param3['classifier__class_weight'] = [None, {0:1,1:5}, {0:1,1:10}, {0:1,1:25}]\n",
    "param3['classifier'] = [clf3]\n",
    "\n",
    "param4 = {}\n",
    "param4['classifier__max_depth'] = [5,10,25,None]\n",
    "param4['classifier__min_samples_split'] = [2,5,10]\n",
    "param4['classifier__class_weight'] = [None, {0:1,1:5}, {0:1,1:10}, {0:1,1:25}]\n",
    "param4['classifier'] = [clf4]\n",
    "\n",
    "param5 = {}\n",
    "param5['classifier__n_neighbors'] = [2,5,10,25,50]\n",
    "param5['classifier'] = [clf5]\n",
    "\n",
    "param6 = {}\n",
    "param6['classifier__alpha'] = [10**0, 10**1, 10**2]\n",
    "param6['classifier'] = [clf6]\n",
    "\n",
    "param7 = {}\n",
    "param7['classifier__n_estimators'] = [10, 50, 100, 250]\n",
    "param7['classifier__max_depth'] = [5, 10, 20]\n",
    "param7['classifier'] = [clf7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('classifier', clf1)])\n",
    "params = [param1, param2, param3, param4, param5, param6, param7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gs = GridSearchCV(pipeline, params, cv=3, n_jobs=-1, scoring='roc_auc').fit(X_train, y_train)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test Precision:\",precision_score(gs.predict(X_test), y_test))\n",
    "print(\"Test Recall:\",recall_score(gs.predict(X_test), y_test))\n",
    "print(\"Test ROC AUC Score:\",roc_auc_score(gs.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rs = RandomizedSearchCV(pipeline, params, cv=3, n_jobs=-1, scoring='roc_auc').fit(X_train, y_train)\n",
    "rs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision:\",precision_score(rs.predict(X_test), y_test))\n",
    "print(\"Recall:\",recall_score(rs.predict(X_test), y_test))\n",
    "print(\"ROC AUC Score:\",roc_auc_score(rs.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "=r on va faire un griudsearch fine tuné là"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = rs_cv.best_estimator_[best_algorithm].predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
